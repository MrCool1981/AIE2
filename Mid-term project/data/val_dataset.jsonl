{"questions": {"d6517df6-948c-4925-90de-b3da4181a372": "What are the responsibilities outlined in GV-4.1-003?", "4595b2b3-3b24-4019-9db7-e13e5ab60fa8": "What is the focus of GOVERN 4.2?", "9abe004c-cf87-4ef0-8245-2cc27d88fa85": "Which AI actor tasks are mentioned in the context?", "31cc0ed6-cf56-45eb-b3c6-48b68713fd7b": "What is the suggested action for Action ID MP-3.4-001?", "6ee39258-c357-4766-b645-7f39ca88ec27": "Which GAI risk is associated with adapting existing training programs to include modules on digital content transparency?", "6c6d2106-feb6-4306-b921-b41097e00e73": "What is the purpose of developing certification programs according to Action ID MP-3.4-003?", "ba422246-d5f0-4046-8c35-6c878ed6238c": "What mechanisms are in place to inventory AI systems?", "b9b12676-5084-4ae8-9968-fc0f45fb4597": "How are AI systems resourced according to organizational risk priorities?", "40ed98b8-cb05-491f-a61a-b0d567ae8b88": "What tasks are involved in Governance and Oversight of AI systems?", "d55e461c-6123-4a95-86ef-ece6d78f53c1": "What is the title of the publication by the National Institute of Standards and Technology in 2022?", "b8e4cf73-125c-49b3-bd82-a8dbd208a20b": "Who is the lead author of the 2021 paper on label errors in test sets?", "3aaca092-1b77-451f-811f-bb9a9b67c71f": "Which organization published a paper in 2022 about managing bias in artificial intelligence?", "9c882f36-6793-416f-bcc4-06d9b274803e": "How does the carbon emission of training a single transformer LLM compare to roundtrip flights between San Francisco and New York?", "dc7a108f-88e6-4a35-a7bf-85738a615c5b": "What types of tasks are more energy and carbon-intensive during LLM inference?", "e6e8bd65-4719-427a-a9ab-49ac2c983f49": "What methods are suggested to reduce environmental impacts at inference time for LLMs?", "1eed1f03-df2c-4d3c-82ed-e52d3caafd12": "What is prompt injection in the context of GAI systems?", "c51759c9-c57c-4fda-904d-c66b6df747cc": "How do direct prompt injections differ from indirect prompt injections?", "f88691fb-cf3d-45ad-accc-0477cd4d93df": "What are some potential consequences of indirect prompt injection attacks?", "28a72b48-0642-47ef-9eb9-31ea770f8d19": "What types of data may unintentionally be included in GAI training datasets?", "3361a2a3-3f79-4081-b577-ec899d1f2a93": "How have websites and mobile apps that generate synthetic NCII evolved?", "4cb47a63-e325-4bdc-82e3-d2a1e641cb21": "What did a recent report find in several commonly used GAI training datasets?", "b7ea996a-f887-49e6-b402-002e2d98a19b": "What is meant by 'Human-Al Configuration'?", "7225122f-6ef0-4c73-a300-6ca046f16c25": "What are the potential risks associated with 'Bias and Homogenization' in AI?", "65a2994d-1236-47a3-a5d6-d165494a0ca7": "What tasks are involved in 'AI Deployment'?", "22904442-a36b-4d4b-8139-7669a7a98ab7": "How can harmful bias in GAI systems lead to discriminatory decision-making?", "2edd683a-6abc-441f-bbd5-c74d45362563": "What challenges do lower-resource languages face with the adoption of GAI systems?", "f97b5827-d672-4ec1-988a-f17fc3d13b53": "Why might GAI systems be inappropriately trusted to perform similarly across all subgroups?", "cf4eb38e-31cc-48a6-9c93-c1235d79f3a0": "What is discussed in Chapter 3 of the AI Risk Management Framework by the National Institute of Standards and Technology?", "af05be4a-3359-423a-8407-d26fa37e645f": "Where can one find the descriptions of AI actor tasks in the AI Risk Management Framework?", "96ee6704-3ba2-442d-8919-dca2b4940473": "What chapter of the AI Risk Management Framework covers AI RMF Profiles?", "8c6abb69-3223-4588-bfe3-34f9a7e9a280": "What mechanisms are in place to sustain the value of deployed AI systems?", "076252f4-ad82-45fa-8051-88a6f761f293": "How are the mechanisms applied to maintain the value of AI systems?", "9c52a885-c91c-4045-9c82-387a4689b0f3": "Why is it important to sustain the value of deployed AI systems?", "969fba7c-8c7b-4632-8fd6-6cc65bcbe156": "What are the suggested actions for gathering structured public feedback?", "628781d3-f4a4-4f06-904d-107e288f675e": "What risks are associated with the action ID MS-1.3-001?", "ebbd8787-d95b-4771-a0cb-27ad9837ab8c": "Who should be consulted for structured human feedback exercises according to action ID MS-1.3-002?", "1f500a4f-9096-4396-b70b-297559ef0cea": "What are the key factors to assess when determining the expected and acceptable GAI system context of use?", "0e13916f-8a0e-4036-aa27-85d3475e2d1c": "What should be included in the documentation of risk measurement plans for GAI systems?", "f71eefd5-10bc-447e-ba07-79ba4992613e": "What types of biases should be considered for AI Actors involved in the design and implementation of GAI systems?", "8e17e3a0-ae22-4363-bf7e-8895d958ea9b": "What are the primary considerations derived from the GAI PWG consultation process?", "10e097e9-8948-4506-9d72-eaf9d4718700": "What are some examples of legal and regulatory requirements for reporting GAI incidents?", "d0ddf446-73b2-4c58-b38d-7d4cc5bfdf72": "Which areas are relevant for voluntary use by organizations designing, developing, and using GAI?", "64b61f37-267e-484a-a6fa-60adca25e747": "What should be leveraged from organizational boards or committees when using third-party pre-trained models?", "bfaf6c91-2f4d-4da9-965f-72c017834be5": "When should human moderation systems be used to review generated content?", "84efbc2f-209f-4ae8-844f-4f6722ad953a": "How should organizational risk tolerance be used in the context of pre-trained models?", "318f9cf4-7f4e-4468-9c98-ce162b1e6059": "What are some of the risks associated with the GAI system value chain?", "8bafe347-8dcf-4860-9483-04888421b404": "What should be re-assessed after fine-tuning or retrieval-augmented generation implementation?", "4692e0f5-5b1b-4d69-89b3-3e03887eb7e8": "What are the key areas of focus for MG-3.1-002?", "08828efb-d09a-400b-ab12-269ae528db7a": "What are the suggested actions for Action ID MS-2.10-001?", "2f75b55a-2cc7-47dc-85f6-f7e5602e32a4": "What risks are associated with Action ID MS-2.10-001?", "517dc5f3-d485-46b4-a266-635a41141eb1": "How should end-users and stakeholders be engaged according to Action ID MS-2.10-002?", "475efe48-be07-4aae-abd8-92ad16fa854e": "What procedures should be established for escalating GAI system incidents to the organizational risk management authority?", "cbfdb943-5e6f-4c4b-a2f8-35539fd69863": "What should be included in the procedures for the remediation of issues that trigger incident response processes for a GAI system?", "b6d56437-5d24-4007-afe7-69b49f9f6c73": "What criteria should be regularly reviewed to determine the deactivation of GAI systems?", "b491b5b2-5e21-4fdf-a697-bd2050bb9bdb": "What are the environmental impacts associated with high compute resource utilization in training or operating GAI models?", "0afa5f71-7277-4801-93e5-812c3a3116da": "How can harmful bias or homogenization in GAI models lead to performance disparities between sub-groups or languages?", "419c3bbe-a4e4-4178-b682-8017bf2140cf": "What are the potential risks of human-AI configurations that result in inappropriate anthropomorphizing of GAI systems?", "47826001-3209-479c-9033-fa3bb3e0ddd6": "What is the level of general awareness among end users about the availability of feedback channels?", "d3f36732-3d9b-4aff-bcfc-1ea6ee7f843a": "How does harmful bias and homogenization impact information integrity?", "c098aeb2-a72c-4b77-9d6e-05f9e321da17": "What tasks are associated with AI actors in the context of AI deployment and monitoring?", "2af79a43-b5b2-4bb5-8d5a-9dc478e4fe00": "What are some examples of technical or model risks mentioned in the context?", "846f3a62-4f70-4034-a31f-7d2679a7bd64": "How can risks be categorized according to the UK's International Scientific Report on the Safety of Advanced AI?", "aa846db3-9a0f-4138-942e-b7ef3f09a5e1": "Which risks are noted to be cross-cutting between the categories?", "05fd4fd9-8332-4bd4-9e11-2b456684a4f2": "What is the suggested action for Action ID GV-1.5-001?", "124b67ed-2d98-42a3-8472-b5035282aa76": "Which GAI risks are associated with Action ID GV-1.5-002?", "bb3cad94-d78e-4ce6-b2e9-45081ec6eaa4": "What is the purpose of maintaining a document retention policy according to Action ID GV-1.5-003?", "784201df-2700-4a0e-9347-d6f40b636f11": "What are the tasks associated with AI Actors?", "b8863080-b8db-446b-a501-a4edcb51f221": "What is the purpose of MEASURE 3.2?", "dae4461c-34bf-4895-a20d-120293c7a446": "What risks are associated with Action ID MS-3.2-001?", "e298c14d-86dd-4a22-acbb-46d1b4f2e648": "When was the document approved by the NIST Editorial Review Board?", "ad9aa4cf-125c-47d6-9eac-dbc97fe90088": "What is the email address provided for AI inquiries?", "82963cb3-94f5-4748-a17d-bd320935c464": "Where is the NIST AI Innovation Lab located?", "a66f7ee8-1e5e-443f-83d7-a94af0bc03b1": "What are some channels organizations can use to engage external stakeholders in product development?", "eaec2c71-3a3f-4256-84b7-0bbd63e705a5": "How can focus groups with select experts be beneficial in product development?", "ffffa160-a7f2-47ce-abbe-a707617c6be4": "Why are participatory engagement methods more commonly used in the early stages of AI or product development?", "13efa4fc-0cb2-482b-ab5e-cbb38e2dc6ff": "What are the intended purposes of the AI system?", "48e1531d-059b-4d04-a2d7-2f64d490c78c": "What are the potential positive and negative impacts of the AI system on society?", "9b6a5160-bac7-49f1-9e63-43f866c24c48": "What assumptions and limitations are considered regarding the AI system's purposes and uses?", "dfa565d6-439d-41de-844e-2081a044ca76": "What are some applications of GAI technologies?", "b278ee82-58e0-4937-9e94-7aed1a746de7": "How can provenance data tracking help manage risks associated with GAI outputs?", "f31ac39f-5651-4606-96a4-be1387b09aec": "What benefits do digital transparency mechanisms offer in the context of synthetic content detection?", "048c460e-fcae-4a0d-a761-e520e7005618": "What are the suggested actions for Action ID MS-2.8-001?", "6ea58544-5ac2-4383-b176-8f61d260d91c": "What GAI risks are associated with compiling statistics on policy violations and intellectual property infringement?", "a2a4ef05-9fd4-4f48-a200-82fa810cb395": "What is the purpose of using digital content transparency solutions in the context provided?", "cce86f1b-bc8f-4a3b-bb6c-a8283c357dd5": "What types of content are considered unacceptable according to GV-1.3-004?", "9a4a40a9-be7f-4376-b07b-a2f4d5b28390": "What is the purpose of maintaining an updated hierarchy of identified and expected GAI risks in GV-1.3-005?", "170e4285-e366-4c02-ab75-24771e2b683f": "What does GV-1.3-004 suggest obtaining input from stakeholder communities for?"}, "relevant_contexts": {"d6517df6-948c-4925-90de-b3da4181a372": "44c8f1d3-0b06-46c4-9809-b4f3ebcb886e", "4595b2b3-3b24-4019-9db7-e13e5ab60fa8": "44c8f1d3-0b06-46c4-9809-b4f3ebcb886e", "9abe004c-cf87-4ef0-8245-2cc27d88fa85": "44c8f1d3-0b06-46c4-9809-b4f3ebcb886e", "31cc0ed6-cf56-45eb-b3c6-48b68713fd7b": "a6d85d9c-63a1-43fa-9b78-6a5669639630", "6ee39258-c357-4766-b645-7f39ca88ec27": "a6d85d9c-63a1-43fa-9b78-6a5669639630", "6c6d2106-feb6-4306-b921-b41097e00e73": "a6d85d9c-63a1-43fa-9b78-6a5669639630", "ba422246-d5f0-4046-8c35-6c878ed6238c": "254f6096-437a-49f5-8a6c-e2edb26f6d5b", "b9b12676-5084-4ae8-9968-fc0f45fb4597": "254f6096-437a-49f5-8a6c-e2edb26f6d5b", "40ed98b8-cb05-491f-a61a-b0d567ae8b88": "254f6096-437a-49f5-8a6c-e2edb26f6d5b", "d55e461c-6123-4a95-86ef-ece6d78f53c1": "5896a847-b260-405c-96d5-d5b99c8a0fc1", "b8e4cf73-125c-49b3-bd82-a8dbd208a20b": "5896a847-b260-405c-96d5-d5b99c8a0fc1", "3aaca092-1b77-451f-811f-bb9a9b67c71f": "5896a847-b260-405c-96d5-d5b99c8a0fc1", "9c882f36-6793-416f-bcc4-06d9b274803e": "41d23455-d964-46b0-9ae2-ad1160677824", "dc7a108f-88e6-4a35-a7bf-85738a615c5b": "41d23455-d964-46b0-9ae2-ad1160677824", "e6e8bd65-4719-427a-a9ab-49ac2c983f49": "41d23455-d964-46b0-9ae2-ad1160677824", "1eed1f03-df2c-4d3c-82ed-e52d3caafd12": "cd83d5b7-ac46-4f9a-aaba-515da32322c0", "c51759c9-c57c-4fda-904d-c66b6df747cc": "cd83d5b7-ac46-4f9a-aaba-515da32322c0", "f88691fb-cf3d-45ad-accc-0477cd4d93df": "cd83d5b7-ac46-4f9a-aaba-515da32322c0", "28a72b48-0642-47ef-9eb9-31ea770f8d19": "fa52de3d-14e6-4ed0-8bf4-15825a9c9236", "3361a2a3-3f79-4081-b577-ec899d1f2a93": "fa52de3d-14e6-4ed0-8bf4-15825a9c9236", "4cb47a63-e325-4bdc-82e3-d2a1e641cb21": "fa52de3d-14e6-4ed0-8bf4-15825a9c9236", "b7ea996a-f887-49e6-b402-002e2d98a19b": "c64fe60e-1f15-4512-a761-77929babfd79", "7225122f-6ef0-4c73-a300-6ca046f16c25": "c64fe60e-1f15-4512-a761-77929babfd79", "65a2994d-1236-47a3-a5d6-d165494a0ca7": "c64fe60e-1f15-4512-a761-77929babfd79", "22904442-a36b-4d4b-8139-7669a7a98ab7": "34e472f7-a091-42cf-bbd0-b7f026cbef0e", "2edd683a-6abc-441f-bbd5-c74d45362563": "34e472f7-a091-42cf-bbd0-b7f026cbef0e", "f97b5827-d672-4ec1-988a-f17fc3d13b53": "34e472f7-a091-42cf-bbd0-b7f026cbef0e", "cf4eb38e-31cc-48a6-9c93-c1235d79f3a0": "edbd8841-e509-470c-8486-76d43f8b6e13", "af05be4a-3359-423a-8407-d26fa37e645f": "edbd8841-e509-470c-8486-76d43f8b6e13", "96ee6704-3ba2-442d-8919-dca2b4940473": "edbd8841-e509-470c-8486-76d43f8b6e13", "8c6abb69-3223-4588-bfe3-34f9a7e9a280": "f0288cff-2c91-49b7-979a-750fde3141d5", "076252f4-ad82-45fa-8051-88a6f761f293": "f0288cff-2c91-49b7-979a-750fde3141d5", "9c52a885-c91c-4045-9c82-387a4689b0f3": "f0288cff-2c91-49b7-979a-750fde3141d5", "969fba7c-8c7b-4632-8fd6-6cc65bcbe156": "5af90274-c7f4-49ab-947a-10d427dd211e", "628781d3-f4a4-4f06-904d-107e288f675e": "5af90274-c7f4-49ab-947a-10d427dd211e", "ebbd8787-d95b-4771-a0cb-27ad9837ab8c": "5af90274-c7f4-49ab-947a-10d427dd211e", "1f500a4f-9096-4396-b70b-297559ef0cea": "06de2a0b-167a-43ff-87c2-7fd0b2e964ad", "0e13916f-8a0e-4036-aa27-85d3475e2d1c": "06de2a0b-167a-43ff-87c2-7fd0b2e964ad", "f71eefd5-10bc-447e-ba07-79ba4992613e": "06de2a0b-167a-43ff-87c2-7fd0b2e964ad", "8e17e3a0-ae22-4363-bf7e-8895d958ea9b": "62e29775-73a7-44a5-b32a-270c2e34f476", "10e097e9-8948-4506-9d72-eaf9d4718700": "62e29775-73a7-44a5-b32a-270c2e34f476", "d0ddf446-73b2-4c58-b38d-7d4cc5bfdf72": "62e29775-73a7-44a5-b32a-270c2e34f476", "64b61f37-267e-484a-a6fa-60adca25e747": "f6d9383e-15ef-4e85-b9ec-7ab25cb97dd1", "bfaf6c91-2f4d-4da9-965f-72c017834be5": "f6d9383e-15ef-4e85-b9ec-7ab25cb97dd1", "84efbc2f-209f-4ae8-844f-4f6722ad953a": "f6d9383e-15ef-4e85-b9ec-7ab25cb97dd1", "318f9cf4-7f4e-4468-9c98-ce162b1e6059": "e94490ee-4d93-4f90-bf89-a6fe7e87aa94", "8bafe347-8dcf-4860-9483-04888421b404": "e94490ee-4d93-4f90-bf89-a6fe7e87aa94", "4692e0f5-5b1b-4d69-89b3-3e03887eb7e8": "e94490ee-4d93-4f90-bf89-a6fe7e87aa94", "08828efb-d09a-400b-ab12-269ae528db7a": "7a0eee2c-2daa-4110-b9b4-4a5c62c0932e", "2f75b55a-2cc7-47dc-85f6-f7e5602e32a4": "7a0eee2c-2daa-4110-b9b4-4a5c62c0932e", "517dc5f3-d485-46b4-a266-635a41141eb1": "7a0eee2c-2daa-4110-b9b4-4a5c62c0932e", "475efe48-be07-4aae-abd8-92ad16fa854e": "599e6cb1-1d0f-411a-9e9a-44fff27500d1", "cbfdb943-5e6f-4c4b-a2f8-35539fd69863": "599e6cb1-1d0f-411a-9e9a-44fff27500d1", "b6d56437-5d24-4007-afe7-69b49f9f6c73": "599e6cb1-1d0f-411a-9e9a-44fff27500d1", "b491b5b2-5e21-4fdf-a697-bd2050bb9bdb": "85272ca3-46f9-4ae6-986e-b75c13ca58ec", "0afa5f71-7277-4801-93e5-812c3a3116da": "85272ca3-46f9-4ae6-986e-b75c13ca58ec", "419c3bbe-a4e4-4178-b682-8017bf2140cf": "85272ca3-46f9-4ae6-986e-b75c13ca58ec", "47826001-3209-479c-9033-fa3bb3e0ddd6": "3dd2a354-f6bb-4385-9ff4-d9a8a61b3576", "d3f36732-3d9b-4aff-bcfc-1ea6ee7f843a": "3dd2a354-f6bb-4385-9ff4-d9a8a61b3576", "c098aeb2-a72c-4b77-9d6e-05f9e321da17": "3dd2a354-f6bb-4385-9ff4-d9a8a61b3576", "2af79a43-b5b2-4bb5-8d5a-9dc478e4fe00": "d6176aea-00f9-48a2-8e42-99fe89831f90", "846f3a62-4f70-4034-a31f-7d2679a7bd64": "d6176aea-00f9-48a2-8e42-99fe89831f90", "aa846db3-9a0f-4138-942e-b7ef3f09a5e1": "d6176aea-00f9-48a2-8e42-99fe89831f90", "05fd4fd9-8332-4bd4-9e11-2b456684a4f2": "d1db7dc5-0c2f-420b-b936-db71c146c427", "124b67ed-2d98-42a3-8472-b5035282aa76": "d1db7dc5-0c2f-420b-b936-db71c146c427", "bb3cad94-d78e-4ce6-b2e9-45081ec6eaa4": "d1db7dc5-0c2f-420b-b936-db71c146c427", "784201df-2700-4a0e-9347-d6f40b636f11": "d3da79b8-d902-4894-a8b8-3a747421f548", "b8863080-b8db-446b-a501-a4edcb51f221": "d3da79b8-d902-4894-a8b8-3a747421f548", "dae4461c-34bf-4895-a20d-120293c7a446": "d3da79b8-d902-4894-a8b8-3a747421f548", "e298c14d-86dd-4a22-acbb-46d1b4f2e648": "085932fd-0d16-4c90-863c-3f2d8e443562", "ad9aa4cf-125c-47d6-9eac-dbc97fe90088": "085932fd-0d16-4c90-863c-3f2d8e443562", "82963cb3-94f5-4748-a17d-bd320935c464": "085932fd-0d16-4c90-863c-3f2d8e443562", "a66f7ee8-1e5e-443f-83d7-a94af0bc03b1": "4bd0d204-f2e2-4ceb-9437-a2503c43a03f", "eaec2c71-3a3f-4256-84b7-0bbd63e705a5": "4bd0d204-f2e2-4ceb-9437-a2503c43a03f", "ffffa160-a7f2-47ce-abbe-a707617c6be4": "4bd0d204-f2e2-4ceb-9437-a2503c43a03f", "13efa4fc-0cb2-482b-ab5e-cbb38e2dc6ff": "4e3f0493-fb4e-4a01-a83a-3115e7fc0f5f", "48e1531d-059b-4d04-a2d7-2f64d490c78c": "4e3f0493-fb4e-4a01-a83a-3115e7fc0f5f", "9b6a5160-bac7-49f1-9e63-43f866c24c48": "4e3f0493-fb4e-4a01-a83a-3115e7fc0f5f", "dfa565d6-439d-41de-844e-2081a044ca76": "741b00c5-37ba-4178-808f-8d89cb8966cf", "b278ee82-58e0-4937-9e94-7aed1a746de7": "741b00c5-37ba-4178-808f-8d89cb8966cf", "f31ac39f-5651-4606-96a4-be1387b09aec": "741b00c5-37ba-4178-808f-8d89cb8966cf", "048c460e-fcae-4a0d-a761-e520e7005618": "4111ca99-5ec3-49e3-b62d-e49228b4e48c", "6ea58544-5ac2-4383-b176-8f61d260d91c": "4111ca99-5ec3-49e3-b62d-e49228b4e48c", "a2a4ef05-9fd4-4f48-a200-82fa810cb395": "4111ca99-5ec3-49e3-b62d-e49228b4e48c", "cce86f1b-bc8f-4a3b-bb6c-a8283c357dd5": "882050c3-63df-4793-b31f-42234fddbdf7", "9a4a40a9-be7f-4376-b07b-a2f4d5b28390": "882050c3-63df-4793-b31f-42234fddbdf7", "170e4285-e366-4c02-ab75-24771e2b683f": "882050c3-63df-4793-b31f-42234fddbdf7"}, "corpus": {"06de2a0b-167a-43ff-87c2-7fd0b2e964ad": "\\begin{center}\n\\begin{tabular}{|c|c|c|}\n\\hline\nMP-1.1-002 & \\begin{tabular}{l}\nDetermine and document the expected and acceptable GAI system context of \\\\\nuse in collaboration with socio-cultural and other domain experts, by assessing: \\\\\nAssumptions and limitations; Direct value to the organization; Intended \\\\\noperational environment and observed usage patterns; Potential positive and \\\\\nnegative impacts to individuals, public safety, groups, communities, \\\\\norganizations, democratic institutions, and the physical environment; Social \\\\\nnorms and expectations. \\\\\n\\end{tabular} & Harmful Bias and Homogenization \\\\\n\\hline\nMP-1.1-003 & \\begin{tabular}{l}\nDocument risk measurement plans to address identified risks. Plans may \\\\\ninclude, as applicable: Individual and group cognitive biases (e.g., confirmation \\\\\nbias, funding bias, groupthink) for AI Actors involved in the design, \\\\\nimplementation, and use of GAI systems; Known past GAI system incidents and \\\\", "44c8f1d3-0b06-46c4-9809-b4f3ebcb886e": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nGV-4.1-003 & \\begin{tabular}{l}\nEstablish policies, procedures, and processes for oversight functions (e.g., senior \\\\\nleadership, legal, compliance, including internal evaluation) across the GAI \\\\\nlifecycle, from problem formulation and supply chains to system decommission. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nValue Chain and Component \\\\\nIntegration \\\\\n\\end{tabular} \\\\\n\\hline\nAI Actor Tasks: AI Deployment, AI Design, AI Development, Operation and Monitoring &  &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}\n\nGOVERN 4.2: Organizational teams document the risks and potential impacts of the Al technology they design, develop, deploy, evaluate, and use, and they communicate about the impacts more broadly.", "c64fe60e-1f15-4512-a761-77929babfd79": "\\end{tabular} & \\begin{tabular}{l}\nHuman-Al Configuration; Harmful \\\\\nBias and Homogenization \\\\\n\\end{tabular} \\\\\n\\hline\nAI Actor Tasks: Al Deployment &  &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "d3da79b8-d902-4894-a8b8-3a747421f548": "AI Actor Tasks: AI Deployment, Operation and Monitoring, TEVV\n\nMEASURE 3.2: Risk tracking approaches are considered for settings where Al risks are difficult to assess using currently available measurement techniques or where metrics are not yet available.\n\n\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMS-3.2-001 & \\begin{tabular}{l}\nEstablish processes for identifying emergent GAI system risks including \\\\\nconsulting with external AI Actors. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-AI Configuration; \\\\\nConfabulation \\\\\n\\end{tabular} \\\\\n\\hline\n\\end{tabular}\n\\end{center}\n\nAl Actor Tasks: Al Impact Assessment, Domain Experts, Operation and Monitoring, TEVV\n\nMEASURE 3.3: Feedback processes for end users and impacted communities to report problems and appeal system outcomes are established and integrated into Al system evaluation metrics.", "a6d85d9c-63a1-43fa-9b78-6a5669639630": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMP-3.4-001 & \\begin{tabular}{l}\nEvaluate whether GAI operators and end-users can accurately understand \\\\\ncontent lineage and origin. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-AI Configuration; \\\\\nInformation Integrity \\\\\n\\end{tabular} \\\\\n\\hline\nMP-3.4-002 & \\begin{tabular}{l}\nAdapt existing training programs to include modules on digital content \\\\\ntransparency. \\\\\n\\end{tabular} & Information Integrity \\\\\n\\hline\nMP-3.4-003 & \\begin{tabular}{l}\nDevelop certification programs that test proficiency in managing GAI risks and \\\\\ninterpreting content provenance, relevant to specific industry and context. \\\\\n\\end{tabular} & Information Integrity \\\\\n\\hline\nMP-3.4-004 & Delineate human proficiency tests from tests of GAI capabilities. & Human-AI Configuration \\\\\n\\hline\nMP-3.4-005 & \\begin{tabular}{l}\nImplement systems to continually monitor and track the outcomes of human-GAI \\\\", "5896a847-b260-405c-96d5-d5b99c8a0fc1": "National Institue of Standards and Technology (2022) Towards a Standard for Identifying and Managing Bias in Artificial Intelligence \\href{https://www.nist.gov/publications/towards-standard-identifying-andmanaging-bias-artificial-intelligence}{https://www.nist.gov/publications/towards-standard-identifying-andmanaging-bias-artificial-intelligence}\n\nNorthcutt, C. et al. (2021) Pervasive Label Errors in Test Sets Destabilize Machine Learning Benchmarks. arXiv. \\href{https://arxiv.org/pdf/2103.14749}{https://arxiv.org/pdf/2103.14749}", "f0288cff-2c91-49b7-979a-750fde3141d5": "MANAGE 2.2: Mechanisms are in place and applied to sustain the value of deployed Al systems.", "85272ca3-46f9-4ae6-986e-b75c13ca58ec": "\\item Environmental Impacts: Impacts due to high compute resource utilization in training or operating GAI models, and related outcomes that may adversely impact ecosystems.\n  \\item Harmful Bias or Homogenization: Amplification and exacerbation of historical, societal, and systemic biases; performance disparities ${ }^{8}$ between sub-groups or languages, possibly due to non-representative training data, that result in discrimination, amplification of biases, or incorrect presumptions about performance; undesired homogeneity that skews system or model outputs, which may be erroneous, lead to ill-founded decision-making, or amplify harmful biases.\n  \\item Human-AI Configuration: Arrangements of or interactions between a human and an AI system which can result in the human inappropriately anthropomorphizing GAI systems or experiencing algorithmic aversion, automation bias, over-reliance, or emotional entanglement with GAI systems.", "41d23455-d964-46b0-9ae2-ad1160677824": "Current estimates suggest that training a single transformer LLM can emit as much carbon as 300 roundtrip flights between San Francisco and New York. In a study comparing energy consumption and carbon emissions for LLM inference, generative tasks (e.g., text summarization) were found to be more energyand carbon-intensive than discriminative or non-generative tasks (e.g., text classification).\n\nMethods for creating smaller versions of trained models, such as model distillation or compression, could reduce environmental impacts at inference time, but training and tuning such models may still contribute to their environmental impacts. Currently there is no agreed upon method to estimate environmental impacts from GAI.", "f6d9383e-15ef-4e85-b9ec-7ab25cb97dd1": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nMG-3.2-007 & \\begin{tabular}{l}\nLeverage feedback and recommendations from organizational boards or \\\\\ncommittees related to the deployment of GAI applications and content \\\\\nprovenance when using third-party pre-trained models. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity; Value Chain \\\\\nand Component Integration \\\\\n\\end{tabular} \\\\\n\\hline\nMG-3.2-008 & \\begin{tabular}{l}\nUse human moderation systems where appropriate to review generated content \\\\\nin accordance with human-Al configuration policies established in the Govern \\\\\nfunction, aligned with socio-cultural norms in the context of use, and for settings \\\\\nwhere Al models are demonstrated to perform poorly. \\\\\n\\end{tabular} & Human-Al Configuration \\\\\n\\hline\nMG-3.2-009 & \\begin{tabular}{l}\nUse organizational risk tolerance to evaluate acceptable risks and performance \\\\\nmetrics and decommission or retrain pre-trained models that perform outside of \\\\", "edbd8841-e509-470c-8486-76d43f8b6e13": "National Institute of Standards and Technology (2023) AI Risk Management Framework, Chapter 3: AI Risks and Trustworthiness.\\\\\n\\href{https://airc.nist.gov/AI}{https://airc.nist.gov/AI} RMF Knowledge Base/AI RMF/Foundational Information/3-sec-characteristics\\\\\nNational Institute of Standards and Technology (2023) AI Risk Management Framework, Chapter 6: AI RMF Profiles. \\href{https://airc.nist.gov/AI}{https://airc.nist.gov/AI} RMF Knowledge Base/AI RMF/Core And Profiles/6-sec-profile National Institute of Standards and Technology (2023) AI Risk Management Framework, Appendix A: Descriptions of AI Actor Tasks.\\\\\n\\href{https://airc.nist.gov/AI}{https://airc.nist.gov/AI} RMF Knowledge Base/AI RMF/Appendices/Appendix A\\#: :text=Al\\%20actors\\% 20in\\%20this\\%20category,data\\%20providers\\%2C\\%20system\\%20funders\\%2C\\%20product", "cd83d5b7-ac46-4f9a-aaba-515da32322c0": "For instance, prompt injection involves modifying what input is provided to a GAI system so that it behaves in unintended ways. In direct prompt injections, attackers might craft malicious prompts and input them directly to a GAI system, with a variety of downstream negative consequences to interconnected systems. Indirect prompt injection attacks occur when adversaries remotely (i.e., without a direct interface) exploit LLM-integrated applications by injecting prompts into data likely to be retrieved. Security researchers have already demonstrated how indirect prompt injections can exploit vulnerabilities by stealing proprietary data or running malicious code remotely on a machine. Merely querying a closed production model can elicit previously undisclosed information about that model.", "5af90274-c7f4-49ab-947a-10d427dd211e": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMS-1.3-001 & \\begin{tabular}{l}\nDefine relevant groups of interest (e.g., demographic groups, subject matter \\\\\nexperts, experience with GAI technology) within the context of use as part of \\\\\nplans for gathering structured public feedback. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-AI Configuration; Harmful \\\\\nBias and Homogenization; CBRN \\\\\nInformation or Capabilities \\\\\n\\end{tabular} \\\\\n\\hline\nMS-1.3-002 & \\begin{tabular}{l}\nEngage in internal and external evaluations, GAI red-teaming, impact \\\\\nassessments, or other structured human feedback exercises in consultation \\\\\nwith representative AI Actors with expertise and familiarity in the context of \\\\\nuse, and/or who are representative of the populations associated with the \\\\\ncontext of use. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-AI Configuration; Harmful \\\\\nBias and Homogenization; CBRN \\\\\nInformation or Capabilities \\\\", "d1db7dc5-0c2f-420b-b936-db71c146c427": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nGV-1.5-001 & \\begin{tabular}{l}\nDefine organizational responsibilities for periodic review of content provenance \\\\\nand incident monitoring for GAI systems. \\\\\n\\end{tabular} & Information Integrity \\\\\n\\hline\nGV-1.5-002 & \\begin{tabular}{l}\nEstablish organizational policies and procedures for after action reviews of GAI \\\\\nsystem incident response and incident disclosures, to identify gaps; Update \\\\\nincident response and incident disclosure processes as required. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-AI Configuration; \\\\\nInformation Security \\\\\n\\end{tabular} \\\\\n\\hline\nGV-1.5-003 & \\begin{tabular}{l}\nMaintain a document retention policy to keep history for test, evaluation, \\\\\nvalidation, and verification (TEVV), and digital content transparency methods for \\\\\nGAI. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity; Intellectual \\\\\nProperty \\\\\n\\end{tabular} \\\\\n\\hline", "4111ca99-5ec3-49e3-b62d-e49228b4e48c": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMS-2.8-001 & \\begin{tabular}{l}\nCompile statistics on actual policy violations, take-down requests, and intellectual \\\\\nproperty infringement for organizational GAI systems: Analyze transparency \\\\\nreports across demographic groups, languages groups. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nIntellectual Property; Harmful Bias \\\\\nand Homogenization \\\\\n\\end{tabular} \\\\\n\\hline\nMS-2.8-002 & Document the instructions given to data annotators or Al red-teamers. & Human-AI Configuration \\\\\n\\hline\n & \\begin{tabular}{l}\nUse digital content transparency solutions to enable the documentation of each \\\\\ninstance where content is generated, modified, or shared to provide a tamper- \\\\\nproof history of the content, promote transparency, and enable traceability. \\\\\nRobust version control systems can also be applied to track changes across the AI \\\\\nlifecycle over time. \\\\", "e94490ee-4d93-4f90-bf89-a6fe7e87aa94": "party GAI models. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nValue Chain and Component \\\\\nIntegration; Intellectual Property \\\\\n\\end{tabular} \\\\\n\\hline\nMG-3.1-002 & \\begin{tabular}{l}\nTest GAI system value chain risks (e.g., data poisoning, malware, other software \\\\\nand hardware vulnerabilities; labor practices; data privacy and localization \\\\\ncompliance; geopolitical alignment). \\\\\n\\end{tabular} & \\begin{tabular}{l}\nData Privacy; Information Security; \\\\\nValue Chain and Component \\\\\nIntegration; Harmful Bias and \\\\\nHomogenization \\\\\n\\end{tabular} \\\\\n\\hline\nMG-3.1-003 & \\begin{tabular}{l}\nRe-assess model risks after fine-tuning or retrieval-augmented generation \\\\\nimplementation and for any third-party GAI models deployed for applications \\\\\nand/or use cases that were not evaluated in initial testing. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nValue Chain and Component \\\\\nIntegration \\\\\n\\end{tabular} \\\\\n\\hline\nMG-3.1-004 & \\begin{tabular}{l}", "254f6096-437a-49f5-8a6c-e2edb26f6d5b": "Al Actor Tasks: Governance and Oversight, Operation and Monitoring\n\nGOVERN 1.6: Mechanisms are in place to inventory AI systems and are resourced according to organizational risk priorities.", "62e29775-73a7-44a5-b32a-270c2e34f476": "\\begin{center}\n\\begin{tabular}{|c|c|c|}\n\\hline\nMG-4.3-003 & \\begin{tabular}{l}\nReport GAI incidents in compliance with legal and regulatory requirements (e.g., \\\\\nHIPAA breach reporting, e.g., OCR (2023) or NHTSA (2022) autonomous vehicle \\\\\ncrash reporting requirements. \\\\\n\\end{tabular} & Information Security; Data Privacy \\\\\n\\hline\n\\end{tabular}\n\\end{center}\n\\section*{Appendix A. Primary GAI Considerations}\nThe following primary considerations were derived as overarching themes from the GAI PWG consultation process. These considerations (Governance, Pre-Deployment Testing, Content Provenance, and Incident Disclosure) are relevant for voluntary use by any organization designing, developing, and using GAI and also inform the Actions to Manage GAI risks. Information included about the primary considerations is not exhaustive, but highlights the most relevant topics derived from the GAI PWG.", "3dd2a354-f6bb-4385-9ff4-d9a8a61b3576": "Assess the general awareness among end users and impacted communities \\\\\nabout the availability of these feedback channels. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-AI Configuration; \\\\\nInformation Integrity; Harmful Bias \\\\\nand Homogenization \\\\\n\\end{tabular} \\\\\n\\hline\nAI Actor Tasks: AI Deployment, Affected Individuals and Communities, End-Users, Operation and Monitoring, TEVV &  &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "599e6cb1-1d0f-411a-9e9a-44fff27500d1": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nMG-2.4-002 & \\begin{tabular}{l}\nEstablish and maintain procedures for escalating GAI system incidents to the \\\\\norganizational risk management authority when specific criteria for deactivation \\\\\nor disengagement is met for a particular context of use or for the GAI system as a \\\\\nwhole. \\\\\n\\end{tabular} & Information Security \\\\\n\\hline\nMG-2.4-003 & \\begin{tabular}{l}\nEstablish and maintain procedures for the remediation of issues which trigger \\\\\nincident response processes for the use of a GAI system, and provide stakeholders \\\\\ntimelines associated with the remediation plan. \\\\\n\\end{tabular} & Information Security \\\\\n\\hline\nMG-2.4-004 & \\begin{tabular}{l}\nEstablish and regularly review specific criteria that warrants the deactivation of \\\\\nGAI systems in accordance with set risk tolerances and appetites. \\\\\n\\end{tabular} & Information Security \\\\\n\\hline", "34e472f7-a091-42cf-bbd0-b7f026cbef0e": "Harmful bias in GAI systems can also lead to harms via disparities between how a model performs for different subgroups or languages (e.g., an LLM may perform less well for non-English languages or certain dialects). Such disparities can contribute to discriminatory decision-making or amplification of existing societal biases. In addition, GAI systems may be inappropriately trusted to perform similarly across all subgroups, which could leave the groups facing underperformance with worse outcomes than if no GAI system were used. Disparate or reduced performance for lower-resource languages also presents challenges to model adoption, inclusion, and accessibility, and may make preservation of endangered languages more difficult if GAI systems become embedded in everyday processes that would otherwise have been opportunities to use these languages.", "fa52de3d-14e6-4ed0-8bf4-15825a9c9236": "Data used for training GAI models may unintentionally include CSAM and NCII. A recent report noted that several commonly used GAI training datasets were found to contain hundreds of known images of\n\nCSAM. Even when trained on \"clean\" data, increasingly capable GAI models can synthesize or produce synthetic NCII and CSAM. Websites, mobile apps, and custom-built models that generate synthetic NCII have moved from niche internet forums to mainstream, automated, and scaled online businesses.", "7a0eee2c-2daa-4110-b9b4-4a5c62c0932e": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMS-2.10-001 & \\begin{tabular}{l}\nConduct Al red-teaming to assess issues such as: Outputting of training data \\\\\nsamples, and subsequent reverse engineering, model extraction, and \\\\\nmembership inference risks; Revealing biometric, confidential, copyrighted, \\\\\nlicensed, patented, personal, proprietary, sensitive, or trade-marked information; \\\\\nTracking or revealing location information of users or members of training \\\\\ndatasets. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-Al Configuration; \\\\\nInformation Integrity; Intellectual \\\\\nProperty \\\\\n\\end{tabular} \\\\\n\\hline\nMS-2.10-002 & \\begin{tabular}{l}\nEngage directly with end-users and other stakeholders to understand their \\\\\nexpectations and concerns regarding content provenance. Use this feedback to \\\\\nguide the design of provenance data-tracking techniques. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-Al Configuration; \\\\", "882050c3-63df-4793-b31f-42234fddbdf7": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nGV-1.3-004 & \\begin{tabular}{l}\nObtain input from stakeholder communities to identify unacceptable use, in \\\\\naccordance with activities in the AI RMF Map function. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nCBRN Information or Capabilities; \\\\\nObscene, Degrading, and/or \\\\\nAbusive Content; Harmful Bias \\\\\nand Homogenization; Dangerous, \\\\\nViolent, or Hateful Content \\\\\n\\end{tabular} \\\\\n\\hline\nGV-1.3-005 & \\begin{tabular}{l}\nMaintain an updated hierarchy of identified and expected GAI risks connected to \\\\\ncontexts of GAI model advancement and use, potentially including specialized risk \\\\\nlevels for GAI systems that address issues such as model collapse and algorithmic \\\\\nmonoculture. \\\\\n\\end{tabular} & Harmful Bias and Homogenization \\\\\n\\hline\nGV-1.3-006 & \\begin{tabular}{l}\nReevaluate organizational risk tolerances to account for unacceptable negative risk \\\\\n(such as where significant negative impacts are imminent, severe harms are \\\\", "d6176aea-00f9-48a2-8e42-99fe89831f90": "\\footnotetext{${ }^{5}$ These risks can be further categorized by organizations depending on their unique approaches to risk definition and management. One possible way to further categorize these risks, derived in part from the UK's International Scientific Report on the Safety of Advanced AI, could be: 1) Technical / Model risks (or risk from malfunction): Confabulation; Dangerous or Violent Recommendations; Data Privacy; Value Chain and Component Integration; Harmful Bias, and Homogenization; 2) Misuse by humans (or malicious use): CBRN Information or Capabilities; Data Privacy; Human-Al Configuration; Obscene, Degrading, and/or Abusive Content; Information Integrity; Information Security; 3) Ecosystem / societal risks (or systemic risks): Data Privacy; Environmental; Intellectual Property. We also note that some risks are cross-cutting between these categories.\n}\\begin{enumerate}", "085932fd-0d16-4c90-863c-3f2d8e443562": "\\subsubsection*{\\section{Publication History}\n}\n Approved by the NIST Editorial Review Board on 07-25-2024 \n\\subsubsection*{\\section{Contact Information}\n}\n \\href{mailto:ai-inquiries@nist.gov}{ai-inquiries@nist.gov} National Institute of Standards and Technology Attn: NIST AI Innovation Lab, Information Technology Laboratory 100 Bureau Drive (Mail Stop 8900) Gaithersburg, MD 20899-8900 \n\\subsubsection*{\\section{Additional Information}\n}", "4e3f0493-fb4e-4a01-a83a-3115e7fc0f5f": "MAP 1.1: Intended purposes, potentially beneficial uses, context specific laws, norms and expectations, and prospective settings in which the Al system will be deployed are understood and documented. Considerations include: the specific set or types of users along with their expectations; potential positive and negative impacts of system uses to individuals, communities, organizations, society, and the planet; assumptions and related limitations about Al system purposes, uses, and risks across the development or product Al lifecycle; and related TEVV and system metrics.", "4bd0d204-f2e2-4ceb-9437-a2503c43a03f": "\\section*{Participatory Engagement Methods}\nOn an ad hoc or more structured basis, organizations can design and use a variety of channels to engage external stakeholders in product development or review. Focus groups with select experts can provide feedback on a range of issues. Small user studies can provide feedback from representative groups or populations. Anonymous surveys can be used to poll or gauge reactions to specific features. Participatory engagement methods are often less structured than field testing or red teaming, and are more commonly used in early stages of AI or product development.\n\\section*{Field Testing}", "741b00c5-37ba-4178-808f-8d89cb8966cf": "GAI technologies can be leveraged for many applications such as content generation and synthetic data. Some aspects of GAI outputs, such as the production of deepfake content, can challenge our ability to distinguish human-generated content from Al-generated synthetic content. To help manage and mitigate these risks, digital transparency mechanisms like provenance data tracking can trace the origin and history of content. Provenance data tracking and synthetic content detection can help facilitate greater information access about both authentic and synthetic content to users, enabling better knowledge of trustworthiness in Al systems. When combined with other organizational accountability mechanisms, digital content transparency approaches can enable processes to trace negative outcomes back to their source, improve information integrity, and uphold public trust. Provenance data tracking and synthetic content detection mechanisms provide information about the origin and history of"}}