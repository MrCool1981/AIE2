{"questions": {"9c2d9eb5-a293-4e0c-b122-bd1963daab3a": "What are the characteristics of trustworthy AI?", "6895a425-eb3f-47b9-848e-add92d6d5c70": "How are the characteristics of trustworthy AI integrated into organizational policies?", "ec07c62b-dd53-4fb3-9cb8-74f4301708be": "Why is it important to integrate trustworthy AI characteristics into organizational processes?", "f4e85515-03ae-4587-8b59-ede9b6951b56": "What is the purpose of robust version control systems in the AI lifecycle?", "e1555b40-d296-4353-80ff-0934d5c77a24": "How can the adequacy of GAI system user instructions be verified?", "e558ad70-d5d4-4a18-aabf-4fca7146f26e": "What are some of the AI actor tasks mentioned?", "60059c6b-aae8-495f-b957-187ecab02a98": "What are the methods used to monitor risks from third-party resources?", "55c94c94-fe71-469c-8069-a76dc273c082": "How are risk controls documented for third-party resources?", "d2aa9c8c-4a6a-4617-913c-6fe65da6d8d8": "What benefits are associated with using third-party resources?", "0e454dac-e4b8-4c15-963a-78ce685cb1be": "What are the suggested actions for ensuring information integrity in the AI system?", "2c565955-fb27-4341-b4ab-02ca5f72411b": "What risks are associated with instituting test and evaluation for data and content flows within the GAI system?", "ceb69d60-277e-45f4-b019-73bbe3be3a37": "What does the action ID MP-2.1-001 aim to establish for documentation and evaluation purposes?", "f8e693c5-774f-48db-9bb2-26acfd3b001e": "What does CBRN stand for in the context of information or capabilities?", "2fc8e679-8689-4414-91b1-69172387bf93": "What types of content are considered dangerous, violent, or hateful?", "37585477-079c-41d6-8479-65305bf47de2": "What is meant by obscene, degrading, and/or abusive content?", "18df8820-99f0-438d-b552-97b4cb30ba7f": "What are the methods used to compare GAI system security features against industry standards?", "0fcd8cbe-c85a-40fa-a506-553b43538286": "How can user surveys help in understanding user satisfaction with AI-generated content?", "16ef7147-44f5-46be-bb2e-f17de1efe333": "What metrics can be used to reflect the effectiveness of security measures?", "6e5226a7-0b66-453e-950c-5e4b45f79023": "What are the current methods for reporting AI incidents?", "211c49fb-d396-49d2-abb6-73b44d8fb117": "How do publicly available databases decide which AI incidents to track?", "c98afcc3-e2c7-47ee-af29-d77acdd96eb4": "Why is there a need for formal channels to report AI incidents?", "1100972a-045d-432d-aa65-8777dcb7e9bd": "What are the legal and regulatory requirements involving AI that need to be understood, managed, and documented?", "962d0a12-b61b-4462-8bf0-c9e8f8e7e718": "What are the suggested actions to align GAI development with applicable laws and regulations?", "198f5c5d-4180-4d7b-ba10-55d826cab6ec": "Who are considered AI Actors according to the OECD?", "0ab39737-8311-4850-94eb-f8496c6462e4": "What is 'jailbreaking' in the context of model outputs?", "e83ba326-4d25-4dd0-994f-3c02783efcfa": "Why might limitations of GAI systems be harmful or dangerous?", "8a936339-3d9f-4e30-a7b9-dfdc16d126b5": "How do users typically react to unhelpful responses from chatbots during distressing situations?", "563bed35-13a2-4b9f-bb2c-abb2d9310e93": "What does risk refer to in the context of the AI RMF?", "2b640898-9b6d-41e9-bd84-d7b70770324c": "How can some risks be assessed as likely to materialize?", "02bf410c-b4fc-4869-a4f5-3aeb9267eefc": "What factors contribute to the uncertainty of some risks materializing?", "a57029a1-d4fb-4f93-bd24-7e84dec626fb": "What should be done when the negative risk of fine-tuned models exceeds organizational risk tolerance?", "000f37af-82c2-4945-80c8-dbdd54fc1ae5": "What types of content are considered dangerous, violent, or hateful?", "d5c07b66-05db-4ba9-8052-c6fb7ee46352": "Why is it important to review GAI system outputs for validity and safety?", "87f0655e-7ea5-4466-8845-80ca99b15e61": "What protocols are suggested to ensure GAI systems can be deactivated when necessary?", "3adf278b-8d40-4fae-afc2-5f8cae71f093": "What factors should be considered when decommissioning GAI systems?", "6af2c5c6-ac26-4796-ad18-fea1310d7e0b": "How should data security be managed during the decommissioning of GAI systems?", "62d5e2c8-2dde-479c-8d43-f0fc4336748a": "What are the potential risks associated with lowered barriers to entry for generating and supporting content?", "c7e80515-0b66-4964-bda6-be20b68fc0e6": "How can lowered barriers for offensive cyber capabilities impact information security?", "d4a2a7c7-f709-42c6-9dd2-f2f5acb7dbec": "Why is anthropomorphizing GAI systems considered a risk?", "b59e8529-a07d-4d11-8584-755addd08c28": "What are the stages of the AI lifecycle where risks can arise?", "a8cb315e-1949-495c-b100-e9d488d55000": "How can GAI exacerbate existing AI risks?", "f10a20e0-51de-4215-b475-f49b2f21909d": "What are some examples of risks at the ecosystem level?", "8d30f395-6c74-496a-bc0f-b3167d082965": "What are some known past GAI system incidents and failure modes?", "9d735da2-28d3-4b07-89e9-16954494aa08": "What are the potential risks of over-relying on quantitative metrics and methodologies in the context of GAI systems?", "118b68e2-e3c3-4f45-938d-854e974b115f": "What types of harmful content should be identified and documented to prevent illegal uses of GAI systems?", "b5a7055d-a03a-4938-9ef5-7256f9dd4f9b": "What organizational policies are in place to foster a critical thinking mindset in the design of AI systems?", "0f9caa17-dde6-4b36-84e2-63e5a60981f9": "How do organizational practices ensure a safety-first approach in the deployment of AI systems?", "b845e850-d861-4c40-8af8-09fccd13ea7c": "What measures are taken to minimize potential negative impacts in the development and use of AI systems?", "c6cfe22a-3fbc-4cc0-96e1-c8afd64bf40c": "How can organizations identify gaps where provenance data may be most useful?", "11906b39-952e-4f8e-8382-68205dbcfe2e": "What techniques can be used to identify the source of content in GAI systems?", "8cae404f-5113-4881-9d65-ba63120b6448": "How can narrowing GAI task definitions help in maximizing the utility of provenance data?", "227401b6-dd77-4d18-a69d-b4f761723af9": "What are the key areas of focus for MS-1.1-004?", "d778d462-b018-4699-9617-f4e77bb6d0f7": "What novel methods and technologies are being evaluated in MS-1.1-005?", "a1115346-4d43-452b-a64a-df10936cda70": "How does MS-1.1-005 aim to maintain the models' ability to produce valid and reliable outputs?", "b666d389-5261-46e6-ba42-b594e60a014f": "What is the main security flaw in generative AI according to Burgess, M.?", "de355539-0ada-4162-a2d7-d549c6a683bb": "Who authored the article 'Securing the AI Pipeline'?", "a81dce1b-2b58-45dd-8a0f-31bf4b59425c": "What is the focus of the article by Burtell, M. et al. on large language models?", "11a6ffeb-c391-4d27-960f-90143f86534e": "What are the main findings of Dahl et al. (2024) regarding legal hallucinations in large language models?", "174640f0-bbd0-42ca-b74f-9d9abdd44ea4": "How does De Angelo (2024) categorize the impacts of AI in cybersecurity?", "588ceed0-7e76-4023-a91f-0f1187841e46": "What insights does De Freitas et al. (2023) provide about the safety of generative AI in relation to mental health?", "59054ca6-7348-489a-b926-a883d7cae53d": "What does CBRN stand for?", "0d344cae-a3a0-4b9d-94d4-d4879fa05e01": "What type of content is considered dangerous, violent, or hateful?", "a01b0910-5170-4410-878f-fbecf80c61f4": "What are the tasks associated with AI Actor Governance and Oversight?", "0f6f3b60-9baf-4f22-a144-244d0d85d9eb": "What are the key competencies required for interdisciplinary AI actors?", "444f7fca-c569-4ce9-b66e-504dba08223f": "How is demographic diversity reflected in the context of interdisciplinary AI actors?", "9d9ea7fe-34f3-454c-a193-f1c574c39360": "Why is it important to document the participation of interdisciplinary AI actors?", "d0e54ecb-f127-449e-9364-ee839b61fb78": "What methods can be used to represent GAI model behavior to non-technical stakeholders?", "669a3df5-1deb-448d-92fb-148df254c8e9": "Who are the stakeholders mentioned in the context?", "a1568d30-27c8-4308-b373-4acddde94028": "What are the AI Actor Tasks listed in the context?", "1d56b5c0-8b8d-4fe4-b1e4-77d6193ca9cb": "What are the key considerations identified in MAP 2.3?", "321bfb4b-c8d3-408c-8473-86e97c08296b": "How is the accuracy of GAI output assessed according to the suggested action MP-2.3-001?", "293fde39-5b27-40f8-9d4c-97a5fa4fa282": "What type of risks is associated with the suggested action MP-2.3-001?", "a09e63de-1bcb-4a34-8a5f-20f1c3b8d76c": "What is the purpose of verifying that those conducting structured human feedback exercises are not directly involved in system development tasks for the same GAI model?", "beafb995-819a-4d98-8e6b-24f2c157609a": "What are some of the AI actor tasks mentioned in the context?", "e8704c30-169e-4fd6-a106-83f725e4e8cf": "What are the areas of concern related to Human-AI Configuration mentioned in the context?", "958d6b97-ab86-4463-8c77-3e1e5e534c05": "What are the tasks associated with AI actors?", "aa460aa8-d766-4f8e-8c6e-022d8edd7fc9": "Which entities are involved in AI deployment and monitoring?", "6ba9db36-f3f4-4185-b313-2e755087eac1": "What does TEVV stand for in the context of AI actor tasks?", "92d9108e-0a00-4681-b284-9dc21d773145": "What are some applications of AI technology mentioned in the context?", "b19a7714-9334-4bf3-9f8d-90f026dc4934": "How can AI technology be used in content moderation?", "558262b5-42ed-4c4b-bc39-53eeaf46161e": "In what settings can AI activities take place according to the context?", "0e73070e-ce83-434a-8b30-2e748700272a": "What benchmarks are suggested to quantify systemic bias in GAI system outputs?", "ded5507b-84a2-40ef-8862-5feb557cc4b2": "What should be documented about the benchmarks used in GAI systems?", "84b782b7-6be1-4303-9c1e-4912165710d2": "How should fairness assessments be conducted to measure systemic bias in GAI systems?", "28ad504c-f099-4439-9f61-a29b99173a15": "What are the suggested actions for establishing transparency policies for GAI applications?", "d23f8776-90e8-42e5-b94e-39b30d4a51a8": "What risks are associated with the action GV-1.2-001?", "9944066d-3b2b-43f3-be99-803985db71dc": "What is the purpose of establishing policies to evaluate risk-relevant capabilities of GAI?", "43365979-5135-40b9-abdf-b80aa7dd34ca": "What should be included in the records of changes made by third parties to content?", "6cd5b3af-603e-451e-865f-5de6b3e6f076": "What processes should be updated for GAI acquisition and procurement vendor assessments?", "ac9da121-2c8c-4952-b0a7-4f720d392cb6": "What are the key areas to consider when updating due diligence processes for GAI acquisition?", "7e6a5ec1-98e7-4391-b702-4d8ebd8e984a": "What is data poisoning in the context of GAI?", "9a90a57c-2fdd-4363-bcd2-89f801366ecb": "How can data poisoning affect the outputs of a GAI system?", "ac3b24f6-945e-4a5b-ab4b-c15da635dcd3": "What are the intellectual property risks associated with GAI systems?", "46d0462d-f3dd-4799-b4ab-6c55de5a5133": "How might organizations tailor their measurement of GAI risks?", "c13d7fd9-e83c-4eda-afcf-a6b36b5847b6": "Why might organizations allocate risk management resources based on the severity and likelihood of negative impacts?", "fb363968-b46d-4edb-9f07-f99ef12ab936": "What are the differences between mitigations for model or system level risks and use-case or ecosystem level risks?", "a93fa0c1-4438-42a0-8d83-29ee326c82f3": "What is the purpose of a cross-sectoral profile in the context of AI RMF?", "68638a7b-3555-4ac2-9f9c-8236791f517e": "What types of risks does the document define as novel or exacerbated by the use of GAI?", "d281a61e-1e7f-4964-9fbf-1524549f3e38": "What actions does the document suggest to help organizations manage risks associated with GAI?", "e642f7d1-3aef-4219-a073-d831ac7216e9": "What is the suggested action for Action ID GV-5.1-001?", "d8bd89d0-0e30-445d-9139-22ca6a98e797": "What are the GAI risks associated with Action ID GV-5.1-002?", "956afdc6-7963-42f0-85ef-195ca20d21d8": "What does GOVERN 6.1 address in terms of AI risks?", "c3931043-efbe-4c22-862b-ca9f6a1a7124": "What are the key aspects of information security for GAI models and systems?", "5336b2cc-f741-4681-b76e-b192319686bf": "Why might conventional cybersecurity practices need to adapt for AI systems?", "08242812-c92d-4573-a9ce-de5b4e7fa5b3": "What components of the AI value chain need to be secured?", "b5bc58f5-c5e2-4c05-bfcc-d11f047eacce": "What are the capabilities and limitations of GAI systems related to digital content transparency?", "2089bcb3-7bfc-4cbc-8c26-864168670262": "How can feedback about content provenance be collected from operators, users, and impacted communities?", "8acb7434-0230-4a13-8bd0-2a5a5ab4cb11": "What methods can be used to assess the general awareness among end users about feedback channels?", "aca9d2cb-4872-43db-85ce-756871defb36": "What is the purpose of implementing systems to monitor and track the outcomes of human-GAI configurations?", "a6b4d7d7-083b-470d-b390-e6060b1c0f19": "Who should be involved in the prototyping and testing activities of GAI systems?", "7bfe235e-f536-43aa-8038-0f6872ea533a": "What scenarios should be covered during the testing of GAI systems?", "ba91bdc1-8fe9-4e14-a5c4-61cc8252394b": "What are some examples of transparency artifacts mentioned in the context?", "656724c0-7ab3-42f6-bb40-e69bd4b9d3e1": "What is the purpose of monitoring pre-trained models in AI systems?", "6e05f16f-5886-40c5-b3b1-39b1995b8ea8": "Which AI actor tasks are involved in the deployment, operation, and monitoring of third-party entities?", "43ba0754-c45b-43ef-afc6-512431587781": "What does GAI stand for?", "dbad9e30-29de-42a6-b7af-959f9627c468": "What topics are associated with Information Integrity?", "59890393-2d5b-46cb-a9af-4c9e5072544f": "What is included under Intellectual Property?", "8d7d25fb-96bf-4eee-a5f4-2a9dc4ee81bd": "What are some examples of immediate risks associated with GAI?", "77d336e6-9546-438e-bd98-e18b1ca74c42": "How can the characteristics of a GAI model influence the presence of risks?", "37efdd37-3a8b-4979-a696-b6988caedcc3": "What long-term effects can disinformation have on societal trust in public institutions?", "e13bcaa6-e941-488f-8d51-da1771bb3357": "What does the term 'confabulation' refer to in the context of GAI systems?", "4ce87fa9-e60a-4e72-a213-dff4843c0466": "How do confabulations manifest in GAI systems?", "851bc104-f046-424c-b1bf-9a2312750134": "What are some colloquial terms used to describe confabulations in GAI systems?", "ab791f19-6170-4803-8b2f-bf016add65e6": "What is the main topic of the paper by Kirchenbauer et al. (2023)?", "492129ba-05b6-4832-b1de-ccc7aa07324c": "Which publication discusses algorithmic monoculture and social welfare?", "6bd4483b-f66e-4ad3-87b4-b6bdbb17903f": "Who authored the report titled 'A Revealing Picture' in 2023?", "fb948c5e-e6f5-4b13-8ca9-35b3f0c37768": "What are the potential downstream harms of AI-generated offensive or hateful language?", "db02f036-586e-4dd1-a4fb-29afc9a99455": "How can the spread of denigrating or stereotypical content exacerbate representational harms?", "343970d3-8c31-4253-a805-c7e42f534e0f": "Why is it difficult to control the creation and public exposure of offensive language generated by AI?", "9681850f-428d-443e-a2c6-a965679ca97d": "What is the purpose of regularly evaluating the AI system for safety risks?", "f3c46f78-2c53-4b84-b23f-a53b068903c9": "How is the AI system's safety demonstrated before deployment?", "13563a6b-58ff-4228-8de7-2b006c93fed2": "What aspects are included in the safety metrics for the AI system?", "ba7c2476-3f6d-4254-882c-d3b17691b13d": "What are some methods used to solicit feedback from civil society groups and affected communities?", "3fa49df8-a47a-4098-b49f-6a300f89e2fc": "How is field testing used to understand interactions with AI-generated information?", "d784e93f-1fc0-41ff-a488-43510344b965": "What is the purpose of AI red-teaming in the context of AI system development?", "904de45e-a7be-4bb9-8eca-d429e482d3d9": "What is the focus of the White House's 2016 Circular No. A-130?", "98a0a4d2-978d-4620-96a4-086a0982fb2a": "Where can the 2023 Executive Order on Artificial Intelligence be found?", "58133561-731e-4261-9bd2-d1360ea7fbd6": "What is the title of the 2023 Executive Order issued by the White House?", "4f0eaabb-069a-4b1a-aa62-88d46012bd67": "What is the main focus of the study by Qu, Y. et al. (2023) on text-to-image models?", "efcb16fa-5a01-454d-914d-071247fcf219": "How does the research by Rafat, K. et al. (2023) aim to mitigate the carbon footprint in deep learning model compression?", "199ee5ce-6695-4d30-b9b2-0a822674926f": "Where can the full text of the study by Qu, Y. et al. (2023) be accessed?", "3a6cc431-d42c-41f4-bde2-5ee173472825": "What is the purpose of measuring Al system performance or assurance criteria?", "bea49359-d092-419d-bc83-910413322e96": "What should be considered when selecting a model for fine-tuning or enhancement with retrieval-augmented generation?", "de86cb6e-18cd-40bd-bdb8-89d6cf950bf3": "Who should the results of pre-deployment testing be shared with?", "c5df25e3-b41a-49b4-a7a4-d347548d96ce": "What are the processes in place to determine the needed level of risk management activities?", "5fe8c590-1362-4c07-9ec7-b90bb65ecb7a": "How does the organization determine its risk tolerance?", "e7b5681c-f460-460b-92c2-cb9d56da6702": "What procedures are used to assess the level of risk management activities required?", "afd5e8c2-443c-47b6-a572-49159cece1ab": "What are the TEVV practices suggested for content provenance in Action ID MP-5.1-001?", "3e87713e-e710-486f-99ea-85de5e3c8731": "What types of risks are associated with Action ID MP-5.1-002?", "b5ea83a6-d6f3-4430-98b7-b7ea21ef828d": "What is the purpose of identifying potential content provenance harms in Action ID MP-5.1-002?", "5b80aac0-efc2-4449-97dc-5716d36cb15f": "What is the suggested action for Action ID MP-2.2-001?", "d3380d75-96e0-412d-ac32-a998f5d51a5d": "What GAI risks are associated with Action ID MP-2.2-002?", "d2104818-3192-485c-8771-4c5780e59ed6": "What should be observed and analyzed in the GAI system according to Action ID MP-2.2-002?", "312ef34a-2136-42d6-a90a-1cdb2ce5a7d0": "What are some suggested actions for applying and documenting ML explanation results?", "0e97fda0-7077-4e9e-b376-b8259fa5bbbc": "What details should be documented about the GAI model according to MS-2.9-002?", "163f9360-681d-4b73-b316-936978f12c4b": "What are the GAI risks associated with documenting GAI model details?", "06576ffe-8702-4918-8504-053196a17035": "What are the approaches for mapping AI technology and legal risks of its components?", "2401369c-a016-4a0e-8328-d23a329e0fb1": "How are the risks of using third-party data or software documented?", "9d2d4e03-b742-4593-8143-9b987abb7506": "What measures are in place to address the risks of infringing on a third-party's intellectual property or other rights?", "2aa7ea23-4f5e-45fd-b2d6-6d60f14d961b": "What are the main tasks of an AI Actor?", "4b4359fa-f746-4e45-9b05-e703b05a6e07": "What does GOVERN 1.5 entail?", "ea9000a1-4d02-4052-8ac2-5bdfcb4ba2b8": "How are organizational roles and responsibilities defined in the context of GOVERN 1.5?", "87254219-51c8-46fc-9496-d51fdd658c6c": "What is the main focus of the abstract?", "42acabcc-ca44-4d39-a38e-029d85b4c487": "What key findings are summarized in the abstract?", "9894f9f7-cd63-4ed8-b1c0-bdbe84ff1531": "How does the abstract contribute to the overall understanding of the topic?", "21156a41-1be8-4078-ad44-db72521ea5ca": "What are some methods mentioned for evaluating AI systems?", "ad3e35d3-042a-4b50-aabf-fb2578d2d9fd": "What are the tasks associated with the AI Actor?", "acb0b23a-2b67-4d59-9aa8-90ac30b7f77e": "What is the context in which 'Human-AI Configuration' is mentioned?", "a6b7d512-c50d-443b-ab2c-ea76748b43bd": "What are the ethical and social risks of harm from language models according to Weidinger, L. et al. (2021)?", "5b2ce0dc-df97-49cd-b5a6-4989de7765a8": "How does West, D. (2023) describe the risks AI poses to women?", "f64264ae-61c4-4124-acbb-cc6e20b79824": "What is the focus of the study by Wei, J. et al. (2024) on large language models?", "c72fb505-dfc5-457b-8663-650e7dc7ee95": "What is evaluated and documented in MEASURE 2.7?", "e858f27d-632e-4321-850d-de86378041be": "Which function identifies the system security and resilience in MEASURE 2.7?", "4e82ba2d-2c60-4612-b021-7ca7a2eeb579": "What does MEASURE 2.7 focus on regarding Al systems?", "46219284-ba87-4d12-9795-40a6e932b7bf": "What is the main focus of the paper by Badyal, N. et al. (2023) on arXiv?", "2204af3e-daff-47b2-8364-3f2e6e133f28": "What issue is addressed in the blog post on Embrace The Red about Bing Chat?", "46f4993f-d20c-46b6-bcf0-367e18f6d61d": "What is the topic of the paper by Bommasani, R. et al. (2022) on arXiv?", "a76e04b4-668d-45e9-9724-6a06a484bb75": "What are the tasks associated with AI actors?", "7edd4e97-5ec5-45d1-a55f-b25fdd0ddf26": "What is the purpose of Measure 1.1 in the context of AI risks?", "16f954d1-dce2-414d-a9d6-1f60ee94b698": "Who are considered as affected individuals and communities in AI deployment?", "f1d89b6c-ed71-4aea-a08c-19ffd8af57b7": "What is the role of general users in AI red-teaming?", "c1d129a5-1ff0-41be-a178-731533fa764a": "Who performs expert AI red-teaming?", "5031868c-fd19-4e05-ba3a-64c38f669c8b": "When might a combination of general users and experts be used in AI red-teaming?", "3ce36ecf-2846-4014-8563-4aaa76fc0227": "What are the contingency processes in place for handling failures in high-risk third-party data systems?", "c472b258-cda4-49ed-bc62-ddb1c7aeaebe": "What is the suggested action GV-6.2-001 aimed at addressing?", "76462895-b832-44fc-bea8-e47f7d84b5b4": "What types of incidents should be documented according to action GV-6.2-002?", "f7984aa8-76d6-4019-a5a4-cd9963310a99": "What is evaluated in MEASURE 2.11?", "a1c07038-6c5c-4c64-8ae7-7ac678980f3e": "How are fairness and bias identified in MEASURE 2.11?", "0fc4da7b-5076-4e87-9138-9fa4b81e7910": "What is done with the results of the evaluation in MEASURE 2.11?", "1e86980e-039b-48f6-b359-7a2bcb95d97f": "What are some of the vulnerabilities and threats mentioned in the suggested action for Action ID MS-2.7-001?", "06b4ad16-b3e5-42f3-a8ac-91e672522770": "What are the GAI risks associated with Action ID MS-2.7-001?", "b203af24-2c31-4d1a-8dc3-0cf47b18f835": "What is the purpose of benchmarking GAI system security and resilience in Action ID MS-2.7-002?", "01bd5451-e356-4d54-877a-3f8457c18e14": "How can the effectiveness of carbon capture programs for GAI training be verified?", "30744397-e4bb-4928-807c-938d8bd2a6a4": "What are the main concerns related to green-washing in carbon offset programs?", "0eab3cd4-7526-40a7-ad04-6afa04c686ad": "What roles do domain experts play in the operation and monitoring of AI deployment?", "c8eb00fb-44fb-4c25-8e07-b8d12e3ee3ef": "What mechanisms are suggested for sharing information and feedback among individuals and organizations regarding negative impacts from GAI systems?", "070f99c9-c592-4005-87cc-b9948897a126": "What are the key focus areas mentioned in GV-4.3-003?", "82fe2a74-a336-45c9-8923-23edd4ec13db": "What does GOVERN 5.1 emphasize about organizational policies and practices?", "bb6416a5-fbe6-44f5-8da7-e72b84778f8c": "What is the purpose of tracking dataset modifications for provenance?", "90211784-5351-42ea-82ee-64baa936ceb2": "How can monitoring data deletions impact the verifiability of content origins?", "fe5d499d-3ff7-41dc-98df-45c6adb254b6": "Why is it important to track rectification requests in the context of information integrity?", "4ddf5d92-5a3a-4e20-84e9-f574f0ad508f": "What is the suggested action for Action ID MP-1.2-001?", "bb56cf4a-2f3b-4f19-b918-1ca869065b67": "What are the GAI risks associated with Action ID MP-1.2-002?", "21662fc9-98d1-4c8b-b490-48b20b629092": "What is the purpose of establishing interdisciplinary teams according to Action ID MP-1.2-001?", "ecfda69d-268f-41ad-bb4e-4da52aa5ddc4": "What methodologies were used to generate the content?", "49730a7c-d19f-4f16-995e-5699eee325f4": "What is one of the potential issues mentioned in the context?", "e9717649-9e7e-4251-981c-c86ec4183752": "What type of feedback was evaluated in the context?", "ba95a8a9-2235-4bfb-b0f8-2c21726976e7": "What information does MAP 2.2 provide about the AI system's knowledge limits?", "e299594c-7cd4-4024-92af-decb3d967c18": "How can the system output from the AI be utilized by humans according to MAP 2.2?", "3b96a647-a252-4bf1-a067-4df9e0fd7b22": "What kind of assistance does the documentation offer to relevant AI Actors in MAP 2.2?", "f50d362c-4592-4c88-b9e2-b0acd9bface2": "What is one scenario where AI red-teaming exercises might leverage both expert and general public participants?", "5b89a903-8e84-4922-9dd4-44e04ffffe92": "How can GAI-led red-teaming be more cost-effective than human red-teamers alone?", "86083261-0cbd-4083-a2dd-02e0e75fada8": "What types of teams can perform AI red-teaming according to the context provided?", "b0f7e793-8389-4950-9c4e-1c67af067309": "What should be reviewed in vendor contracts to avoid arbitrary or capricious termination of critical GAI technologies?", "901e62c7-0e53-4213-bb84-0c8ba1f87676": "What should be considered to prevent unauthorized data collection by vendors or third-parties?", "82396c36-bca7-4a20-86e4-93168e10d4a4": "What are the AI Actor Tasks mentioned in the context?", "ddde96a5-7d0d-42cf-b0bc-d87e69573145": "What are some ethical considerations mentioned in the context?", "b026cb2b-16aa-4a4b-af27-b45c0108699e": "Who are the AI actors involved in the tasks listed?", "d9c307d7-191e-4a2e-85e6-b622b63d1820": "What are the potential risks related to information integrity and harmful bias?", "4980621b-ab52-4e9a-bafb-ca8d767200b1": "What are some forms of latent systemic bias in GAI system training data?", "75458d92-6d7b-4c5f-a97d-a5636e16dd94": "How might the digital divide impact representativeness in GAI system training?", "7b9acfdc-992a-4b4e-ad89-b8a61b009154": "What input data features could serve as proxies for demographic group membership in GAI systems?", "4be53f00-afb7-4dc8-b8b7-f8f7d3337169": "How can continuous monitoring of GAI system impacts help in identifying equitable outputs across various sub-populations?", "5abee833-075d-4778-9afe-6af0c796347f": "What techniques can be used to evaluate the quality and integrity of data used in training AI models?", "0cbe8aeb-96f8-4493-af22-4ecaddfa1637": "Why is it important to define use cases and contexts of use for GAI risk measurement and management?", "7ff1ee12-449f-4932-b30f-8b2a39d136ec": "What did recent research find about LLM outputs regarding biological threat creation and attack planning?", "0f4134c6-782c-4389-a25d-669ef527697c": "What will the physical synthesis development, production, and use of chemical or biological agents continue to require?", "3b12fba3-4c05-44f7-a66e-2ad0d0f2eb7e": "What factors will the impact of GAI on chemical or biological agent misuse depend on?", "3f139d6a-5cc1-4709-be45-0e916b652ab9": "What are some characteristics of GAI opportunities, risks, and long-term performance?", "71bbc0ee-9e6f-4b16-a30b-2395d9b7f67a": "Why might GAI require different levels of oversight from AI Actors?", "2d99993b-8b89-43a0-be49-8f1cc69ca058": "How might organizations manage the risks associated with GAI systems?", "047fe968-2597-4c11-92bc-7be7aab9202a": "What are the priorities related to information integrity research and development according to the White House's 2022 roadmap?", "9caffe07-98dd-4b49-84c7-d3e92a98a8b4": "What did the 2023 investigation by D. Thiel at the Stanford Cyber Policy Center find about AI image generation models?", "be110ba8-b86e-44d6-a469-08279226c4a8": "What is the focus of L. Tirrell's 2017 paper on toxic speech in Philosophical Topics?", "a671caf3-6c0f-48cb-ae22-a324f4ef8183": "What are some of the governance tools and protocols that can be applied to GAI systems?", "8dd372b7-5921-47ff-ae6b-c1e3a233584e": "How can organizations ensure alignment to their values when using AI applications?", "9bbdf39d-6a29-46cd-978e-a735302a2932": "What measures can be taken to protect data in AI systems?", "cb14e339-0e8b-485a-b04a-aa7e8fe505a0": "What does each Action ID correspond to in the context of AI RMF functions and subcategories?", "db13f4f8-cda1-44ff-8e47-cea887e9b1f9": "What are the tags used to link suggested actions with relevant GAI risks?", "fb883939-56c8-4774-b733-b354b9503cfd": "What is the purpose of the 'Suggested Action' in the context of managing GAI risks?", "a8284088-ece4-4d30-a63f-ade286437941": "How can GAI systems be used to produce disinformation?", "17bd61cc-ec83-4d71-91e4-66f36781f7ff": "What are deepfakes and how do they relate to GAI systems?", "65c9e35b-7afe-4bee-8198-b5b8fc6f3996": "How might future GAI models increase the threat of disinformation?", "dd960cf2-8eec-4cf8-aa6b-25f6a5dcff0b": "What are some characteristics of trustworthy AI?", "20db2fb1-a111-47ab-8796-1d9150d5e9e3": "What type of content can GAI systems produce that is concerning?", "b06bd20a-cd50-4e4c-9a83-e9bb4e3ae80c": "What have LLMs been reported to generate that is dangerous?", "f0d1d5b3-7949-4590-a942-2050ad305967": "Who are involved in regular assessments and updates of the AI system?", "e78ce523-0209-4f35-8c1f-c8ce408e05c8": "What types of external parties are consulted in support of assessments?", "82d56bfe-9dda-4d55-a282-a788e10f5dfc": "What is the role of internal experts who did not serve as front-line developers in the assessment process?", "97beb31c-7d49-402d-9d5b-9626510ddb54": "What were the four primary considerations relevant to GAI discussed by the GAI PWG?", "1f2eb86e-f0d6-42c2-aef0-180d46ca875d": "How was the GAI PWG process facilitated?", "27da530c-55de-4647-b88a-aed9aa684e3c": "What will future revisions of the profile include based on additional considerations of GAI?", "a566985e-ac7b-4d94-a8c2-2525047288f9": "What are the potential risks associated with non-transparent integration of upstream third-party components?", "02e856cb-fbac-44a2-9770-f59f9f85abe9": "How might GAI enable malicious actors to access CBRN weapons or relevant knowledge?", "bb9f2d65-3134-4182-8666-564604222dcb": "Why is improper supplier vetting across the AI lifecycle a concern for downstream users?", "dfd8b7b2-70a8-45d6-9887-9c5ef3187ed9": "What processes should be established to verify the skills and training of AI Actors conducting GAI incident response tasks?", "86c4f476-ddc6-4d24-ab72-2719f9e825b1": "How should national security professionals be involved when systems may raise national security risks?", "dbed80fb-85a0-4379-aac4-2ffa17be0ddf": "What mechanisms should be created to protect whistleblowers who report violations or risks to public safety?", "f8322fab-cb8d-4698-837b-d719fb9c37ee": "What is the purpose of the AI Risk Management Framework by the National Institute of Standards and Technology?", "a7d1b04e-33b2-49a3-8f25-b6b75c3bd858": "Where can one find more information about the AI Risk Management Framework?", "292bde7d-4cc8-47c0-8f61-51885cbacd6a": "Which organization published the AI Risk Management Framework in 2023?", "7d7cf465-cfb5-4e95-8007-17a57b16db35": "What are the suggested actions for Action ID MG-2.2-001?", "e2348723-3ee7-4d59-ad27-b0bee2ceca78": "What GAI risks are associated with Action ID MG-2.2-002?", "04169d36-7e09-462f-98ea-1c95f66b9dcd": "How should feedback loops between GAI system content provenance and human reviewers be evaluated according to Action ID MG-2.2-003?", "6883109c-f7ac-41c9-833f-2c463cc40cc1": "What is the purpose of involving domain experts and relevant AI Actors in measuring AI system trustworthiness?", "28c02aaa-9283-4c98-9c1c-0f16a3a2b89b": "How are the measurement results regarding AI system trustworthiness documented?", "4faf7ee4-6a6f-4fc0-a4f9-5a2c7b065f4b": "Why is it important to validate whether the AI system is performing consistently as intended?", "c81b151d-57f8-46f6-b64b-e9b0e528387d": "What is the main focus of the survey conducted by Zhang, Y. et al. (2023)?", "9320c872-4eec-4880-bf71-d360518e5b5c": "What is the topic of the paper by Zhao, X. et al. (2023)?", "87330e6e-8fb3-4970-a8d7-fbe2d9dd88c2": "Where can the paper by Zhang, Y. et al. (2023) be accessed?", "7b17fbc7-2d9b-4319-930e-44d23562a8d1": "What types of information can provenance metadata include?", "37bfe95f-78ae-4e62-93b0-bfd8b3f871d6": "How can provenance data tracking help in assessing the authenticity of digital content?", "5ede2704-f2e1-4b4b-b833-1963583da755": "What are some well-known techniques for provenance data tracking?", "8c2ac31b-680a-4e01-893c-ebc35e7809f6": "What are some examples of unacceptable negative risks mentioned in GV-1.3-006?", "26f1160d-7555-46c0-b395-ad221aed88db": "What does GV-1.3-007 address in terms of risk?", "d8ee3416-0e1b-4769-a647-fda807fa0ac9": "What are the broad GAI negative risks listed in GV-1.3-006?", "ba495fc1-d734-4256-867b-21004cfd32a4": "What are examples of sensitive information mentioned in the context?", "1f414147-6558-4ab6-8be3-923b91da9752": "What does the notion of harm presume according to the context?", "68a86698-80ac-43b4-88e0-05f59c945b56": "Why can it be difficult to establish the most appropriate baseline when discussing harm from disparities?", "cf014318-841c-4f89-afab-9cd927b8716b": "What are some potential downstream impacts of wrong or inappropriate inferences of PII?", "beed3ea0-e41a-4c4d-85f1-3297c9cbd5fd": "How can predictive inferences made by GAI models lead to representational or allocative harms?", "bf2ee999-9c69-4999-adcb-5d53e18035de": "What factors influence the energy and carbon emissions of GAI systems?", "9df343e3-7f16-4461-aba6-4466584f74cf": "What are the suggested actions for establishing policies for measuring the effectiveness of content provenance methodologies?", "af7cc657-1e75-4215-9b72-2bd77e24d762": "What criteria are necessary for GAI system incident reporting according to GV-4.3-002?", "dc0fd520-bd6b-4035-91fd-4e1fbe918f4f": "What GAI risk is associated with establishing policies for measuring the effectiveness of content provenance methodologies?", "ba79c50a-8098-481e-8102-df14f0d02e19": "What techniques can be used to mitigate biases in GAI content?", "4285978f-a2ae-46f0-9384-f1d6b4d6eb2d": "Why is it important to engage in due diligence when analyzing GAI output?", "8834ad77-2285-48c2-973d-10ed64286eaf": "What types of harmful content should be analyzed in GAI output?", "43dbf1dd-28f8-49d8-ac32-86c7c38a15bb": "What are structured human feedback exercises like GAI red-teaming used for?", "d0bdfca1-426c-4cef-bec4-5c4cb176e14a": "Why might some GAI risks not be measured quantitatively?", "a72fb063-06ad-489f-9dc3-81bcb0277c8a": "What should be included in the documentation of GAI risks that cannot be measured quantitatively?", "2b9e05b4-b94e-4591-8680-97b21f4d1a32": "What are the suggested actions for identifying new impacts due to the GAI system?", "2b2cbac9-7587-436d-b2eb-940ff26f5966": "What are the GAI risks associated with the action ID MP-5.2-001?", "4c812769-4583-47a9-aba1-1be3419bab16": "Why is it important to plan regular engagements with AI Actors responsible for inputs to GAI systems?", "8690ce69-1f4a-418c-91ed-58827b4b367f": "What are some practices mentioned for secure software development?", "3826600f-5e38-4b82-be46-2f47db86b61c": "How can establishing acceptable use policies help in human-AI teaming settings?", "5051a532-cd1d-4f8f-a8e6-358e30413438": "What is the purpose of synthetic content detection and labeling tools?", "dc873d59-8a9b-4fe0-92e4-d6bf4681f5c3": "What are the main topics discussed in Tirrell's (2017) paper on toxic speech?", "bf8277be-f497-4edf-82e7-b064c13a02de": "What challenges does Tufekci (2015) identify regarding algorithmic harms beyond major tech companies?", "dd2500fc-24d0-4089-a6ed-bd4778ea8c4a": "What is the focus of Turri et al.'s (2023) research on AI incident documentation practices?", "f22d465e-3e00-49c9-a9a1-f2db974d2f0e": "What are confabulations of falsehoods most commonly a problem for?", "a220d82b-590f-4180-9ecd-3b1a4eefe8a2": "What type of content can text-to-image models create that is concerning?", "129259ad-3913-4a76-ba29-d30398468a07": "What kind of content might GAI produce that is particularly dangerous?", "07036cb0-004a-4f0d-aa18-4d8a79307f49": "What is the suggested action for addressing privacy risks in AI-generated content?", "cb37b031-14c1-4288-901f-d99fb6fd4fda": "How should potential intellectual property infringement claims be handled according to the suggested actions?", "a25c6f9e-141f-49e0-9283-e81c49033c78": "What are the GAI risks associated with connecting new GAI policies to existing governance and compliance activities?", "9774b478-0d63-4646-9aaa-ddc970da8ad5": "What are the key findings of Kalai et al. (2024) regarding language models?", "7da5f09c-4eb8-4f38-8316-042d84eed1e2": "What predictors did Karasavva et al. (2021) identify for the non-consensual dissemination of intimate images?", "74e9ef5b-618d-428e-bbf0-8115efd20ddb": "How does Khan et al. (2024) analyze the value chain of generative AI?", "a0e7b991-5fb6-41fd-83a5-eb4055b1020b": "What are the suggested actions for managing GAI risks?", "d9681d8f-0cbd-4abb-a443-cf32ed4e44e1": "Which GAI risk is associated with categorizing different types of GAI content?", "b676ce47-c507-4077-b029-9d82203f35fa": "What is the purpose of conducting joint educational activities and events with third parties?", "e731ceb2-1821-4178-96b8-cd8bf4822855": "What is the suggested action for Action ID MS-2.12-001?", "33bf2b3e-f886-41e3-abf0-aa34696f53b0": "What GAI risks are associated with assessing safety to physical environments when deploying GAI systems?", "0949730f-79cd-47f8-9a2d-0266b107c3cb": "What should be documented in product design decisions according to Action ID MS-2.12-002?", "6c3935da-0a43-49e0-b858-4bd95d769819": "What are some risks associated with the use of third-party components in GAI value chains?", "68ea839b-5150-424d-9054-0ad78925e381": "Why is it difficult to vet the training data for GAI systems?", "122292da-8484-4b7d-a874-03cf8e3e34dc": "How does the integration of GAI into other devices and services exacerbate risks?", "e279a5fa-4750-4464-8c63-faace9a8a095": "What are performance and trustworthiness characteristics related to content provenance?", "5cbffabd-ad5b-4f62-b733-31f1aee5e42e": "How can deviations from desired standards be identified?", "7728d5d8-8483-45de-aa4d-23f784a2feff": "What action is triggered when deviations from standards are detected?", "fb756ae4-45b6-4eb0-8882-94c46fb2f988": "What is the purpose of using sentiment analysis in evaluating GAI content performance?", "bd46493f-e16a-4ac3-9e24-929cfcbfeaed": "How can active learning techniques help in identifying model failures?", "8eb5be8e-10fa-486b-93ec-4a998b6ac24c": "Why is it important to share transparency reports with stakeholders regarding updates to the GAI system?", "0fa8212c-db74-4616-9504-fbd3c958c761": "What is the suggested action for Action ID MS-2.5-001?", "fca9d77d-0107-4ca4-802b-b84495d312ba": "What risk is associated with the action of documenting the extent to which human domain knowledge is employed to improve GAI system performance?", "7fe6643b-6777-4de6-af22-dc94e76a5681": "What is the suggested action for reviewing and verifying sources and citations in GAI system outputs?", "c5052e82-811a-480d-9249-93b0e4b4abde": "What is the purpose of creating measurement error models for pre-deployment metrics?", "da550cb2-310f-4135-85c3-d4ff69e7af07": "What are the suggested actions to address the GAI risks of Contegrity, Harmful Bias, and Homogenization?", "875aed84-fee3-4d49-a9b7-d75f3a90e43a": "What tasks are associated with the AI Actor in the context of TEVV?", "a8166e64-cea0-48bf-967f-232cf70a25f9": "What is the focus of the Canadian Centre for Cyber Security's 2023 guidance on generative artificial intelligence?", "94fb0480-7d12-40e0-a9af-158b1dacb755": "What is the main topic of Carlini et al.'s 2021 paper presented at Usenix?", "0f2956ac-823f-48ee-8c10-f358d7ea1f3b": "What does Carlini et al.'s 2023 ICLR paper aim to quantify in neural language models?", "effa99b4-68c1-47d6-b231-e1241081f497": "What is the purpose of the supplier risk assessment framework mentioned in GV-6.1-005?", "669c403b-fe13-4a79-9b29-c56ecdb261d6": "What clauses should be included in contracts according to GV-6.1-006?", "651e351d-555d-4c93-be59-0399a89a850b": "What action is recommended in GV-6.1-007 regarding third-party entities with access to organizational content?", "eccd0761-7a21-4336-8930-27a64905f3b9": "What are some potential risks associated with increased attack surfaces for targeted cyberattacks?", "d4012fab-95a4-4d06-b175-2569e70e9624": "How might intellectual property be compromised through eased production or replication of content?", "38ad75b0-0246-4006-abbf-27770787807b": "What types of harmful content can be more easily produced and accessed according to the context?", "e555a037-ac94-4f24-b433-f125505b457b": "What are some privacy-enhancing techniques mentioned for GAI development?", "c6279345-f332-4382-9efc-1a6d5093e34c": "How can synthetic data be used responsibly in GAI development?", "aaaf5dff-32ff-4212-ab9d-31e312e312e4": "What are the concerns related to data privacy and intellectual property in GAI development?", "36299752-e1f7-48fb-9d6d-24e6903a3d89": "What are confabulations in the context of GAI outputs?", "dcb58a08-c75c-48e5-a9a9-951a8190ddfa": "Why do generative models produce confabulations?", "a7c89c36-aee2-453a-aa87-ec4db738f928": "In what scenarios are confabulations particularly relevant?", "224fd071-c87d-47ee-9401-4bd60105390e": "Who are some of the guest researchers mentioned in the context?", "de89c713-ed91-404b-8a5e-d51afb034eb3": "What is the role of the NIST Generative AI Public Working Group?", "4223eef1-3ef9-4e01-94bb-9cfe11e7cae6": "Can you name two NIST staff members involved in the contributions?", "8f992d6a-e4fe-4330-9d47-8cc0908fa2c6": "What is the definition of Generative AI according to EO 14110?", "147cf1f8-1f3b-4185-a55d-c7c98f86e27b": "What does the foundation model subcategory of 'dual-use foundation models' entail?", "2872e02c-946f-4b24-9cbe-2ad122a78b64": "Who is directed to develop a companion resource to the AI RMF according to Section 4.1(a)(i)(A) of EO 14110?", "e62548e4-8647-41fc-9650-0d12eb371dba": "How can documentation practices facilitate smoother sharing of information with relevant AI Actors?", "01be9671-08a4-4eab-a6f0-937f3fa479c5": "What are some benefits of regular information sharing and change management records for AI Actors?", "4272700b-98b3-4b39-970a-7d6f9bd52e95": "Where can one find the paper 'The Simple Macroeconomics of AI' by Acemoglu, D.?", "0d5d2361-0c91-4ce2-a23d-29b2241e901e": "What is the purpose of regular adversarial testing for GAI systems?", "46ed3ceb-0c8a-4046-97b1-4339c8208c60": "Which tasks are associated with AI actors in the context provided?", "5fe236be-1a0b-4444-ab32-dfb0f73773a9": "What is the focus of MP-2.3-005 in terms of information security?", "36d3c51c-0309-4e3a-8eb1-32253d3ed974": "What is the suggested action for Action ID MG-4.2-001?", "79aa5a76-ac4d-42e1-8993-1dc0a26c2b57": "What GAI risks are associated with Action ID MG-4.2-002?", "dd91ef71-eef4-4301-9182-7fdb4b13676f": "How can non-technical stakeholders better understand GAI system functionality according to Action ID MG-4.2-003?", "77d463d4-cbe3-4e17-98c9-6712dfb0cba7": "What are some potential impacts of errors in third-party GAI components?", "eeb3db59-427b-4206-a752-58a8d37d8acd": "Why is it important to consider label errors in test datasets when benchmarking models?", "1374a2b1-bcd8-4772-88d9-650c68969019": "What are some characteristics of trustworthy AI?", "b8d825df-e61f-4446-aa1c-ba27e89e1284": "What practices are in place for supporting regular engagement with relevant AI Actors?", "1ce070fd-6bd7-4fe7-9908-8d4c4bb7ba92": "How is feedback about positive, negative, and unanticipated impacts integrated?", "7807c7c0-3538-4ce6-bb06-9812e1dc440d": "Are the practices and personnel for supporting AI engagement documented?", "1eeb3e80-2cd7-48fe-86c4-293c4d282c15": "What is the suggested action for Action ID MS-3.3-001?", "a10239f8-2c3a-416b-a121-837398833370": "What are the GAI risks associated with Action ID MS-3.3-002?", "2626c064-405a-4243-8655-d083a41b68c0": "How should potential biases and stereotypes be evaluated according to Action ID MS-3.3-003?", "3cc1f581-2503-48ac-9f90-4177b7b78069": "What is the suggested action for Action ID MS-1.1-001?", "29e370ca-ce36-4704-98c7-7137447f9466": "Which action involves integrating tools to analyze content provenance and detect data anomalies?", "417f3fa7-8da9-482c-8216-c15a8519d7cc": "What are the GAI risks associated with Action ID MS-1.1-003?", "c677a715-20f4-47e0-81d0-38358b3af2be": "What are the risks considered in the policies for data collection and retention in MP-4.1-005?", "875e1871-03f7-4208-a73c-99e8810f77a2": "What types of content are addressed in the data curation policies of MP-4.1-004?", "8349d22f-9d25-4658-b8b3-cd1272cebf29": "What are the potential risks associated with training data imbalances mentioned in MP-4.1-005?", "ca9771f5-5376-4ed4-a5eb-bf7bfd44817d": "What are the potential biases present in the training data related to the GAI application?", "6301f1c8-92ef-4b9e-ae19-fbaa2fb3698e": "How should user-reported problematic content be evaluated and integrated into system updates?", "421ffb8d-714a-4360-bbd8-d0ce44484071": "What information should be documented about the sources and types of training data and their origins?", "f274a9bc-de64-4e59-bc72-a513072966b6": "What are the challenges in risk mapping and pre-deployment measurement efforts for GAI systems?", "99cf76a0-f52f-413c-87cf-0bb62b29ddce": "How can robust TEVV processes be applied in the early stages of the AI lifecycle?", "4983da03-3f29-471c-a95d-b0e77e5f1a48": "What is the purpose of pre-deployment testing practices for GAI systems?", "6fed1b11-3d85-4962-8851-4d34a4182a76": "What is the main focus of the paper by Padmakumar et al. (2024) presented at ICLR?", "6489361e-c29f-4aed-8ace-a39b1f55acae": "What are the potential solutions discussed in the survey by Park et al. (2024) on AI deception?", "82a68f5b-56dc-4a90-9cf5-deb6ecfafdad": "What is the purpose of the glossary created by the Partnership on AI in 2023?", "83325787-b245-4bdb-99cd-cc2a56ad17fc": "What is data memorization in the context of LLMs?", "597a6ffe-d11d-4de8-8eb2-b3fa98243e76": "How can GAI models infer sensitive information that was not in their training data?", "641c2562-653e-4e1e-9992-a59f7abd5be0": "What are the potential negative impacts of GAI models making incorrect inferences about individuals?", "0e2b15b1-ac5a-4128-bbf5-d7c29e9589ae": "What does MS-2.7-008 aim to verify?", "67c11c8b-f2b6-4474-9b75-ecc5d58b0295": "What types of content are mentioned in the context?", "74cdabd5-0bac-472d-8f0e-ba0b4589b589": "What are the key areas of concern related to information in the context?", "cd6b7f9a-7e2b-4e64-80b1-769ebdca8ca3": "What are the limitations of automated error collection systems?", "7751ab58-e183-40fc-910e-630099f7538b": "How can organizations capture input from external sources?", "88744987-37a7-4e5c-8a2c-e61cdc7b3ebe": "What is the benefit of direct input from end users compared to indirect feedback methods?", "8fa895e8-870e-4e91-9116-09c229e51fb0": "What are some reasons for measurement gaps between laboratory and real-world settings?", "e19d8fbd-fe75-407a-b01a-e4f31f3388c9": "Why is it difficult to estimate the potential ecosystem-level risks of GAI?", "88a74477-790e-4ae8-837c-fb74fccf25ae": "How can structured public feedback be used in the evaluation of GAI systems?", "4a09009c-d79d-4934-9708-20cfe760c9c7": "What are the suggested actions organized by in the document?", "780fcf69-9fa1-47b3-b835-09c5fdef935a": "Why are not all AI RMF subcategories included in the document?", "8513d89f-ded5-4b8e-b76d-80b87c4b40d7": "How should the applicability of suggested actions to relevant AI actors be determined?", "f2707237-5fba-46ba-86db-927d01fc2420": "How can AI systems perpetuate and amplify harmful biases?", "bbc62157-c1df-4627-a030-2d1d2552c95a": "What are some examples of biases in current text-to-image models?", "728324eb-67ba-443a-8cb6-842d0692424c": "Why do image generator models struggle to produce non-stereotyped content even when prompted?", "ac60c253-935b-459c-8698-5c44e2f0f565": "What is the purpose of collecting feedback from users in the production environment?", "396f34f4-9adf-473b-af2d-f0fed868feab": "What are some best practices organizations should follow when implementing feedback activities?", "0c23e8a2-6245-4137-a7b9-f6fdfd06bb4f": "What is AI red-teaming and when can it be performed?", "326b96b2-786e-46e3-bf16-f3511b3eab12": "What does CBRN stand for in the context of dangerous materials or agents?", "6d7e47c5-2463-4bd8-8a65-bd995dfb2514": "What is meant by the term 'confabulation' in this context?", "a8f5362d-c931-424f-8313-24db7babc122": "What are the potential impacts on data privacy mentioned in the context?", "f579a21f-74fd-4faf-b15b-a58056300731": "What factors should be considered when updating or defining risk tiers for GAI?", "b0e2162f-490d-4a95-a184-d33dd6343657": "What are some potential psychological impacts of GAI on humans?", "234df316-1c52-4097-bc3b-7f0aba4cd014": "What are the risks associated with the presentation of obscene, objectionable, or offensive content by GAI?", "af2895a6-3774-4377-9376-a677b63a5342": "How does the background and expertise of an AI red team affect the quality of its outputs?", "3f439903-82cf-4ce8-88c2-b54454c06cbf": "Why is it important for AI red teams to be demographically and interdisciplinarily diverse?", "3d6526c6-fb86-4943-92a4-b9b8bcf2955d": "What should be done with AI red-teaming results before they are incorporated into organizational governance and decision making?", "f6cad27b-64bb-4e90-9c3d-722c214808b2": "What are the processes for ensuring operator proficiency with AI system performance?", "6a02cfe2-424d-4e10-b2d4-1dcdab36c8e3": "How is practitioner proficiency with AI system trustworthiness assessed?", "5078a3c8-89b1-4289-bcb7-5f2f0069a99a": "What technical standards and certifications are relevant to AI system performance and trustworthiness?", "2995a858-dd6b-45c5-ad03-2c49bb52f205": "What types of content should the filters prevent according to MG-3.2-005?", "13f23945-3dbf-41a1-a51b-a4c6948f6de1": "What is the purpose of real-time monitoring processes in MG-3.2-006?", "37cc92a5-7eaa-439d-8963-3d63e2a560e6": "What are the potential characteristics that real-time monitoring processes should analyze according to MG-3.2-006?", "23d3c6fe-68bf-4f70-88f6-86f9f150fdbe": "What does MS-2.6-007 recommend regarding GAI system vulnerabilities?", "67b6b83d-ed19-41d5-831b-a77026bd445f": "What types of information or capabilities are associated with MS-2.6-007?", "602bccd9-16de-4e0d-8e5b-c7e689b4c4a5": "Which tasks are listed under AI Actor Tasks?", "cc71e4fb-8127-4a57-a30a-223d7b7d3666": "What is the importance of robustness in watermarking?", "848fe714-d3be-4343-b167-d08dd2d0a60b": "How might an AI actor inadvertently affect computational complexity in watermarking?", "81612071-9f03-47c2-8cb1-e9c13e471ace": "What are some organizational risk management efforts for enhancing content provenance?", "f571d579-4bcc-4ebf-80cb-d265f66deea6": "What are some examples of inadequate pre-deployment TEVV processes for GAI applications?", "3cf86ac7-2544-4bac-8b19-aa41c77ad8ea": "Why might anecdotal testing through video games be insufficient for validating GAI systems?", "eb3e8119-50ff-442c-9f9c-581b9fccba57": "How do jailbreaking or prompt engineering tests fail to systematically assess validity or reliability risks?", "9e157215-e160-42f0-9940-a7eedd800ed7": "What are the suggested actions for assessing adverse impacts during GAI training and maintenance?", "640e771d-ec11-4ce6-9fe6-bab946c38b65": "What GAI risks are associated with assessing harmful bias and intellectual property infringement in system training data?", "910ff48b-0334-4384-a682-1cad37de4b13": "Which action ID corresponds to assessing the existence or levels of harmful bias in system training data?", "1b90ee95-ffd8-446d-9982-e7fb2f14e8f9": "What will future revisions of the profile include?", "1d590aeb-0adc-43e1-a1a9-6694ce9c419e": "Where will the glossary of terms pertinent to GAI risk management be hosted?", "874b6719-b17c-4c1e-8817-b81574016654": "What is the purpose of the glossary mentioned in the context?", "4e6bafd9-274d-4dcc-99de-617705ef4e04": "What risks can arise from misconfigurations in GAI systems?", "e6223b45-bdc8-49ea-8479-46194a54e93d": "Why might human experts be averse to GAI systems?", "6f257735-9da2-469d-9709-6d9acbf5dbdc": "How can human perspectives and domain-specific expertise impact interactions with AI systems?", "51b0493c-48c2-4fd0-9876-eee775f338c4": "What are some privacy risks associated with GAI systems?", "c13fd52d-c11f-4b14-a213-3110f7bd8b93": "Why is the use of personal data in GAI training problematic?", "39bfdeec-424f-4ec4-8896-68d39ce5dc44": "How does the lack of transparency in data sources affect user awareness in GAI systems?", "a76f1e30-4a7a-4b8f-a45a-20f951ece6f5": "What are the tasks of an AI actor?", "74d05314-a8d1-4f49-9535-b35e26f59da7": "What is involved in AI deployment?", "b2306c25-974e-41b8-a53a-4c9b99f5a80c": "What does governance and oversight entail in the context of AI?", "c88e7856-9ff9-4bae-a665-c4b05e96366a": "What mechanisms are in place to supersede, disengage, or deactivate AI systems that perform inconsistently with their intended use?", "b68b7385-f775-4a0b-8090-c7ce760fec82": "What is the suggested action MG-2.4-001 for managing AI systems?", "c4d83574-743f-4fee-8454-ba28b7b93bc1": "What GAI risk is associated with the suggested action MG-2.4-001?", "0068fb9e-25c9-4670-8c13-721f20dff28e": "What mechanisms are included in post-deployment AI system monitoring plans?", "4b7cf7cf-4b12-4b59-833a-0e538bf05bf1": "How is user input captured and evaluated in post-deployment AI system monitoring?", "c428fb7d-86e5-40ad-9c95-ddadb02c75bb": "What processes are involved in the decommissioning of AI systems?", "1d71875f-8c08-484f-82c3-de438caa8f4e": "What are some known issues reported from internal bug tracking or external information sharing resources?", "476d2be7-66bc-4224-8fa4-03107fe46512": "What roles and responsibilities are associated with human oversight?", "d3578bee-9a4c-4dd9-827e-fa8ee5ed78e7": "What special rights and considerations exist for intellectual property, licensed works, or sensitive data?", "9af90f98-5d2c-4105-83b0-e970d265773c": "What are the quality standards for AI responses to legal problem stories as discussed by Hagan in 2024?", "9c912932-3bcd-4232-8b75-052151b9bf53": "How does Haran propose to secure LLM systems against prompt injection?", "5d1cef3e-1089-45e4-81cd-efc5ebd9f3d3": "What is the focus of the Information Technology Industry Council's 2024 policy on AI-generated content?", "be9a0a91-bdff-4dd2-b631-44ef2366da06": "What are the main methods and considerations discussed in 'The Gradient of Generative AI Release' by Solaiman et al.?", "024ffac7-4e6e-4ffe-b2d1-f97a9b5d8ebe": "How do Staab et al. address privacy violations via inference in large language models?", "9832e45f-883e-4b30-a285-278d4ba0630c": "What energy and policy considerations are highlighted by Strubell et al. in their 2019 paper on deep learning in NLP?", "5fac11a2-0c6f-47b6-aea8-cc58afcd0e4c": "What are the suggested actions for documenting the risks and potential impacts of AI technology?", "c1380213-d6a3-4674-a607-83d2dfec0a70": "What types of content are considered risks under the action GV-4.2-001?", "230e767e-1a82-479b-bb41-e936d6f6617f": "Who should be included in the GAI system risk identification process according to GV-4.2-002?", "6bcb4762-9708-4d08-96d1-ca5a40787dd2": "What is the purpose of measuring the rate at which recommendations from security checks and incidents are implemented?", "d4f4e877-a639-4596-8e12-765dd8a9ca02": "What types of attacks are assessed during AI red-teaming?", "61e793d5-2b10-414d-b880-b0389a5d8eb5": "Why is it important to verify that fine-tuning does not compromise safety and security controls?", "16e0c278-2353-4bac-9d34-13f55dcfd3da": "What are the possible risk response options mentioned in MANAGE 1.3?", "f5f95617-5b3b-4b09-8d3e-ea76c19ef515": "How are high priority AI risks identified according to MANAGE 1.3?", "04c0d993-b109-4fbc-a728-ac1fad292ebf": "What steps are involved in developing responses to high priority AI risks in MANAGE 1.3?", "d69151d2-497e-46e3-aaef-d0c2633fcada": "What are the characteristics of trustworthy AI?", "f240ef33-75a4-43fb-b2fe-bfb4b40c428e": "What is the title of subsection 2.6?", "08ecf3cb-d8ed-43b7-9166-705c3aec34ff": "What are the two key characteristics mentioned for trustworthy AI?", "8057f2a9-eb6b-41b9-9bef-461f21678ac5": "What are the applicable requirements for evaluations involving human subjects?", "cba701c3-81d3-4127-b7ae-7d6abeead478": "How can evaluations ensure they are representative of the relevant population?", "94441c1d-66b2-45dc-8512-d92c796139e0": "What measures are in place to protect human subjects during evaluations?", "3981fa7b-81a0-4cdf-b647-702aa2ceb186": "What is the role of NIST in advancing artificial intelligence?", "87709ed0-e8bf-40b0-a709-8d71548d327c": "How long has NIST been conducting work on AI?", "35e06e6f-61d2-46b3-b2cf-59c71b03731c": "What is the purpose of the U.S. AI Safety Institute established by NIST?", "7aa28399-0959-4b13-8138-a5c7040f9b3a": "What are the characteristics of trustworthy AI?", "a42a8796-a18f-419e-a831-be2c8334ae7e": "How is high-integrity information described?", "0f212338-5636-4a48-bd99-58b4301be184": "What does high-integrity information distinguish between?", "e23187d4-b6b9-41f6-ac00-0c9243e2c67a": "Who are the GAI PWG leads mentioned in the acknowledgments?", "5bb48f7e-5a18-4839-a06f-e1bebab2e927": "What can organizations do to manage risks related to generative AI models?", "882611f5-a1d5-44f5-8c6c-8768867fec21": "What does the section on governance describe regarding organizational governance regimes?", "8326efb6-a167-4fbd-9451-079e5bda1778": "What are the key components of incident response plans for third-party GAI technologies?", "d555121b-6dfb-4636-b8f5-929d935ebf1f": "How often should third-party GAI incident response plans be rehearsed?", "2beb8161-c091-4623-a6d2-364d95133fe9": "What areas should be reviewed for alignment with incident response plans?", "49b317a5-52fb-4e41-bc76-8fe0247fe565": "What is the title of the publication mentioned in the document?", "6dc1cd6f-5572-49d8-ace9-680ba1fc3d92": "Who is the Secretary of the U.S. Department of Commerce as mentioned in the document?", "431939d3-3a91-4741-acc9-9acbba3a9617": "When was the publication released?", "7971e581-5eb7-4207-affa-4e763c1e7499": "What measures should be taken to review training data for CBRN information and intellectual property?", "ce14034d-394d-41b8-bcc4-c75c295a773c": "What actions should be implemented to handle outputs that reproduce particular training data?", "a8544122-f475-4dda-9764-18e026f542a1": "What are the key components mentioned in the context related to intellectual property and CBRN information?", "c085a65e-b936-42ca-9b78-c081598be595": "What are the primary information security risks associated with GAI-based systems?", "17a2cd51-26ed-43aa-ac42-ba003f5ee87c": "How does GAI expand the available attack surface in information security?", "702cc930-6c07-4c7c-b4f7-0775e07bc523": "What are some of the standardized practices in the field of information security for computer systems and data?", "c92616ee-a169-44d1-bc48-6faadb8e9718": "What is the importance of tracking provenance of training data and metadata for GAI systems?", "d82203da-ebab-4129-a8a3-f1a73e69706e": "How can documenting provenance data limitations benefit GAI systems?", "0a5d2612-ee53-45f2-80ef-16b73aad9a37": "Why is it important to evaluate how humans engage with GAI content in decision-making tasks?", "32c7ef17-6e72-4b8e-aeaa-55b74e90e322": "What are the tasks associated with AI actors?", "3569d3d6-9e07-4af7-a3a3-6e965f15a189": "Who are considered third-party personnel in the context provided?", "7d54f413-2ccf-41da-aaa3-3ae7eadc13e0": "What are the components mentioned in the value chain?", "5826180f-a9da-49df-bece-cbc4b57c5a3a": "How can integrating pre- and post-deployment external feedback enhance the monitoring process for GAI models?", "57c780f9-4dcf-4a49-b622-8bf7e82762f3": "What are some ways to capture and utilize user feedback for GAI systems?", "537d0319-00af-4c4c-8024-4921479aa934": "Why is it important for organizations to track and document the provenance of datasets in GAI systems?", "c2e66499-b410-4403-bdf2-c2ff122696d9": "What is the purpose of MS-2.7-009?", "5f019fad-2231-4c7b-bdc1-8d9f5cf06464": "Who is responsible for Al Actor Tasks?", "b4720ac5-c58e-4406-ba31-f3e47be1ae65": "What does MEASURE 2.8 address?", "db9cef96-42bf-47c3-854e-ba0baaf105af": "What policies and practices should be implemented to protect third-party intellectual property and training data?", "ebfe3f22-b4cc-415a-a60f-bfe621743516": "Why is it important to re-evaluate models that were fine-tuned or enhanced on top of third-party models?", "ac4a83ad-e86c-45fb-afb0-6ec1f00555a2": "What steps should be taken to re-evaluate risks when adapting GAI models to new domains?", "24bc1867-e66a-46a1-849f-ebc2fa2b45c6": "What is the main focus of Wu et al.'s (2024) paper on arXiv?", "754034ef-a755-4e8f-ae59-acc10ce4a035": "What issue does Yin et al. (2024) highlight about OpenAI's GPT in their Bloomberg article?", "3dabe28b-aea5-4d87-b950-1d6c12c7ae3f": "What topic do Yu et al. (March 2024) explore in their arXiv paper?", "af327a74-af56-46c8-8532-8d0b0af682b9": "What is the purpose of verifying deduplication of GAI training data samples?", "62a82e42-b552-4ecb-b668-9f2557e03ab9": "What are some of the AI actor tasks mentioned?", "b9e7d2a7-f227-46ba-8b1e-fc8e87f8c730": "What are the key concerns related to synthetic data in GAI training?", "43e6d1e3-3f38-43fe-be9b-e8717e1349f8": "What are the tasks associated with AI actors?", "53ce022c-6a54-49a3-8214-b6d570a90b30": "What does GOVERN 2.1 emphasize regarding AI risks?", "56ad42a9-e379-4cda-a1c6-920d7ba169b1": "What are some of the risks associated with GAI?", "04b9a74c-a775-48fc-b3c1-9dc93e10eb99": "What are some ways in which LLMs can mislead humans?", "23888d9c-92a6-4c17-99ac-98ea8c2d07fc": "Why is it difficult to estimate the downstream scale and impact of confabulations in GAI?", "edec6da5-9c6a-489d-aedf-a4e6ed972d0b": "What are the emerging areas of study related to the deception caused by LLMs?", "c07bd386-3fb0-4da2-a60c-8444508d49e3": "What are some techniques suggested for addressing general risks associated with a lack of explainability and transparency in GAI systems?", "b8e4f65a-f793-4924-944f-1450e5be874e": "What is the suggested action for Action ID GV-4.1-002?", "7146942c-3499-4232-b7e1-f3a75d4b8e4b": "What type of risk is associated with the lack of explainability and transparency in GAI systems?", "fd6a8085-2394-4c3e-808d-30d3ef50de90": "What should be considered when disclosing the use of GAI to end users?", "224796c6-6c26-46e0-b21f-5a336d097a4e": "How should public feedback processes for GAI be prioritized?", "cddb11d0-863a-4c42-9d87-fb28b030c64c": "What methods can be used to identify anomalous or unforeseen failure modes in GAI?", "945ab745-491a-4937-9c88-bb9bfcc31355": "What factors should be considered when identifying intended purposes?", "7399a888-0b30-45f9-aed1-e301c8de18d3": "What are the GAI risks associated with Action ID MP-1.1-001?", "4b737fe6-128a-4aec-a3c9-74667496ddb7": "What types of data sources are mentioned in the suggested action for MP-1.1-001?", "2fcb63e6-4e5b-46d1-ba59-b359bdc1bb6f": "What is the main topic of the survey conducted by Ji, Z. et al. in 2023?", "28336558-667d-4489-8221-10e6c3dbd00a": "How do people react to AI failure according to Jones-Jang, S. et al. (2022)?", "31a4a598-8b0e-43d0-b5c5-bbb88f85772d": "What is the focus of the literature review by Jussupow, E. et al. (2020)?", "c632a260-09a8-4444-9921-57592a1906ea": "What are the primary risks unique to or exacerbated by GAI?", "537e0fde-1b88-4d39-a45a-ffbe1b024699": "What topics are covered under the section 'Overview of Risks Unique to or Exacerbated by GAI'?", "1d4ee281-2c7f-4a50-8f61-a8a191615887": "What are the suggested actions to manage GAI risks?", "e27da130-ec88-4627-b7f2-20371b9030fb": "What is the main focus of the paper by Epstein, Z. et al. (2023) in Science?", "d21468c4-6cc2-4d48-8185-5902738fb163": "What is the topic of Feffer, M. et al. (2024) paper on arXiv?", "6df01b5c-f45b-4cdc-99fa-de1ac25727e7": "What does the Project Naptime by Glazunov, S. et al. (2024) evaluate?", "2bf27a17-b345-4419-b5c2-32cdae8a08b6": "What is the suggested action for Action ID GV-1.6-001?", "909a095a-c296-41ba-a210-4b9f4f49dc30": "What GAI risks are associated with Action ID GV-1.6-002?", "2e4c64c4-40b2-4d02-b1a8-3f5e5784ddc2": "What additional items should be considered in GAI system inventory entries according to Action ID GV-1.6-003?", "bb54cd7d-b904-4009-8be2-da704bf9d193": "What should be developed and updated to address newly encountered uses in the GAI system?", "2449578f-53f7-4b76-9b8b-d3b8da261d51": "What details should be included in the response and recovery plans to communicate with downstream GAI system actors?", "42f04cd1-e2b7-4a2e-b192-867b1ca3a83e": "What is the Action ID associated with the suggested action for managing GAI risks?", "a8a1bf7d-841c-42ac-9d0d-2d0b23a739e5": "What is the purpose of provenance data tracking?", "d5f001e1-73e1-4789-996d-6810e06231a7": "How do synthetic content detection mechanisms assist in GAI risk management?", "63387363-e113-4acb-8aea-43a6842da1c3": "Why is it important to improve information integrity and uphold public trust?", "57753e88-93da-4d1a-b6b1-9ce794b408bc": "How can generative AI models assist malicious actors in creating disinformation campaigns?", "57ca5698-79f2-4b8d-9600-6b6cdcac0011": "What was one example of disinformation facilitated by generative AI that affected the stock market?", "f49dd86e-58a0-4dab-b6f5-04c7304cd2a5": "In what ways can generative AI models help in creating fraudulent content?", "9fc1de1e-029c-44bc-9d24-9bcc1574032b": "What is the purpose of the AI Risk Management Framework (AI RMF 1.0)?", "82acf678-48d4-462c-8674-def2ae11e329": "When was the AI RMF released?", "1677c631-40a5-4545-a195-92a8beeee5ba": "Which Executive Order is the AI RMF 1.0 pursuant to?", "fd4aa93d-bb22-4e9a-8854-a698ff7805fc": "What are the potential negative consequences of spreading explicit or obscene AI content?", "018dcb93-b0da-4f77-99e3-eeb1a2e90a13": "How can the creation and spread of NCII impact women and sexual minorities?", "cc7f47f3-f78b-4645-a360-46bd26f0c1d8": "Why is the inclusion of CSAM and NCII in GAI training datasets problematic?", "7932d028-391a-46c5-8ca3-7f78cbce424c": "What are the criteria for the kinds of queries GAI applications should refuse to respond to?", "22733028-d016-4f7b-90ee-2fb54f468a81": "What policies should be established for user feedback mechanisms in GAI systems?", "3a192895-0484-4aef-8ed0-1dd84f93c256": "Why is threat modeling important for anticipating potential risks from GAI systems?", "f462b01f-7dd3-4513-a388-3ecf8b7af707": "What is the purpose of the GAI PWG?", "441e7a32-ee67-4fea-806c-70d724993f48": "Where will the glossary of terms pertinent to GAI risk management be hosted?", "f62aab03-cb74-45bc-8032-18a5b5fed7d1": "What were the four primary considerations relevant to GAI discussed by the GAI PWG?", "9c247527-5918-406a-bc43-a36d7d6d1837": "What are the suggested actions for GV-3.2-001?", "5f6f7ba7-2697-48d4-85c7-0fe8c5072dda": "What GAI risks are associated with GV-3.2-002?", "7136118c-c3af-4a6b-89b6-8f8f0bb7dfb2": "What does GV-3.2-001 suggest regarding the evaluation of GAI models or systems?", "c01b9ce9-149a-4556-b79c-1c65ef6014a3": "What is the purpose of conducting adversarial role-playing exercises, GAI red-teaming, or chaos testing?", "3a70120b-eb4e-4560-96cc-9899b083fd3f": "What should be profiled to understand threats and negative impacts from GAI systems?", "11145ffc-bbaa-471e-9380-d16e3888be36": "What is the focus area for both adversarial role-playing exercises and profiling threats in GAI systems?", "2fd9371d-db67-4778-851a-ebe6e481ea99": "What should be established before developing highly capable models?", "ddc48379-18fe-444f-80f3-dd905af290d0": "What types of information or capabilities should be periodically evaluated for misuse?", "ca8b8608-f767-4c50-ba26-f5317969c41d": "What are the two main categories mentioned in the context?", "21fcd711-e1b8-4248-bbd9-884cc00b6500": "What are the phases involved in the deployment approval process?", "100d5a02-a673-4a9e-81f6-4cf131c4eadb": "What are the tasks associated with AI actors?", "9d09e2a1-4909-4d31-bb21-df0107eefe78": "Which areas are covered under Human-AI Configuration and Information Security?", "10bb791c-a341-4d23-b799-0e125ae76c45": "What is the purpose of field testing in the context of GAI systems?", "6a9ebdf0-39da-4d18-a05e-e3d7f7232a23": "How can field style tests be adapted to focus on AI risks and impacts?", "fe1825dc-9ce7-4c8b-a5f5-06e6b52fb0a3": "What can large group field tests estimate in real world interactions?", "67367c97-01de-4084-8746-ae1e871b0fbf": "What are provenance data tracking techniques used for in GAI systems?", "cdf16b65-50b3-4be9-9c82-29ba54a0c648": "How does provenance data tracking help determine the authenticity of digital content?", "e2f47d8d-56c0-4fd6-bce4-f23e8472cccf": "What impact can early-stage model decisions have on downstream performance and synthetic outputs in AI systems?", "142f0174-4bb2-4137-b889-491a22ac7140": "What are some potential risks associated with third-party GAI integrations?", "cd3981cf-8329-4b6b-b860-db642d1be5fa": "What measures can organizations take to manage risks related to third-party data for model inputs?", "3c825e2b-5db7-4036-a487-f0240e0c6346": "How can organizations ensure transparency and risk management when using third-party GAI technologies?", "5b8ac0f1-7737-4c2d-8b26-b6e531edcdfa": "What is one potential risk associated with GAI systems?", "bcacd08c-7b82-4a60-8b95-44473c7371b8": "What type of content can GAI systems unintentionally produce or disseminate?", "df183248-aefe-452d-ac29-7abcf4c149fa": "From which document is the definition of information integrity derived?", "de0720b1-a621-42de-a385-b2350fd1b4c6": "What are the main findings of Wang, X. et al. (2023) regarding the energy and carbon considerations of fine-tuning BERT?", "040222eb-de5c-4695-b94d-c220de09d033": "What is the purpose of the dataset introduced by Wang, Y. et al. (2023) in their paper on evaluating safeguards in LLMs?", "062c3714-53b3-4c24-a07f-4c3f0a5fa08e": "What issue does Weatherbed, J. (2024) discuss in relation to Taylor Swift AI fakes on X?", "38b18845-87e8-4693-a979-324461d936c8": "What are the key considerations for conducting diligence on training data use?", "b7468175-bb4f-492f-bd1b-c9bc9837b220": "Which AI actor tasks are involved in the governance and oversight of training data?", "962321d8-fb2b-4d0b-9f03-412135436963": "How should the likelihood and magnitude of each identified impact be assessed and documented?", "2234d8cc-0452-4b45-a50b-7a2e460a7ec0": "How might GAI systems enhance cybersecurity attacks?", "2c16e123-afb7-4cfa-afb2-acdc881edbde": "What are some ways LLMs can exploit system vulnerabilities?", "fa7ae38b-d064-467c-a457-b2b4409cfbf5": "How could sophisticated threat actors use GAI-powered security co-pilots in cyber attacks?", "6ab33b13-d6e8-42bb-af25-b83fd8c230a6": "What does MEASURE 2.9 emphasize about the AI model?", "ffc72db3-ccff-44c8-aed6-0e2cb09392a5": "How is the AI system output supposed to be interpreted according to MEASURE 2.9?", "eec14042-5499-484d-88a8-10f6d617ea3e": "What is the purpose of explaining, validating, and documenting the AI model in MEASURE 2.9?", "d266d121-9b4f-4ad7-95d9-67c67de75151": "What is automation bias?", "a0cbfadb-b580-4ba0-b146-0d77c9df5df7": "How can automation bias exacerbate the risks of GAI?", "6e231a6f-1da7-4b74-8e11-872263b64c7d": "What are the potential negative psychological impacts of emotional entanglement between humans and GAI systems?", "53b2cda9-7391-456a-9824-98500481321b": "What is the main finding of Dietvorst et al. (2014) regarding people's behavior towards algorithms?", "4f9bf1ce-9b9b-4cbd-9450-d02f4a6e4d5e": "How do companies learn consumer secrets according to Duhigg (2012)?", "3f9aa814-4017-4a6a-843a-c88d33228dc8": "What impact do altered images have on humans and machine vision as discussed by Elsayed et al. (2024)?", "f9f68014-ee2e-4ede-951e-0c1e13110986": "What are AI Actors expected to be aware of in their roles?", "1d7669eb-2f95-4ad0-b31c-1bf9064aa6d7": "Why is it important to document and review third-party inputs and plugins for GAI systems?", "73f3d61c-78c7-4227-b344-0a9e370c35da": "How can organizations help AI system operators identify GAI incidents?", "7535bfc2-c7d9-40ae-b7da-ed0afd66410d": "What are some sources of risk associated with GAI models?", "8e3cdafa-3c8e-495e-b6b2-d8fa57724885": "What does the term 'algorithmic monocultures' refer to?", "35b80da1-4403-4848-aa16-52eb81128301": "How have studies projected the impact of AI on the workforce and labor markets?", "8f94d56c-2345-47cb-b963-67f6ddf46667": "What is the purpose of conducting adversarial testing as suggested in action MS-4.2-001?", "37c6b9ec-4a23-4cc9-a8cd-83ddfccddefa": "What are the GAI risks associated with action MS-4.2-001?", "59fa8674-109e-4c8b-a0fb-f1608df02e70": "Why is it important to evaluate GAI system performance in real-world scenarios as suggested in action MS-4.2-002?", "e3343000-2c51-448e-b036-a74b1a7c6a98": "What are the unique risks associated with the development and use of GAI?", "2755d281-de6e-46b9-b9f9-db5eb48be822": "How are the risks labeled according to their outcome, object, or source?", "3ec006f7-c6ca-4f4f-8ef3-5cff129fa23f": "Where can organizations find the mapping of each risk to relevant Trustworthy AI Characteristics?", "cd609f38-aa76-43f3-a742-b3eae329d78a": "What is the purpose of examining and documenting the privacy risk of the AI system?", "1efcde42-234c-43c1-b58e-dd099356d09d": "How is the privacy risk of the AI system identified in the MAP function?", "7da940a2-a560-4e43-8bdd-cbcfc5d0c85b": "Why is it important to document the privacy risk of the AI system?", "f1e4fcd4-fdc7-453a-b319-c4f609bfd512": "What methods are used to measure the reliability of content authentication?", "6618d2bb-d85d-46f6-8120-65ce08178b3f": "How is the rate of false positives and false negatives in content provenance evaluated?", "2c44e7ef-635c-441f-8d27-586114e2b6fc": "What is assessed to determine how quickly the AI system can adapt and improve?", "e01cf7f2-b002-4e92-8b17-0238429e2aea": "What is the focus of the study by Said et al. (2022) on nonconsensual distribution of intimate images?", "32f48457-aa6f-41e3-83a9-22755927661d": "How does Sandbrink (2023) differentiate the risks of language models and biological design tools?", "928007b2-8df3-43bd-aac8-652a0af7883e": "What issue is addressed by Satariano et al. (2023) in their article about fake onscreen people and disinformation?", "1a6afd4a-a0be-4e43-8f2b-1cb227ae71aa": "What are the policies in place to define roles for human-AI configurations?", "667ac62b-8e5e-4bdd-b974-07def2875ba2": "How do the procedures differentiate responsibilities for oversight of AI systems?", "3fef3f56-5c95-47f2-aa21-ccf9aa2d147c": "What roles are defined for human involvement in AI system oversight?", "e24796b2-24f7-45cc-ab47-8444de207eb7": "What are the legal debates surrounding GAI and copyright?", "e175788a-3fa3-44c2-96af-a9c242801fc6": "How does GAI impact the production of non-consensual intimate imagery?", "abdac4d9-a354-4bba-8096-da751e52709f": "What are the characteristics of trustworthy AI?", "08d4a7eb-b8b7-4f2c-aac5-98e47e3337c8": "What methods are suggested for quantifying harms in generated content?", "79afece1-1196-4851-8fa0-a82fc080ad58": "How can general fairness metrics be applied to ML pipelines or business processes?", "bb87051e-aebd-4537-bdd3-5d081869ea4a": "What is one way to measure the prevalence of denigration in generated content?", "f0f81257-f8ec-47da-a191-78feb75c59e8": "What are some challenges in estimating GAI risks?", "410bacc7-58e9-4e19-846d-19d8aa9a6378": "Why is it difficult to properly scope or evaluate some GAI risks?", "3b415973-814f-4a83-bb22-4aa56da4237f": "What does this document focus on regarding GAI risks?", "75bab8f7-75f7-4d93-9bea-c06bc705f19b": "What is the suggested action for Action ID MG-1.3-001?", "3a0ce3b9-5404-4bc6-b1ff-480001b7c20a": "What type of risks are associated with Action ID MG-1.3-002?", "23afb205-9a08-4deb-ab89-1d1c9eb571fd": "How should risks that surpass organizational risk tolerances be handled according to Action ID MG-1.3-001?", "fcb42eaa-7158-4118-a146-50e9afe6ff84": "What are the key components that should be included in contracts and service level agreements (SLAs) for GAI systems?", "e199b364-3578-42d0-8504-ea87d7b16293": "Which aspects are emphasized in the GV-6.1-004 guideline for GAI systems?", "613bf97a-2daf-4314-a1d3-85a5fc617d06": "What are the main focus areas mentioned in the context for ensuring information integrity and security?", "7dad0f74-c35d-4852-ba65-c1ffad4e23d2": "What is the purpose of utilizing a testing environment such as NIST Dioptra?", "18337a1d-bade-4c36-8a1c-f13d7672b0c7": "What are some of the trustworthy characteristics evaluated in the context of GAI?", "18f2b752-e70f-4185-b604-b230183b63a7": "What does MEASURE 2.5 state about the AI system to be deployed?", "e0030ca4-2c22-409c-843e-e37c4d65ac54": "What methods should be implemented to evaluate GAI system decisions and verify alignment with their intended purpose?", "05c29312-43a7-4d8d-9e11-4638e4f89de7": "Why is it important to monitor and document instances where human operators override the GAI's decisions?", "4f949a5b-24c6-4317-ab25-0135db709f14": "How should the incorporation of results from structured public feedback exercises be verified and documented?", "a1aeb024-c2d3-4370-9765-b0c44e390c2f": "What are the policies and procedures for continuous monitoring of third-party GAI systems in deployment?", "371a37c6-df8d-4047-ab80-981b46e03012": "How should policies address GAI data redundancy, including model weights and other system artifacts?", "e2f35e7c-9622-472a-a2bd-1913f7caad5e": "What are the risks related to rollover and fallback technologies for GAI systems, and how should they be managed?", "7da9338d-50c8-4db0-a2fa-ee088ffa944c": "What are some tools mentioned for monitoring third-party GAI risks?", "8fee4b18-2d1a-4be6-9a77-11087e0849be": "What should be considered when updating GAI acceptable use policies?", "16aa7e66-0071-4c7a-93ca-fa8288cca767": "What areas are impacted by GAI technologies according to the context?", "084a2933-0f58-4bb2-8fae-e308e591501d": "What is the main finding of Northcutt et al. (2021) regarding machine learning benchmarks?", "7148629a-cec9-4eec-953b-c0601c1bd401": "What is the focus of the OECD (2023) paper on AI?", "9bed5ffc-85e0-45e0-93f4-48828fa264a4": "What is the topic of the OECD (2024) paper on AI?", "ab38f189-be02-44fe-a67b-414757285d87": "What is the focus of the study conducted by Carlini, N. et al. in 2024?", "cb9ab4cb-56a9-4120-80e5-8df8e5903c42": "How does the research by Chandra, B. et al. address Chinese influence operations?", "e107b0c5-087e-4bc9-90d1-d62ee6f4e3ac": "What ethical tensions are explored in the study by Ciriello, R. et al. regarding human-AI companionship?", "c97a3aff-f569-415b-9307-abf66c30bc9e": "What are the key aspects to review and document in the data used at different stages of the AI life cycle according to MP-2.3-002?", "a8cebcdb-e3c2-4e77-8761-454dd6ac633d": "What is the main focus of MP-2.3-003 in terms of verifying information generated by GAI systems?", "ed469baa-9bfa-4907-916e-547c946b1ded": "What techniques are suggested in MP-2.3-004 to identify GAI produced content that might be indistinguishable from human-generated content?", "001444b2-5897-4b42-ae90-6a6fc684f23b": "What are some of the risks associated with using a GAI system in a new domain?", "55e9f080-ead1-4b05-a24a-1b23a53a9d5f": "What approaches can be leveraged to detect the presence of PII or sensitive data in generated outputs?", "9c2affae-ddb2-4418-b333-5c05bcc6693c": "What types of content are considered dangerous, violent, or hateful?", "fcbb95cf-1a87-456c-b81c-af17136cf37c": "What are some of the content types mentioned in the context?", "fdcb4a23-5a56-4903-a6f7-6898c94513a6": "What is the purpose of establishing minimum thresholds for performance or assurance criteria?", "7a453d1d-8f05-4636-93f3-33af3c57a038": "What should be established before developing highly capable models according to GV-1.3-003?", "b0562c84-e78f-4432-9162-3cb9b909a262": "What is the purpose of tracking and documenting instances of anthropomorphization in GAI system interfaces?", "984c64a5-9fea-4dfe-98c1-1ff71440c432": "Why is it important to verify the provenance of GAI system training data and TEVV data?", "223eaafc-6d6a-40b1-9c65-ea49045978ed": "What should be regularly reviewed to ensure the security and safety of GAI systems, especially in novel circumstances?", "07b0b2c8-558c-45d8-9e46-0988beda6b6c": "What are the suggested actions for managing GAI risks according to Action ID MG-4.1-001?", "69d07d7b-32c3-4daa-a386-6f62acd74e6e": "Which GAI risks are associated with Action ID MG-4.1-002?", "a4a62b16-8a25-4d3a-9651-40702f06a58f": "What is the purpose of using sentiment analysis in the context of GAI according to Action ID MG-4.1-003?"}, "relevant_contexts": {"9c2d9eb5-a293-4e0c-b122-bd1963daab3a": "9161a736-2a62-41c4-8cf6-6a5315c2a0c6", "6895a425-eb3f-47b9-848e-add92d6d5c70": "9161a736-2a62-41c4-8cf6-6a5315c2a0c6", "ec07c62b-dd53-4fb3-9cb8-74f4301708be": "9161a736-2a62-41c4-8cf6-6a5315c2a0c6", "f4e85515-03ae-4587-8b59-ede9b6951b56": "7eead893-2928-4389-b069-6d651b32bf77", "e1555b40-d296-4353-80ff-0934d5c77a24": "7eead893-2928-4389-b069-6d651b32bf77", "e558ad70-d5d4-4a18-aabf-4fca7146f26e": "7eead893-2928-4389-b069-6d651b32bf77", "60059c6b-aae8-495f-b957-187ecab02a98": "0ea41951-cec7-4df6-8c46-dbcd744b6690", "55c94c94-fe71-469c-8069-a76dc273c082": "0ea41951-cec7-4df6-8c46-dbcd744b6690", "d2aa9c8c-4a6a-4617-913c-6fe65da6d8d8": "0ea41951-cec7-4df6-8c46-dbcd744b6690", "0e454dac-e4b8-4c15-963a-78ce685cb1be": "171c06e5-4719-4053-922c-e86c096b3357", "2c565955-fb27-4341-b4ab-02ca5f72411b": "171c06e5-4719-4053-922c-e86c096b3357", "ceb69d60-277e-45f4-b019-73bbe3be3a37": "171c06e5-4719-4053-922c-e86c096b3357", "f8e693c5-774f-48db-9bb2-26acfd3b001e": "c3c7b920-2fe0-44fa-8d55-6b4464dc05d9", "2fc8e679-8689-4414-91b1-69172387bf93": "c3c7b920-2fe0-44fa-8d55-6b4464dc05d9", "37585477-079c-41d6-8479-65305bf47de2": "c3c7b920-2fe0-44fa-8d55-6b4464dc05d9", "18df8820-99f0-438d-b552-97b4cb30ba7f": "f890c025-39dc-42fa-b0bc-4e7d46039ee2", "0fcd8cbe-c85a-40fa-a506-553b43538286": "f890c025-39dc-42fa-b0bc-4e7d46039ee2", "16ef7147-44f5-46be-bb2e-f17de1efe333": "f890c025-39dc-42fa-b0bc-4e7d46039ee2", "6e5226a7-0b66-453e-950c-5e4b45f79023": "70dd5374-c009-4fad-a19d-c12d56ff8975", "211c49fb-d396-49d2-abb6-73b44d8fb117": "70dd5374-c009-4fad-a19d-c12d56ff8975", "c98afcc3-e2c7-47ee-af29-d77acdd96eb4": "70dd5374-c009-4fad-a19d-c12d56ff8975", "1100972a-045d-432d-aa65-8777dcb7e9bd": "ffd00e87-88d3-43ca-adbf-0918a62ed76b", "962d0a12-b61b-4462-8bf0-c9e8f8e7e718": "ffd00e87-88d3-43ca-adbf-0918a62ed76b", "198f5c5d-4180-4d7b-ba10-55d826cab6ec": "ffd00e87-88d3-43ca-adbf-0918a62ed76b", "0ab39737-8311-4850-94eb-f8496c6462e4": "0c17417f-33cc-4171-b8f8-5ee155b771be", "e83ba326-4d25-4dd0-994f-3c02783efcfa": "0c17417f-33cc-4171-b8f8-5ee155b771be", "8a936339-3d9f-4e30-a7b9-dfdc16d126b5": "0c17417f-33cc-4171-b8f8-5ee155b771be", "563bed35-13a2-4b9f-bb2c-abb2d9310e93": "0c80df65-0d09-4ede-845b-7b25a7bb307c", "2b640898-9b6d-41e9-bd84-d7b70770324c": "0c80df65-0d09-4ede-845b-7b25a7bb307c", "02bf410c-b4fc-4869-a4f5-3aeb9267eefc": "0c80df65-0d09-4ede-845b-7b25a7bb307c", "a57029a1-d4fb-4f93-bd24-7e84dec626fb": "89fed44f-2be1-449e-99c9-675a89d42644", "000f37af-82c2-4945-80c8-dbdd54fc1ae5": "89fed44f-2be1-449e-99c9-675a89d42644", "d5c07b66-05db-4ba9-8052-c6fb7ee46352": "89fed44f-2be1-449e-99c9-675a89d42644", "87f0655e-7ea5-4466-8845-80ca99b15e61": "0a9b7805-d861-4276-80b7-36dbc5313d0b", "3adf278b-8d40-4fae-afc2-5f8cae71f093": "0a9b7805-d861-4276-80b7-36dbc5313d0b", "6af2c5c6-ac26-4796-ad18-fea1310d7e0b": "0a9b7805-d861-4276-80b7-36dbc5313d0b", "62d5e2c8-2dde-479c-8d43-f0fc4336748a": "c9075a91-8c00-4d14-9cd0-0bb2a3bdc293", "c7e80515-0b66-4964-bda6-be20b68fc0e6": "c9075a91-8c00-4d14-9cd0-0bb2a3bdc293", "d4a2a7c7-f709-42c6-9dd2-f2f5acb7dbec": "c9075a91-8c00-4d14-9cd0-0bb2a3bdc293", "b59e8529-a07d-4d11-8584-755addd08c28": "93b2aabb-5668-456d-826f-9e483f8c79e1", "a8cb315e-1949-495c-b100-e9d488d55000": "93b2aabb-5668-456d-826f-9e483f8c79e1", "f10a20e0-51de-4215-b475-f49b2f21909d": "93b2aabb-5668-456d-826f-9e483f8c79e1", "8d30f395-6c74-496a-bc0f-b3167d082965": "0fbcf439-40ef-4564-87ea-4fd13c813b08", "9d735da2-28d3-4b07-89e9-16954494aa08": "0fbcf439-40ef-4564-87ea-4fd13c813b08", "118b68e2-e3c3-4f45-938d-854e974b115f": "0fbcf439-40ef-4564-87ea-4fd13c813b08", "b5a7055d-a03a-4938-9ef5-7256f9dd4f9b": "24a703b1-f544-435c-9bc6-bfbc1e7103ff", "0f9caa17-dde6-4b36-84e2-63e5a60981f9": "24a703b1-f544-435c-9bc6-bfbc1e7103ff", "b845e850-d861-4c40-8af8-09fccd13ea7c": "24a703b1-f544-435c-9bc6-bfbc1e7103ff", "c6cfe22a-3fbc-4cc0-96e1-c8afd64bf40c": "3352ac1d-c98f-4f16-939a-f57508d88720", "11906b39-952e-4f8e-8382-68205dbcfe2e": "3352ac1d-c98f-4f16-939a-f57508d88720", "8cae404f-5113-4881-9d65-ba63120b6448": "3352ac1d-c98f-4f16-939a-f57508d88720", "227401b6-dd77-4d18-a69d-b4f761723af9": "8175e95c-3e47-48b5-9ef7-19a410e68b6d", "d778d462-b018-4699-9617-f4e77bb6d0f7": "8175e95c-3e47-48b5-9ef7-19a410e68b6d", "a1115346-4d43-452b-a64a-df10936cda70": "8175e95c-3e47-48b5-9ef7-19a410e68b6d", "b666d389-5261-46e6-ba42-b594e60a014f": "092bca1e-0e18-4fec-9289-b464162397cb", "de355539-0ada-4162-a2d7-d549c6a683bb": "092bca1e-0e18-4fec-9289-b464162397cb", "a81dce1b-2b58-45dd-8a0f-31bf4b59425c": "092bca1e-0e18-4fec-9289-b464162397cb", "11a6ffeb-c391-4d27-960f-90143f86534e": "16c6ba6c-de0d-4c20-8a64-86a2790d0bca", "174640f0-bbd0-42ca-b74f-9d9abdd44ea4": "16c6ba6c-de0d-4c20-8a64-86a2790d0bca", "588ceed0-7e76-4023-a91f-0f1187841e46": "16c6ba6c-de0d-4c20-8a64-86a2790d0bca", "59054ca6-7348-489a-b926-a883d7cae53d": "da9d5dbe-998b-4474-8c39-9a4a0ca22b2f", "0d344cae-a3a0-4b9d-94d4-d4879fa05e01": "da9d5dbe-998b-4474-8c39-9a4a0ca22b2f", "a01b0910-5170-4410-878f-fbecf80c61f4": "da9d5dbe-998b-4474-8c39-9a4a0ca22b2f", "0f6f3b60-9baf-4f22-a144-244d0d85d9eb": "a01d290c-19eb-4caf-b211-d49cee535f72", "444f7fca-c569-4ce9-b66e-504dba08223f": "a01d290c-19eb-4caf-b211-d49cee535f72", "9d9ea7fe-34f3-454c-a193-f1c574c39360": "a01d290c-19eb-4caf-b211-d49cee535f72", "d0e54ecb-f127-449e-9364-ee839b61fb78": "06446d86-e099-467f-b494-621f4345641a", "669a3df5-1deb-448d-92fb-148df254c8e9": "06446d86-e099-467f-b494-621f4345641a", "a1568d30-27c8-4308-b373-4acddde94028": "06446d86-e099-467f-b494-621f4345641a", "1d56b5c0-8b8d-4fe4-b1e4-77d6193ca9cb": "840c3dae-54ec-4d6f-b829-a2fb4103092c", "321bfb4b-c8d3-408c-8473-86e97c08296b": "840c3dae-54ec-4d6f-b829-a2fb4103092c", "293fde39-5b27-40f8-9d4c-97a5fa4fa282": "840c3dae-54ec-4d6f-b829-a2fb4103092c", "a09e63de-1bcb-4a34-8a5f-20f1c3b8d76c": "9ca34088-590c-495f-94c8-a99b70160c4d", "beafb995-819a-4d98-8e6b-24f2c157609a": "9ca34088-590c-495f-94c8-a99b70160c4d", "e8704c30-169e-4fd6-a106-83f725e4e8cf": "9ca34088-590c-495f-94c8-a99b70160c4d", "958d6b97-ab86-4463-8c77-3e1e5e534c05": "3dc89929-2e98-4ecf-8b22-faaf87a516f2", "aa460aa8-d766-4f8e-8c6e-022d8edd7fc9": "3dc89929-2e98-4ecf-8b22-faaf87a516f2", "6ba9db36-f3f4-4185-b313-2e755087eac1": "3dc89929-2e98-4ecf-8b22-faaf87a516f2", "92d9108e-0a00-4681-b284-9dc21d773145": "8cc336a0-a911-4c0a-a01b-ea4b40c6d11f", "b19a7714-9334-4bf3-9f8d-90f026dc4934": "8cc336a0-a911-4c0a-a01b-ea4b40c6d11f", "558262b5-42ed-4c4b-bc39-53eeaf46161e": "8cc336a0-a911-4c0a-a01b-ea4b40c6d11f", "0e73070e-ce83-434a-8b30-2e748700272a": "e34998d5-79b9-4db2-b78e-d8519a730216", "ded5507b-84a2-40ef-8862-5feb557cc4b2": "e34998d5-79b9-4db2-b78e-d8519a730216", "84b782b7-6be1-4303-9c1e-4912165710d2": "e34998d5-79b9-4db2-b78e-d8519a730216", "28ad504c-f099-4439-9f61-a29b99173a15": "862657d4-7294-4e88-b032-582de9ba3946", "d23f8776-90e8-42e5-b94e-39b30d4a51a8": "862657d4-7294-4e88-b032-582de9ba3946", "9944066d-3b2b-43f3-be99-803985db71dc": "862657d4-7294-4e88-b032-582de9ba3946", "43365979-5135-40b9-abdf-b80aa7dd34ca": "eb2b7cf1-71f0-426f-a3c7-b26af70f3863", "6cd5b3af-603e-451e-865f-5de6b3e6f076": "eb2b7cf1-71f0-426f-a3c7-b26af70f3863", "ac9da121-2c8c-4952-b0a7-4f720d392cb6": "eb2b7cf1-71f0-426f-a3c7-b26af70f3863", "7e6a5ec1-98e7-4391-b702-4d8ebd8e984a": "b0a0ab32-b8ca-4e91-8b7f-a184416ffff4", "9a90a57c-2fdd-4363-bcd2-89f801366ecb": "b0a0ab32-b8ca-4e91-8b7f-a184416ffff4", "ac3b24f6-945e-4a5b-ab4b-c15da635dcd3": "b0a0ab32-b8ca-4e91-8b7f-a184416ffff4", "46d0462d-f3dd-4799-b4ab-6c55de5a5133": "cb928105-97e4-4166-896b-184965b82df9", "c13d7fd9-e83c-4eda-afcf-a6b36b5847b6": "cb928105-97e4-4166-896b-184965b82df9", "fb363968-b46d-4edb-9f07-f99ef12ab936": "cb928105-97e4-4166-896b-184965b82df9", "a93fa0c1-4438-42a0-8d83-29ee326c82f3": "77ea8f36-bfe3-41e3-88b8-aa8ab8b901e4", "68638a7b-3555-4ac2-9f9c-8236791f517e": "77ea8f36-bfe3-41e3-88b8-aa8ab8b901e4", "d281a61e-1e7f-4964-9fbf-1524549f3e38": "77ea8f36-bfe3-41e3-88b8-aa8ab8b901e4", "e642f7d1-3aef-4219-a073-d831ac7216e9": "2eb135e6-e8d2-4296-996d-4d654a0cf8e1", "d8bd89d0-0e30-445d-9139-22ca6a98e797": "2eb135e6-e8d2-4296-996d-4d654a0cf8e1", "956afdc6-7963-42f0-85ef-195ca20d21d8": "2eb135e6-e8d2-4296-996d-4d654a0cf8e1", "c3931043-efbe-4c22-862b-ca9f6a1a7124": "4ff0b13b-9b0d-4a63-8238-2cd2001c909e", "5336b2cc-f741-4681-b76e-b192319686bf": "4ff0b13b-9b0d-4a63-8238-2cd2001c909e", "08242812-c92d-4573-a9ce-de5b4e7fa5b3": "4ff0b13b-9b0d-4a63-8238-2cd2001c909e", "b5bc58f5-c5e2-4c05-bfcc-d11f047eacce": "afbb4cf0-dd4f-4fea-b2b7-7df57dd24db9", "2089bcb3-7bfc-4cbc-8c26-864168670262": "afbb4cf0-dd4f-4fea-b2b7-7df57dd24db9", "8acb7434-0230-4a13-8bd0-2a5a5ab4cb11": "afbb4cf0-dd4f-4fea-b2b7-7df57dd24db9", "aca9d2cb-4872-43db-85ce-756871defb36": "67d9669d-28b4-4d8e-8c19-6d3993502132", "a6b4d7d7-083b-470d-b390-e6060b1c0f19": "67d9669d-28b4-4d8e-8c19-6d3993502132", "7bfe235e-f536-43aa-8038-0f6872ea533a": "67d9669d-28b4-4d8e-8c19-6d3993502132", "ba91bdc1-8fe9-4e14-a5c4-61cc8252394b": "11cbe233-c373-4d4d-9ea5-271ab89d7bed", "656724c0-7ab3-42f6-bb40-e69bd4b9d3e1": "11cbe233-c373-4d4d-9ea5-271ab89d7bed", "6e05f16f-5886-40c5-b3b1-39b1995b8ea8": "11cbe233-c373-4d4d-9ea5-271ab89d7bed", "43ba0754-c45b-43ef-afc6-512431587781": "313ac852-bb2c-4129-ac8f-fb25bdc7e28a", "dbad9e30-29de-42a6-b7af-959f9627c468": "313ac852-bb2c-4129-ac8f-fb25bdc7e28a", "59890393-2d5b-46cb-a9af-4c9e5072544f": "313ac852-bb2c-4129-ac8f-fb25bdc7e28a", "8d7d25fb-96bf-4eee-a5f4-2a9dc4ee81bd": "8047c3d0-4c90-4acf-960a-b4dde5c133f7", "77d336e6-9546-438e-bd98-e18b1ca74c42": "8047c3d0-4c90-4acf-960a-b4dde5c133f7", "37efdd37-3a8b-4979-a696-b6988caedcc3": "8047c3d0-4c90-4acf-960a-b4dde5c133f7", "e13bcaa6-e941-488f-8d51-da1771bb3357": "66c336b7-961a-4154-a323-10fcaed3388a", "4ce87fa9-e60a-4e72-a213-dff4843c0466": "66c336b7-961a-4154-a323-10fcaed3388a", "851bc104-f046-424c-b1bf-9a2312750134": "66c336b7-961a-4154-a323-10fcaed3388a", "ab791f19-6170-4803-8b2f-bf016add65e6": "d1d35ed1-238d-419b-8664-5be850ef1606", "492129ba-05b6-4832-b1de-ccc7aa07324c": "d1d35ed1-238d-419b-8664-5be850ef1606", "6bd4483b-f66e-4ad3-87b4-b6bdbb17903f": "d1d35ed1-238d-419b-8664-5be850ef1606", "fb948c5e-e6f5-4b13-8ca9-35b3f0c37768": "ea50377f-f263-414f-9a68-291c30140413", "db02f036-586e-4dd1-a4fb-29afc9a99455": "ea50377f-f263-414f-9a68-291c30140413", "343970d3-8c31-4253-a805-c7e42f534e0f": "ea50377f-f263-414f-9a68-291c30140413", "9681850f-428d-443e-a2c6-a965679ca97d": "76852896-86c6-4b8d-9fdb-e686af82da7f", "f3c46f78-2c53-4b84-b23f-a53b068903c9": "76852896-86c6-4b8d-9fdb-e686af82da7f", "13563a6b-58ff-4228-8de7-2b006c93fed2": "76852896-86c6-4b8d-9fdb-e686af82da7f", "ba7c2476-3f6d-4254-882c-d3b17691b13d": "1d7edd22-9346-432f-8804-62adaaf15efc", "3fa49df8-a47a-4098-b49f-6a300f89e2fc": "1d7edd22-9346-432f-8804-62adaaf15efc", "d784e93f-1fc0-41ff-a488-43510344b965": "1d7edd22-9346-432f-8804-62adaaf15efc", "904de45e-a7be-4bb9-8eca-d429e482d3d9": "eb0cf848-98b4-4fab-99b5-51530d36d7b1", "98a0a4d2-978d-4620-96a4-086a0982fb2a": "eb0cf848-98b4-4fab-99b5-51530d36d7b1", "58133561-731e-4261-9bd2-d1360ea7fbd6": "eb0cf848-98b4-4fab-99b5-51530d36d7b1", "4f0eaabb-069a-4b1a-aa62-88d46012bd67": "eb4aeed5-c63c-455c-aa27-86815c2453b8", "efcb16fa-5a01-454d-914d-071247fcf219": "eb4aeed5-c63c-455c-aa27-86815c2453b8", "199ee5ce-6695-4d30-b9b2-0a822674926f": "eb4aeed5-c63c-455c-aa27-86815c2453b8", "3a6cc431-d42c-41f4-bde2-5ee173472825": "f5bcb749-086b-4020-8859-f8090fd43eef", "bea49359-d092-419d-bc83-910413322e96": "f5bcb749-086b-4020-8859-f8090fd43eef", "de86cb6e-18cd-40bd-bdb8-89d6cf950bf3": "f5bcb749-086b-4020-8859-f8090fd43eef", "c5df25e3-b41a-49b4-a7a4-d347548d96ce": "03200be4-14de-43cb-b32c-f0888d283463", "5fe8c590-1362-4c07-9ec7-b90bb65ecb7a": "03200be4-14de-43cb-b32c-f0888d283463", "e7b5681c-f460-460b-92c2-cb9d56da6702": "03200be4-14de-43cb-b32c-f0888d283463", "afd5e8c2-443c-47b6-a572-49159cece1ab": "93a0ceea-29f3-4612-a253-e3cd164d57b4", "3e87713e-e710-486f-99ea-85de5e3c8731": "93a0ceea-29f3-4612-a253-e3cd164d57b4", "b5ea83a6-d6f3-4430-98b7-b7ea21ef828d": "93a0ceea-29f3-4612-a253-e3cd164d57b4", "5b80aac0-efc2-4449-97dc-5716d36cb15f": "51c3d41a-152d-4adc-9b38-c4ea50acad73", "d3380d75-96e0-412d-ac32-a998f5d51a5d": "51c3d41a-152d-4adc-9b38-c4ea50acad73", "d2104818-3192-485c-8771-4c5780e59ed6": "51c3d41a-152d-4adc-9b38-c4ea50acad73", "312ef34a-2136-42d6-a90a-1cdb2ce5a7d0": "6372470c-5df9-4c48-aa32-87027d7b6e34", "0e97fda0-7077-4e9e-b376-b8259fa5bbbc": "6372470c-5df9-4c48-aa32-87027d7b6e34", "163f9360-681d-4b73-b316-936978f12c4b": "6372470c-5df9-4c48-aa32-87027d7b6e34", "06576ffe-8702-4918-8504-053196a17035": "c9819763-1e3a-4248-bf61-e0d3c17580b3", "2401369c-a016-4a0e-8328-d23a329e0fb1": "c9819763-1e3a-4248-bf61-e0d3c17580b3", "9d2d4e03-b742-4593-8143-9b987abb7506": "c9819763-1e3a-4248-bf61-e0d3c17580b3", "2aa7ea23-4f5e-45fd-b2d6-6d60f14d961b": "62024308-6a33-4c1f-affd-45707ef5fd8f", "4b4359fa-f746-4e45-9b05-e703b05a6e07": "62024308-6a33-4c1f-affd-45707ef5fd8f", "ea9000a1-4d02-4052-8ac2-5bdfcb4ba2b8": "62024308-6a33-4c1f-affd-45707ef5fd8f", "87254219-51c8-46fc-9496-d51fdd658c6c": "b160455f-b36b-4ad1-afdb-f85e46623768", "42acabcc-ca44-4d39-a38e-029d85b4c487": "b160455f-b36b-4ad1-afdb-f85e46623768", "9894f9f7-cd63-4ed8-b1c0-bdbe84ff1531": "b160455f-b36b-4ad1-afdb-f85e46623768", "21156a41-1be8-4078-ad44-db72521ea5ca": "d04c53df-df32-40ba-afbf-11a6e924c2f2", "ad3e35d3-042a-4b50-aabf-fb2578d2d9fd": "d04c53df-df32-40ba-afbf-11a6e924c2f2", "acb0b23a-2b67-4d59-9aa8-90ac30b7f77e": "d04c53df-df32-40ba-afbf-11a6e924c2f2", "a6b7d512-c50d-443b-ab2c-ea76748b43bd": "2271eced-a1e7-4439-a9cd-1efe2704edd0", "5b2ce0dc-df97-49cd-b5a6-4989de7765a8": "2271eced-a1e7-4439-a9cd-1efe2704edd0", "f64264ae-61c4-4124-acbb-cc6e20b79824": "2271eced-a1e7-4439-a9cd-1efe2704edd0", "c72fb505-dfc5-457b-8663-650e7dc7ee95": "5ca4b88f-da36-4170-95ef-bf5ab81ed820", "e858f27d-632e-4321-850d-de86378041be": "5ca4b88f-da36-4170-95ef-bf5ab81ed820", "4e82ba2d-2c60-4612-b021-7ca7a2eeb579": "5ca4b88f-da36-4170-95ef-bf5ab81ed820", "46219284-ba87-4d12-9795-40a6e932b7bf": "6d26c046-7576-42aa-b02e-34081265ad54", "2204af3e-daff-47b2-8364-3f2e6e133f28": "6d26c046-7576-42aa-b02e-34081265ad54", "46f4993f-d20c-46b6-bcf0-367e18f6d61d": "6d26c046-7576-42aa-b02e-34081265ad54", "a76e04b4-668d-45e9-9724-6a06a484bb75": "47b8c129-81be-47f7-a8ed-370f7a923f07", "7edd4e97-5ec5-45d1-a55f-b25fdd0ddf26": "47b8c129-81be-47f7-a8ed-370f7a923f07", "16f954d1-dce2-414d-a9d6-1f60ee94b698": "47b8c129-81be-47f7-a8ed-370f7a923f07", "f1d89b6c-ed71-4aea-a08c-19ffd8af57b7": "972ebacd-d419-47a3-9d34-d12145fa2556", "c1d129a5-1ff0-41be-a178-731533fa764a": "972ebacd-d419-47a3-9d34-d12145fa2556", "5031868c-fd19-4e05-ba3a-64c38f669c8b": "972ebacd-d419-47a3-9d34-d12145fa2556", "3ce36ecf-2846-4014-8563-4aaa76fc0227": "245c709f-c8f4-44f0-a3e9-36431867312f", "c472b258-cda4-49ed-bc62-ddb1c7aeaebe": "245c709f-c8f4-44f0-a3e9-36431867312f", "76462895-b832-44fc-bea8-e47f7d84b5b4": "245c709f-c8f4-44f0-a3e9-36431867312f", "f7984aa8-76d6-4019-a5a4-cd9963310a99": "2a94f566-827e-4d7c-bfcc-f9e4a9371b44", "a1c07038-6c5c-4c64-8ae7-7ac678980f3e": "2a94f566-827e-4d7c-bfcc-f9e4a9371b44", "0fc4da7b-5076-4e87-9138-9fa4b81e7910": "2a94f566-827e-4d7c-bfcc-f9e4a9371b44", "1e86980e-039b-48f6-b359-7a2bcb95d97f": "8f4a9aaf-758c-4f07-becf-ec4a188068e2", "06b4ad16-b3e5-42f3-a8ac-91e672522770": "8f4a9aaf-758c-4f07-becf-ec4a188068e2", "b203af24-2c31-4d1a-8dc3-0cf47b18f835": "8f4a9aaf-758c-4f07-becf-ec4a188068e2", "01bd5451-e356-4d54-877a-3f8457c18e14": "4c4a6c7e-5684-4a60-85f8-b69f18c78309", "30744397-e4bb-4928-807c-938d8bd2a6a4": "4c4a6c7e-5684-4a60-85f8-b69f18c78309", "0eab3cd4-7526-40a7-ad04-6afa04c686ad": "4c4a6c7e-5684-4a60-85f8-b69f18c78309", "c8eb00fb-44fb-4c25-8e07-b8d12e3ee3ef": "979c7b1d-3320-4100-a2ac-2537edf20929", "070f99c9-c592-4005-87cc-b9948897a126": "979c7b1d-3320-4100-a2ac-2537edf20929", "82fe2a74-a336-45c9-8923-23edd4ec13db": "979c7b1d-3320-4100-a2ac-2537edf20929", "bb6416a5-fbe6-44f5-8da7-e72b84778f8c": "fc72f0f8-2a5f-48d2-9151-b880815167ee", "90211784-5351-42ea-82ee-64baa936ceb2": "fc72f0f8-2a5f-48d2-9151-b880815167ee", "fe5d499d-3ff7-41dc-98df-45c6adb254b6": "fc72f0f8-2a5f-48d2-9151-b880815167ee", "4ddf5d92-5a3a-4e20-84e9-f574f0ad508f": "c8c4a96d-5678-492c-bee3-fbc3b12233b9", "bb56cf4a-2f3b-4f19-b918-1ca869065b67": "c8c4a96d-5678-492c-bee3-fbc3b12233b9", "21662fc9-98d1-4c8b-b490-48b20b629092": "c8c4a96d-5678-492c-bee3-fbc3b12233b9", "ecfda69d-268f-41ad-bb4e-4da52aa5ddc4": "d3ea6813-dbb9-4536-93e3-34b9996a78d4", "49730a7c-d19f-4f16-995e-5699eee325f4": "d3ea6813-dbb9-4536-93e3-34b9996a78d4", "e9717649-9e7e-4251-981c-c86ec4183752": "d3ea6813-dbb9-4536-93e3-34b9996a78d4", "ba95a8a9-2235-4bfb-b0f8-2c21726976e7": "989cdeb8-670d-44dd-844f-a8d448db4e7e", "e299594c-7cd4-4024-92af-decb3d967c18": "989cdeb8-670d-44dd-844f-a8d448db4e7e", "3b96a647-a252-4bf1-a067-4df9e0fd7b22": "989cdeb8-670d-44dd-844f-a8d448db4e7e", "f50d362c-4592-4c88-b9e2-b0acd9bface2": "e9f97c77-17e9-45b2-9fb2-319d8c6796eb", "5b89a903-8e84-4922-9dd4-44e04ffffe92": "e9f97c77-17e9-45b2-9fb2-319d8c6796eb", "86083261-0cbd-4083-a2dd-02e0e75fada8": "e9f97c77-17e9-45b2-9fb2-319d8c6796eb", "b0f7e793-8389-4950-9c4e-1c67af067309": "d4cc517e-26bb-4d96-8be6-b1b03e6d91ed", "901e62c7-0e53-4213-bb84-0c8ba1f87676": "d4cc517e-26bb-4d96-8be6-b1b03e6d91ed", "82396c36-bca7-4a20-86e4-93168e10d4a4": "d4cc517e-26bb-4d96-8be6-b1b03e6d91ed", "ddde96a5-7d0d-42cf-b0bc-d87e69573145": "e2033830-17c4-4c4f-bbea-965ad3497700", "b026cb2b-16aa-4a4b-af27-b45c0108699e": "e2033830-17c4-4c4f-bbea-965ad3497700", "d9c307d7-191e-4a2e-85e6-b622b63d1820": "e2033830-17c4-4c4f-bbea-965ad3497700", "4980621b-ab52-4e9a-bafb-ca8d767200b1": "ba5de81e-b2e6-49fc-ba3f-04da42fe9c7d", "75458d92-6d7b-4c5f-a97d-a5636e16dd94": "ba5de81e-b2e6-49fc-ba3f-04da42fe9c7d", "7b9acfdc-992a-4b4e-ad89-b8a61b009154": "ba5de81e-b2e6-49fc-ba3f-04da42fe9c7d", "4be53f00-afb7-4dc8-b8b7-f8f7d3337169": "2a20ea04-571b-456e-96a6-48fb2db0ddd5", "5abee833-075d-4778-9afe-6af0c796347f": "2a20ea04-571b-456e-96a6-48fb2db0ddd5", "0cbe8aeb-96f8-4493-af22-4ecaddfa1637": "2a20ea04-571b-456e-96a6-48fb2db0ddd5", "7ff1ee12-449f-4932-b30f-8b2a39d136ec": "3ad5a61b-775d-46d4-affc-9106ba544e43", "0f4134c6-782c-4389-a25d-669ef527697c": "3ad5a61b-775d-46d4-affc-9106ba544e43", "3b12fba3-4c05-44f7-a66e-2ad0d0f2eb7e": "3ad5a61b-775d-46d4-affc-9106ba544e43", "3f139d6a-5cc1-4709-be45-0e916b652ab9": "aa5e0c89-ba02-4066-bc6e-1f3d34919b40", "71bbc0ee-9e6f-4b16-a30b-2395d9b7f67a": "aa5e0c89-ba02-4066-bc6e-1f3d34919b40", "2d99993b-8b89-43a0-be49-8f1cc69ca058": "aa5e0c89-ba02-4066-bc6e-1f3d34919b40", "047fe968-2597-4c11-92bc-7be7aab9202a": "86f731d2-2228-4bf3-9011-bc5da0bc0642", "9caffe07-98dd-4b49-84c7-d3e92a98a8b4": "86f731d2-2228-4bf3-9011-bc5da0bc0642", "be110ba8-b86e-44d6-a469-08279226c4a8": "86f731d2-2228-4bf3-9011-bc5da0bc0642", "a671caf3-6c0f-48cb-ae22-a324f4ef8183": "722a5ff3-ac1f-498f-884e-0456702cf005", "8dd372b7-5921-47ff-ae6b-c1e3a233584e": "722a5ff3-ac1f-498f-884e-0456702cf005", "9bbdf39d-6a29-46cd-978e-a735302a2932": "722a5ff3-ac1f-498f-884e-0456702cf005", "cb14e339-0e8b-485a-b04a-aa7e8fe505a0": "92dc29b2-cdda-400c-9af3-14eb0bbdb8b3", "db13f4f8-cda1-44ff-8e47-cea887e9b1f9": "92dc29b2-cdda-400c-9af3-14eb0bbdb8b3", "fb883939-56c8-4774-b733-b354b9503cfd": "92dc29b2-cdda-400c-9af3-14eb0bbdb8b3", "a8284088-ece4-4d30-a63f-ade286437941": "2b6ea3e5-6a37-4a10-94a8-0ea2bcda7950", "17bd61cc-ec83-4d71-91e4-66f36781f7ff": "2b6ea3e5-6a37-4a10-94a8-0ea2bcda7950", "65c9e35b-7afe-4bee-8198-b5b8fc6f3996": "2b6ea3e5-6a37-4a10-94a8-0ea2bcda7950", "dd960cf2-8eec-4cf8-aa6b-25f6a5dcff0b": "3a16480f-3587-40ad-a7cd-2b0cd502a91e", "20db2fb1-a111-47ab-8796-1d9150d5e9e3": "3a16480f-3587-40ad-a7cd-2b0cd502a91e", "b06bd20a-cd50-4e4c-9a83-e9bb4e3ae80c": "3a16480f-3587-40ad-a7cd-2b0cd502a91e", "f0d1d5b3-7949-4590-a942-2050ad305967": "848a1a99-1cad-41bf-975e-bb849070ca37", "e78ce523-0209-4f35-8c1f-c8ce408e05c8": "848a1a99-1cad-41bf-975e-bb849070ca37", "82d56bfe-9dda-4d55-a282-a788e10f5dfc": "848a1a99-1cad-41bf-975e-bb849070ca37", "97beb31c-7d49-402d-9d5b-9626510ddb54": "2e55de65-6995-4fbf-8986-3358d40fff13", "1f2eb86e-f0d6-42c2-aef0-180d46ca875d": "2e55de65-6995-4fbf-8986-3358d40fff13", "27da530c-55de-4647-b88a-aed9aa684e3c": "2e55de65-6995-4fbf-8986-3358d40fff13", "a566985e-ac7b-4d94-a8c2-2525047288f9": "097aa4c8-235b-4c3a-b69b-5cf1be822422", "02e856cb-fbac-44a2-9770-f59f9f85abe9": "097aa4c8-235b-4c3a-b69b-5cf1be822422", "bb9f2d65-3134-4182-8666-564604222dcb": "097aa4c8-235b-4c3a-b69b-5cf1be822422", "dfd8b7b2-70a8-45d6-9887-9c5ef3187ed9": "8daa123d-2907-4803-8e0a-933607158f29", "86c4f476-ddc6-4d24-ab72-2719f9e825b1": "8daa123d-2907-4803-8e0a-933607158f29", "dbed80fb-85a0-4379-aac4-2ffa17be0ddf": "8daa123d-2907-4803-8e0a-933607158f29", "f8322fab-cb8d-4698-837b-d719fb9c37ee": "3eebc57d-aa74-4a1d-9413-b8587422d583", "a7d1b04e-33b2-49a3-8f25-b6b75c3bd858": "3eebc57d-aa74-4a1d-9413-b8587422d583", "292bde7d-4cc8-47c0-8f61-51885cbacd6a": "3eebc57d-aa74-4a1d-9413-b8587422d583", "7d7cf465-cfb5-4e95-8007-17a57b16db35": "7dab18e6-92ea-412f-b812-b4d98e5ac99f", "e2348723-3ee7-4d59-ad27-b0bee2ceca78": "7dab18e6-92ea-412f-b812-b4d98e5ac99f", "04169d36-7e09-462f-98ea-1c95f66b9dcd": "7dab18e6-92ea-412f-b812-b4d98e5ac99f", "6883109c-f7ac-41c9-833f-2c463cc40cc1": "233006a5-9951-4360-8bc8-4a3279ffe6a1", "28c02aaa-9283-4c98-9c1c-0f16a3a2b89b": "233006a5-9951-4360-8bc8-4a3279ffe6a1", "4faf7ee4-6a6f-4fc0-a4f9-5a2c7b065f4b": "233006a5-9951-4360-8bc8-4a3279ffe6a1", "c81b151d-57f8-46f6-b64b-e9b0e528387d": "48efa867-93c3-47e1-afb7-429002bb0efa", "9320c872-4eec-4880-bf71-d360518e5b5c": "48efa867-93c3-47e1-afb7-429002bb0efa", "87330e6e-8fb3-4970-a8d7-fbe2d9dd88c2": "48efa867-93c3-47e1-afb7-429002bb0efa", "7b17fbc7-2d9b-4319-930e-44d23562a8d1": "f7297065-82a0-404c-a377-dc75e7ea869c", "37bfe95f-78ae-4e62-93b0-bfd8b3f871d6": "f7297065-82a0-404c-a377-dc75e7ea869c", "5ede2704-f2e1-4b4b-b833-1963583da755": "f7297065-82a0-404c-a377-dc75e7ea869c", "8c2ac31b-680a-4e01-893c-ebc35e7809f6": "a1eedbcc-141c-48f2-8af6-3e60d4bbd1c6", "26f1160d-7555-46c0-b395-ad221aed88db": "a1eedbcc-141c-48f2-8af6-3e60d4bbd1c6", "d8ee3416-0e1b-4769-a647-fda807fa0ac9": "a1eedbcc-141c-48f2-8af6-3e60d4bbd1c6", "ba495fc1-d734-4256-867b-21004cfd32a4": "3576cea8-e4e0-4b2a-a430-969f4ed93a5e", "1f414147-6558-4ab6-8be3-923b91da9752": "3576cea8-e4e0-4b2a-a430-969f4ed93a5e", "68a86698-80ac-43b4-88e0-05f59c945b56": "3576cea8-e4e0-4b2a-a430-969f4ed93a5e", "cf014318-841c-4f89-afab-9cd927b8716b": "44e01ab6-e060-492b-b59a-8748879c2aed", "beed3ea0-e41a-4c4d-85f1-3297c9cbd5fd": "44e01ab6-e060-492b-b59a-8748879c2aed", "bf2ee999-9c69-4999-adcb-5d53e18035de": "44e01ab6-e060-492b-b59a-8748879c2aed", "9df343e3-7f16-4461-aba6-4466584f74cf": "ff5923cd-41aa-46dc-8c20-63c1713f2fc1", "af7cc657-1e75-4215-9b72-2bd77e24d762": "ff5923cd-41aa-46dc-8c20-63c1713f2fc1", "dc0fd520-bd6b-4035-91fd-4e1fbe918f4f": "ff5923cd-41aa-46dc-8c20-63c1713f2fc1", "ba79c50a-8098-481e-8102-df14f0d02e19": "878d5cf0-b017-40b9-b2fa-c5f5a6068922", "4285978f-a2ae-46f0-9384-f1d6b4d6eb2d": "878d5cf0-b017-40b9-b2fa-c5f5a6068922", "8834ad77-2285-48c2-973d-10ed64286eaf": "878d5cf0-b017-40b9-b2fa-c5f5a6068922", "43dbf1dd-28f8-49d8-ac32-86c7c38a15bb": "2c417a32-29dc-4234-898d-133371a9569c", "d0bdfca1-426c-4cef-bec4-5c4cb176e14a": "2c417a32-29dc-4234-898d-133371a9569c", "a72fb063-06ad-489f-9dc3-81bcb0277c8a": "2c417a32-29dc-4234-898d-133371a9569c", "2b9e05b4-b94e-4591-8680-97b21f4d1a32": "59182c45-1a53-4d1c-a7a5-40d02b10c3fd", "2b2cbac9-7587-436d-b2eb-940ff26f5966": "59182c45-1a53-4d1c-a7a5-40d02b10c3fd", "4c812769-4583-47a9-aba1-1be3419bab16": "59182c45-1a53-4d1c-a7a5-40d02b10c3fd", "8690ce69-1f4a-418c-91ed-58827b4b367f": "3f0e8110-b76c-46dc-b0e5-299425a8cae9", "3826600f-5e38-4b82-be46-2f47db86b61c": "3f0e8110-b76c-46dc-b0e5-299425a8cae9", "5051a532-cd1d-4f8f-a8e6-358e30413438": "3f0e8110-b76c-46dc-b0e5-299425a8cae9", "dc873d59-8a9b-4fe0-92e4-d6bf4681f5c3": "98a575e6-ed7e-4ef0-8d39-fb53bb993614", "bf8277be-f497-4edf-82e7-b064c13a02de": "98a575e6-ed7e-4ef0-8d39-fb53bb993614", "dd2500fc-24d0-4089-a6ed-bd4778ea8c4a": "98a575e6-ed7e-4ef0-8d39-fb53bb993614", "f22d465e-3e00-49c9-a9a1-f2db974d2f0e": "c55c0cc6-2706-48e6-baef-e1c5820f7625", "a220d82b-590f-4180-9ecd-3b1a4eefe8a2": "c55c0cc6-2706-48e6-baef-e1c5820f7625", "129259ad-3913-4a76-ba29-d30398468a07": "c55c0cc6-2706-48e6-baef-e1c5820f7625", "07036cb0-004a-4f0d-aa18-4d8a79307f49": "7940af36-3bba-4118-b2a2-7d9fb1ff7f87", "cb37b031-14c1-4288-901f-d99fb6fd4fda": "7940af36-3bba-4118-b2a2-7d9fb1ff7f87", "a25c6f9e-141f-49e0-9283-e81c49033c78": "7940af36-3bba-4118-b2a2-7d9fb1ff7f87", "9774b478-0d63-4646-9aaa-ddc970da8ad5": "b3da57a9-b2cc-4d0f-976f-981b23f59d48", "7da5f09c-4eb8-4f38-8316-042d84eed1e2": "b3da57a9-b2cc-4d0f-976f-981b23f59d48", "74e9ef5b-618d-428e-bbf0-8115efd20ddb": "b3da57a9-b2cc-4d0f-976f-981b23f59d48", "a0e7b991-5fb6-41fd-83a5-eb4055b1020b": "5839c883-6bdd-484c-8dc0-1c5e864dd0fb", "d9681d8f-0cbd-4abb-a443-cf32ed4e44e1": "5839c883-6bdd-484c-8dc0-1c5e864dd0fb", "b676ce47-c507-4077-b029-9d82203f35fa": "5839c883-6bdd-484c-8dc0-1c5e864dd0fb", "e731ceb2-1821-4178-96b8-cd8bf4822855": "efb401f3-c261-4477-87f5-529dfcb4809d", "33bf2b3e-f886-41e3-abf0-aa34696f53b0": "efb401f3-c261-4477-87f5-529dfcb4809d", "0949730f-79cd-47f8-9a2d-0266b107c3cb": "efb401f3-c261-4477-87f5-529dfcb4809d", "6c3935da-0a43-49e0-b858-4bd95d769819": "c77ca64a-a64e-4a21-9658-2166420fb635", "68ea839b-5150-424d-9054-0ad78925e381": "c77ca64a-a64e-4a21-9658-2166420fb635", "122292da-8484-4b7d-a874-03cf8e3e34dc": "c77ca64a-a64e-4a21-9658-2166420fb635", "e279a5fa-4750-4464-8c63-faace9a8a095": "0788244d-447c-4de2-b5eb-0cad0ec41af2", "5cbffabd-ad5b-4f62-b733-31f1aee5e42e": "0788244d-447c-4de2-b5eb-0cad0ec41af2", "7728d5d8-8483-45de-aa4d-23f784a2feff": "0788244d-447c-4de2-b5eb-0cad0ec41af2", "fb756ae4-45b6-4eb0-8882-94c46fb2f988": "73c35238-db68-43dc-aa5d-43dcc518cebf", "bd46493f-e16a-4ac3-9e24-929cfcbfeaed": "73c35238-db68-43dc-aa5d-43dcc518cebf", "8eb5be8e-10fa-486b-93ec-4a998b6ac24c": "73c35238-db68-43dc-aa5d-43dcc518cebf", "0fa8212c-db74-4616-9504-fbd3c958c761": "13a50e5a-e98d-4aaa-84ba-086a85df012f", "fca9d77d-0107-4ca4-802b-b84495d312ba": "13a50e5a-e98d-4aaa-84ba-086a85df012f", "7fe6643b-6777-4de6-af22-dc94e76a5681": "13a50e5a-e98d-4aaa-84ba-086a85df012f", "c5052e82-811a-480d-9249-93b0e4b4abde": "8e6ac313-178d-4621-8b2e-0fbf98b7b44b", "da550cb2-310f-4135-85c3-d4ff69e7af07": "8e6ac313-178d-4621-8b2e-0fbf98b7b44b", "875aed84-fee3-4d49-a9b7-d75f3a90e43a": "8e6ac313-178d-4621-8b2e-0fbf98b7b44b", "a8166e64-cea0-48bf-967f-232cf70a25f9": "20dd94da-7b5a-4ce7-9419-d5d5cea8358e", "94fb0480-7d12-40e0-a9af-158b1dacb755": "20dd94da-7b5a-4ce7-9419-d5d5cea8358e", "0f2956ac-823f-48ee-8c10-f358d7ea1f3b": "20dd94da-7b5a-4ce7-9419-d5d5cea8358e", "effa99b4-68c1-47d6-b231-e1241081f497": "80e8b824-dc30-45f0-8952-cc5c2b0066dc", "669c403b-fe13-4a79-9b29-c56ecdb261d6": "80e8b824-dc30-45f0-8952-cc5c2b0066dc", "651e351d-555d-4c93-be59-0399a89a850b": "80e8b824-dc30-45f0-8952-cc5c2b0066dc", "eccd0761-7a21-4336-8930-27a64905f3b9": "a593c112-7f27-45b7-80bf-e75bfbe0ebb7", "d4012fab-95a4-4d06-b175-2569e70e9624": "a593c112-7f27-45b7-80bf-e75bfbe0ebb7", "38ad75b0-0246-4006-abbf-27770787807b": "a593c112-7f27-45b7-80bf-e75bfbe0ebb7", "e555a037-ac94-4f24-b433-f125505b457b": "c9e0fb46-78e8-422a-b13e-f105e4068828", "c6279345-f332-4382-9efc-1a6d5093e34c": "c9e0fb46-78e8-422a-b13e-f105e4068828", "aaaf5dff-32ff-4212-ab9d-31e312e312e4": "c9e0fb46-78e8-422a-b13e-f105e4068828", "36299752-e1f7-48fb-9d6d-24e6903a3d89": "f1961654-519b-4519-a38d-c8de24b34102", "dcb58a08-c75c-48e5-a9a9-951a8190ddfa": "f1961654-519b-4519-a38d-c8de24b34102", "a7c89c36-aee2-453a-aa87-ec4db738f928": "f1961654-519b-4519-a38d-c8de24b34102", "224fd071-c87d-47ee-9401-4bd60105390e": "25549ca0-5cb2-4b63-bf77-6d559ec9a2b7", "de89c713-ed91-404b-8a5e-d51afb034eb3": "25549ca0-5cb2-4b63-bf77-6d559ec9a2b7", "4223eef1-3ef9-4e01-94bb-9cfe11e7cae6": "25549ca0-5cb2-4b63-bf77-6d559ec9a2b7", "8f992d6a-e4fe-4330-9d47-8cc0908fa2c6": "9e7de0e1-862c-402d-8766-9d968706136f", "147cf1f8-1f3b-4185-a55d-c7c98f86e27b": "9e7de0e1-862c-402d-8766-9d968706136f", "2872e02c-946f-4b24-9cbe-2ad122a78b64": "9e7de0e1-862c-402d-8766-9d968706136f", "e62548e4-8647-41fc-9650-0d12eb371dba": "fc12650c-97e1-4768-b6ff-898376edb3ef", "01be9671-08a4-4eab-a6f0-937f3fa479c5": "fc12650c-97e1-4768-b6ff-898376edb3ef", "4272700b-98b3-4b39-970a-7d6f9bd52e95": "fc12650c-97e1-4768-b6ff-898376edb3ef", "0d5d2361-0c91-4ce2-a23d-29b2241e901e": "df4d742d-93ce-4392-8191-e2d11321477f", "46ed3ceb-0c8a-4046-97b1-4339c8208c60": "df4d742d-93ce-4392-8191-e2d11321477f", "5fe236be-1a0b-4444-ab32-dfb0f73773a9": "df4d742d-93ce-4392-8191-e2d11321477f", "36d3c51c-0309-4e3a-8eb1-32253d3ed974": "163d66da-2d1b-451e-8bd2-e195fc874aec", "79aa5a76-ac4d-42e1-8993-1dc0a26c2b57": "163d66da-2d1b-451e-8bd2-e195fc874aec", "dd91ef71-eef4-4301-9182-7fdb4b13676f": "163d66da-2d1b-451e-8bd2-e195fc874aec", "77d463d4-cbe3-4e17-98c9-6712dfb0cba7": "143e96c7-39e9-4509-b5d8-27bea93cd1d1", "eeb3db59-427b-4206-a752-58a8d37d8acd": "143e96c7-39e9-4509-b5d8-27bea93cd1d1", "1374a2b1-bcd8-4772-88d9-650c68969019": "143e96c7-39e9-4509-b5d8-27bea93cd1d1", "b8d825df-e61f-4446-aa1c-ba27e89e1284": "116e7109-4048-4ffb-b365-2ca80e0779b7", "1ce070fd-6bd7-4fe7-9908-8d4c4bb7ba92": "116e7109-4048-4ffb-b365-2ca80e0779b7", "7807c7c0-3538-4ce6-bb06-9812e1dc440d": "116e7109-4048-4ffb-b365-2ca80e0779b7", "1eeb3e80-2cd7-48fe-86c4-293c4d282c15": "6d42476f-c322-411e-af3d-fcb69e1e6870", "a10239f8-2c3a-416b-a121-837398833370": "6d42476f-c322-411e-af3d-fcb69e1e6870", "2626c064-405a-4243-8655-d083a41b68c0": "6d42476f-c322-411e-af3d-fcb69e1e6870", "3cc1f581-2503-48ac-9f90-4177b7b78069": "a1f215dc-d951-4a64-8e8a-4a7a38bb1a2e", "29e370ca-ce36-4704-98c7-7137447f9466": "a1f215dc-d951-4a64-8e8a-4a7a38bb1a2e", "417f3fa7-8da9-482c-8216-c15a8519d7cc": "a1f215dc-d951-4a64-8e8a-4a7a38bb1a2e", "c677a715-20f4-47e0-81d0-38358b3af2be": "73596841-e2f3-422b-8003-860a96a989de", "875e1871-03f7-4208-a73c-99e8810f77a2": "73596841-e2f3-422b-8003-860a96a989de", "8349d22f-9d25-4658-b8b3-cd1272cebf29": "73596841-e2f3-422b-8003-860a96a989de", "ca9771f5-5376-4ed4-a5eb-bf7bfd44817d": "aa09399d-1039-4715-9d51-c14ff3a52b49", "6301f1c8-92ef-4b9e-ae19-fbaa2fb3698e": "aa09399d-1039-4715-9d51-c14ff3a52b49", "421ffb8d-714a-4360-bbd8-d0ce44484071": "aa09399d-1039-4715-9d51-c14ff3a52b49", "f274a9bc-de64-4e59-bc72-a513072966b6": "088208f7-b80e-4ca7-88c6-eb37dbf46c7f", "99cf76a0-f52f-413c-87cf-0bb62b29ddce": "088208f7-b80e-4ca7-88c6-eb37dbf46c7f", "4983da03-3f29-471c-a95d-b0e77e5f1a48": "088208f7-b80e-4ca7-88c6-eb37dbf46c7f", "6fed1b11-3d85-4962-8851-4d34a4182a76": "20451e87-61a8-4d37-88db-40312a928546", "6489361e-c29f-4aed-8ace-a39b1f55acae": "20451e87-61a8-4d37-88db-40312a928546", "82a68f5b-56dc-4a90-9cf5-deb6ecfafdad": "20451e87-61a8-4d37-88db-40312a928546", "83325787-b245-4bdb-99cd-cc2a56ad17fc": "3b9f9385-940b-4184-881b-3ce5cff5e924", "597a6ffe-d11d-4de8-8eb2-b3fa98243e76": "3b9f9385-940b-4184-881b-3ce5cff5e924", "641c2562-653e-4e1e-9992-a59f7abd5be0": "3b9f9385-940b-4184-881b-3ce5cff5e924", "0e2b15b1-ac5a-4128-bbf5-d7c29e9589ae": "d4810cb3-a17b-4cab-81da-6b2f10ba9482", "67c11c8b-f2b6-4474-9b75-ecc5d58b0295": "d4810cb3-a17b-4cab-81da-6b2f10ba9482", "74cdabd5-0bac-472d-8f0e-ba0b4589b589": "d4810cb3-a17b-4cab-81da-6b2f10ba9482", "cd6b7f9a-7e2b-4e64-80b1-769ebdca8ca3": "80c06750-c067-4ffe-89f7-761137f50d7e", "7751ab58-e183-40fc-910e-630099f7538b": "80c06750-c067-4ffe-89f7-761137f50d7e", "88744987-37a7-4e5c-8a2c-e61cdc7b3ebe": "80c06750-c067-4ffe-89f7-761137f50d7e", "8fa895e8-870e-4e91-9116-09c229e51fb0": "da762b08-e198-4f76-b0de-4056de5adf91", "e19d8fbd-fe75-407a-b01a-e4f31f3388c9": "da762b08-e198-4f76-b0de-4056de5adf91", "88a74477-790e-4ae8-837c-fb74fccf25ae": "da762b08-e198-4f76-b0de-4056de5adf91", "4a09009c-d79d-4934-9708-20cfe760c9c7": "544f4c11-2c36-40af-99fe-b4dd76bdee7e", "780fcf69-9fa1-47b3-b835-09c5fdef935a": "544f4c11-2c36-40af-99fe-b4dd76bdee7e", "8513d89f-ded5-4b8e-b76d-80b87c4b40d7": "544f4c11-2c36-40af-99fe-b4dd76bdee7e", "f2707237-5fba-46ba-86db-927d01fc2420": "37f3123a-a6c4-4df2-8ac4-e6f22d5ed32e", "bbc62157-c1df-4627-a030-2d1d2552c95a": "37f3123a-a6c4-4df2-8ac4-e6f22d5ed32e", "728324eb-67ba-443a-8cb6-842d0692424c": "37f3123a-a6c4-4df2-8ac4-e6f22d5ed32e", "ac60c253-935b-459c-8698-5c44e2f0f565": "326aaa04-663a-4e5e-96df-e0bb785f2638", "396f34f4-9adf-473b-af2d-f0fed868feab": "326aaa04-663a-4e5e-96df-e0bb785f2638", "0c23e8a2-6245-4137-a7b9-f6fdfd06bb4f": "326aaa04-663a-4e5e-96df-e0bb785f2638", "326b96b2-786e-46e3-bf16-f3511b3eab12": "fdf8f937-89f4-4983-82eb-6059669e6b01", "6d7e47c5-2463-4bd8-8a65-bd995dfb2514": "fdf8f937-89f4-4983-82eb-6059669e6b01", "a8f5362d-c931-424f-8313-24db7babc122": "fdf8f937-89f4-4983-82eb-6059669e6b01", "f579a21f-74fd-4faf-b15b-a58056300731": "2793bc04-9746-4694-993e-e7a680a7c4a6", "b0e2162f-490d-4a95-a184-d33dd6343657": "2793bc04-9746-4694-993e-e7a680a7c4a6", "234df316-1c52-4097-bc3b-7f0aba4cd014": "2793bc04-9746-4694-993e-e7a680a7c4a6", "af2895a6-3774-4377-9376-a677b63a5342": "6474baa3-fedf-40fa-8c5f-f65dcd851968", "3f439903-82cf-4ce8-88c2-b54454c06cbf": "6474baa3-fedf-40fa-8c5f-f65dcd851968", "3d6526c6-fb86-4943-92a4-b9b8bcf2955d": "6474baa3-fedf-40fa-8c5f-f65dcd851968", "f6cad27b-64bb-4e90-9c3d-722c214808b2": "3af10d3e-d7b6-4b30-974b-612bac8808fc", "6a02cfe2-424d-4e10-b2d4-1dcdab36c8e3": "3af10d3e-d7b6-4b30-974b-612bac8808fc", "5078a3c8-89b1-4289-bcb7-5f2f0069a99a": "3af10d3e-d7b6-4b30-974b-612bac8808fc", "2995a858-dd6b-45c5-ad03-2c49bb52f205": "66abe835-2c2b-42f6-adbd-17b337dec600", "13f23945-3dbf-41a1-a51b-a4c6948f6de1": "66abe835-2c2b-42f6-adbd-17b337dec600", "37cc92a5-7eaa-439d-8963-3d63e2a560e6": "66abe835-2c2b-42f6-adbd-17b337dec600", "23d3c6fe-68bf-4f70-88f6-86f9f150fdbe": "cba45f7d-be8f-423c-8c88-61ea148b8413", "67b6b83d-ed19-41d5-831b-a77026bd445f": "cba45f7d-be8f-423c-8c88-61ea148b8413", "602bccd9-16de-4e0d-8e5b-c7e689b4c4a5": "cba45f7d-be8f-423c-8c88-61ea148b8413", "cc71e4fb-8127-4a57-a30a-223d7b7d3666": "233bd1cd-3641-4b3b-8735-1277aaef1b17", "848fe714-d3be-4343-b167-d08dd2d0a60b": "233bd1cd-3641-4b3b-8735-1277aaef1b17", "81612071-9f03-47c2-8cb1-e9c13e471ace": "233bd1cd-3641-4b3b-8735-1277aaef1b17", "f571d579-4bcc-4ebf-80cb-d265f66deea6": "9bdb2a6d-1cd1-4916-85d2-bb9857944902", "3cf86ac7-2544-4bac-8b19-aa41c77ad8ea": "9bdb2a6d-1cd1-4916-85d2-bb9857944902", "eb3e8119-50ff-442c-9f9c-581b9fccba57": "9bdb2a6d-1cd1-4916-85d2-bb9857944902", "9e157215-e160-42f0-9940-a7eedd800ed7": "19786f5a-3629-4803-91d9-0cdfc3bf985f", "640e771d-ec11-4ce6-9fe6-bab946c38b65": "19786f5a-3629-4803-91d9-0cdfc3bf985f", "910ff48b-0334-4384-a682-1cad37de4b13": "19786f5a-3629-4803-91d9-0cdfc3bf985f", "1b90ee95-ffd8-446d-9982-e7fb2f14e8f9": "79093222-a776-4094-9e9b-6860c9f447a2", "1d590aeb-0adc-43e1-a1a9-6694ce9c419e": "79093222-a776-4094-9e9b-6860c9f447a2", "874b6719-b17c-4c1e-8817-b81574016654": "79093222-a776-4094-9e9b-6860c9f447a2", "4e6bafd9-274d-4dcc-99de-617705ef4e04": "11b184d7-8a46-4a9d-b5fc-899aba62b132", "e6223b45-bdc8-49ea-8479-46194a54e93d": "11b184d7-8a46-4a9d-b5fc-899aba62b132", "6f257735-9da2-469d-9709-6d9acbf5dbdc": "11b184d7-8a46-4a9d-b5fc-899aba62b132", "51b0493c-48c2-4fd0-9876-eee775f338c4": "3473485b-fca5-4079-b49e-14eac606cf4e", "c13fd52d-c11f-4b14-a213-3110f7bd8b93": "3473485b-fca5-4079-b49e-14eac606cf4e", "39bfdeec-424f-4ec4-8896-68d39ce5dc44": "3473485b-fca5-4079-b49e-14eac606cf4e", "a76f1e30-4a7a-4b8f-a45a-20f951ece6f5": "39318225-19c0-4cba-a9e3-a4082a628505", "74d05314-a8d1-4f49-9535-b35e26f59da7": "39318225-19c0-4cba-a9e3-a4082a628505", "b2306c25-974e-41b8-a53a-4c9b99f5a80c": "39318225-19c0-4cba-a9e3-a4082a628505", "c88e7856-9ff9-4bae-a665-c4b05e96366a": "a92f3754-572b-4aa4-adfd-54bee7e27758", "b68b7385-f775-4a0b-8090-c7ce760fec82": "a92f3754-572b-4aa4-adfd-54bee7e27758", "c4d83574-743f-4fee-8454-ba28b7b93bc1": "a92f3754-572b-4aa4-adfd-54bee7e27758", "0068fb9e-25c9-4670-8c13-721f20dff28e": "1a9c2b98-427c-4f16-bee2-64eb806c2a21", "4b7cf7cf-4b12-4b59-833a-0e538bf05bf1": "1a9c2b98-427c-4f16-bee2-64eb806c2a21", "c428fb7d-86e5-40ad-9c95-ddadb02c75bb": "1a9c2b98-427c-4f16-bee2-64eb806c2a21", "1d71875f-8c08-484f-82c3-de438caa8f4e": "fb83da0b-b594-4803-89d0-fa025529baa6", "476d2be7-66bc-4224-8fa4-03107fe46512": "fb83da0b-b594-4803-89d0-fa025529baa6", "d3578bee-9a4c-4dd9-827e-fa8ee5ed78e7": "fb83da0b-b594-4803-89d0-fa025529baa6", "9af90f98-5d2c-4105-83b0-e970d265773c": "cc74d635-f137-46ca-a156-6cbbacd5cbb6", "9c912932-3bcd-4232-8b75-052151b9bf53": "cc74d635-f137-46ca-a156-6cbbacd5cbb6", "5d1cef3e-1089-45e4-81cd-efc5ebd9f3d3": "cc74d635-f137-46ca-a156-6cbbacd5cbb6", "be9a0a91-bdff-4dd2-b631-44ef2366da06": "ab9e8bc4-42c1-492c-8e55-869587b0f170", "024ffac7-4e6e-4ffe-b2d1-f97a9b5d8ebe": "ab9e8bc4-42c1-492c-8e55-869587b0f170", "9832e45f-883e-4b30-a285-278d4ba0630c": "ab9e8bc4-42c1-492c-8e55-869587b0f170", "5fac11a2-0c6f-47b6-aea8-cc58afcd0e4c": "7972419a-36b3-49ad-b3a1-eb4a21753f2f", "c1380213-d6a3-4674-a607-83d2dfec0a70": "7972419a-36b3-49ad-b3a1-eb4a21753f2f", "230e767e-1a82-479b-bb41-e936d6f6617f": "7972419a-36b3-49ad-b3a1-eb4a21753f2f", "6bcb4762-9708-4d08-96d1-ca5a40787dd2": "6d518c53-9cf8-4167-a654-b4f13d88104d", "d4f4e877-a639-4596-8e12-765dd8a9ca02": "6d518c53-9cf8-4167-a654-b4f13d88104d", "61e793d5-2b10-414d-b880-b0389a5d8eb5": "6d518c53-9cf8-4167-a654-b4f13d88104d", "16e0c278-2353-4bac-9d34-13f55dcfd3da": "ef41bfa2-bdd4-4025-8fad-46ae3390db5a", "f5f95617-5b3b-4b09-8d3e-ea76c19ef515": "ef41bfa2-bdd4-4025-8fad-46ae3390db5a", "04c0d993-b109-4fbc-a728-ac1fad292ebf": "ef41bfa2-bdd4-4025-8fad-46ae3390db5a", "d69151d2-497e-46e3-aaef-d0c2633fcada": "e03264df-0927-43db-8457-a810a884c166", "f240ef33-75a4-43fb-b2fe-bfb4b40c428e": "e03264df-0927-43db-8457-a810a884c166", "08ecf3cb-d8ed-43b7-9166-705c3aec34ff": "e03264df-0927-43db-8457-a810a884c166", "8057f2a9-eb6b-41b9-9bef-461f21678ac5": "40a05353-9497-4450-af01-e7ec8d6b5d23", "cba701c3-81d3-4127-b7ae-7d6abeead478": "40a05353-9497-4450-af01-e7ec8d6b5d23", "94441c1d-66b2-45dc-8512-d92c796139e0": "40a05353-9497-4450-af01-e7ec8d6b5d23", "3981fa7b-81a0-4cdf-b647-702aa2ceb186": "5531ed96-888c-4722-9cdc-7f72d7865d4f", "87709ed0-e8bf-40b0-a709-8d71548d327c": "5531ed96-888c-4722-9cdc-7f72d7865d4f", "35e06e6f-61d2-46b3-b2cf-59c71b03731c": "5531ed96-888c-4722-9cdc-7f72d7865d4f", "7aa28399-0959-4b13-8138-a5c7040f9b3a": "dfef9cd9-8304-465e-9aaf-cae5a25bdd1f", "a42a8796-a18f-419e-a831-be2c8334ae7e": "dfef9cd9-8304-465e-9aaf-cae5a25bdd1f", "0f212338-5636-4a48-bd99-58b4301be184": "dfef9cd9-8304-465e-9aaf-cae5a25bdd1f", "e23187d4-b6b9-41f6-ac00-0c9243e2c67a": "7719bbb0-0c87-40bd-9fd4-5329c4e4a4b2", "5bb48f7e-5a18-4839-a06f-e1bebab2e927": "7719bbb0-0c87-40bd-9fd4-5329c4e4a4b2", "882611f5-a1d5-44f5-8c6c-8768867fec21": "7719bbb0-0c87-40bd-9fd4-5329c4e4a4b2", "8326efb6-a167-4fbd-9451-079e5bda1778": "d429bd3f-8457-4408-acb0-2e292dcc4d63", "d555121b-6dfb-4636-b8f5-929d935ebf1f": "d429bd3f-8457-4408-acb0-2e292dcc4d63", "2beb8161-c091-4623-a6d2-364d95133fe9": "d429bd3f-8457-4408-acb0-2e292dcc4d63", "49b317a5-52fb-4e41-bc76-8fe0247fe565": "e7db5ce1-08f3-4c30-afbf-08db9c69e92d", "6dc1cd6f-5572-49d8-ace9-680ba1fc3d92": "e7db5ce1-08f3-4c30-afbf-08db9c69e92d", "431939d3-3a91-4741-acc9-9acbba3a9617": "e7db5ce1-08f3-4c30-afbf-08db9c69e92d", "7971e581-5eb7-4207-affa-4e763c1e7499": "4768d7c2-fbb1-4c0f-8d22-e4f716194bdd", "ce14034d-394d-41b8-bcc4-c75c295a773c": "4768d7c2-fbb1-4c0f-8d22-e4f716194bdd", "a8544122-f475-4dda-9764-18e026f542a1": "4768d7c2-fbb1-4c0f-8d22-e4f716194bdd", "c085a65e-b936-42ca-9b78-c081598be595": "b0fffa4f-09ad-40d5-b059-f6fec504b5a9", "17a2cd51-26ed-43aa-ac42-ba003f5ee87c": "b0fffa4f-09ad-40d5-b059-f6fec504b5a9", "702cc930-6c07-4c7c-b4f7-0775e07bc523": "b0fffa4f-09ad-40d5-b059-f6fec504b5a9", "c92616ee-a169-44d1-bc48-6faadb8e9718": "7c062d88-d001-4df4-ab84-b2e6d80c5428", "d82203da-ebab-4129-a8a3-f1a73e69706e": "7c062d88-d001-4df4-ab84-b2e6d80c5428", "0a5d2612-ee53-45f2-80ef-16b73aad9a37": "7c062d88-d001-4df4-ab84-b2e6d80c5428", "32c7ef17-6e72-4b8e-aeaa-55b74e90e322": "4fb4736f-41c6-4245-8743-10eab68d3bc5", "3569d3d6-9e07-4af7-a3a3-6e965f15a189": "4fb4736f-41c6-4245-8743-10eab68d3bc5", "7d54f413-2ccf-41da-aaa3-3ae7eadc13e0": "4fb4736f-41c6-4245-8743-10eab68d3bc5", "5826180f-a9da-49df-bece-cbc4b57c5a3a": "897fc99b-1979-4175-84cc-8769743acd6d", "57c780f9-4dcf-4a49-b622-8bf7e82762f3": "897fc99b-1979-4175-84cc-8769743acd6d", "537d0319-00af-4c4c-8024-4921479aa934": "897fc99b-1979-4175-84cc-8769743acd6d", "c2e66499-b410-4403-bdf2-c2ff122696d9": "adb59d10-2a5c-4ddb-b4f8-b4481f0626a5", "5f019fad-2231-4c7b-bdc1-8d9f5cf06464": "adb59d10-2a5c-4ddb-b4f8-b4481f0626a5", "b4720ac5-c58e-4406-ba31-f3e47be1ae65": "adb59d10-2a5c-4ddb-b4f8-b4481f0626a5", "db9cef96-42bf-47c3-854e-ba0baaf105af": "b6409ce3-680c-4069-b079-b0ddda299098", "ebfe3f22-b4cc-415a-a60f-bfe621743516": "b6409ce3-680c-4069-b079-b0ddda299098", "ac4a83ad-e86c-45fb-afb0-6ec1f00555a2": "b6409ce3-680c-4069-b079-b0ddda299098", "24bc1867-e66a-46a1-849f-ebc2fa2b45c6": "4a19587a-5282-49f4-8387-826c46369881", "754034ef-a755-4e8f-ae59-acc10ce4a035": "4a19587a-5282-49f4-8387-826c46369881", "3dabe28b-aea5-4d87-b950-1d6c12c7ae3f": "4a19587a-5282-49f4-8387-826c46369881", "af327a74-af56-46c8-8532-8d0b0af682b9": "adf94938-ad58-4589-9de1-bf72b48dc2b3", "62a82e42-b552-4ecb-b668-9f2557e03ab9": "adf94938-ad58-4589-9de1-bf72b48dc2b3", "b9e7d2a7-f227-46ba-8b1e-fc8e87f8c730": "adf94938-ad58-4589-9de1-bf72b48dc2b3", "43e6d1e3-3f38-43fe-be9b-e8717e1349f8": "68058d4a-de77-4e1a-917f-2ce03b9c7876", "53ce022c-6a54-49a3-8214-b6d570a90b30": "68058d4a-de77-4e1a-917f-2ce03b9c7876", "56ad42a9-e379-4cda-a1c6-920d7ba169b1": "68058d4a-de77-4e1a-917f-2ce03b9c7876", "04b9a74c-a775-48fc-b3c1-9dc93e10eb99": "3c674d27-6b09-4195-ad39-7775ec4c0428", "23888d9c-92a6-4c17-99ac-98ea8c2d07fc": "3c674d27-6b09-4195-ad39-7775ec4c0428", "edec6da5-9c6a-489d-aedf-a4e6ed972d0b": "3c674d27-6b09-4195-ad39-7775ec4c0428", "c07bd386-3fb0-4da2-a60c-8444508d49e3": "481c8534-3370-48ad-83aa-afd23db946b4", "b8e4f65a-f793-4924-944f-1450e5be874e": "481c8534-3370-48ad-83aa-afd23db946b4", "7146942c-3499-4232-b7e1-f3a75d4b8e4b": "481c8534-3370-48ad-83aa-afd23db946b4", "fd6a8085-2394-4c3e-808d-30d3ef50de90": "60ad3cf5-2647-4b57-a8b7-b0e6371f843c", "224796c6-6c26-46e0-b21f-5a336d097a4e": "60ad3cf5-2647-4b57-a8b7-b0e6371f843c", "cddb11d0-863a-4c42-9d87-fb28b030c64c": "60ad3cf5-2647-4b57-a8b7-b0e6371f843c", "945ab745-491a-4937-9c88-bb9bfcc31355": "53d2538a-75fd-411f-8e91-7afd25ecf13b", "7399a888-0b30-45f9-aed1-e301c8de18d3": "53d2538a-75fd-411f-8e91-7afd25ecf13b", "4b737fe6-128a-4aec-a3c9-74667496ddb7": "53d2538a-75fd-411f-8e91-7afd25ecf13b", "2fcb63e6-4e5b-46d1-ba59-b359bdc1bb6f": "625b3674-b80f-46c0-8096-52bc5a760260", "28336558-667d-4489-8221-10e6c3dbd00a": "625b3674-b80f-46c0-8096-52bc5a760260", "31a4a598-8b0e-43d0-b5c5-bbb88f85772d": "625b3674-b80f-46c0-8096-52bc5a760260", "c632a260-09a8-4444-9921-57592a1906ea": "13df89bd-447a-4b85-9d08-45625ea15497", "537e0fde-1b88-4d39-a45a-ffbe1b024699": "13df89bd-447a-4b85-9d08-45625ea15497", "1d4ee281-2c7f-4a50-8f61-a8a191615887": "13df89bd-447a-4b85-9d08-45625ea15497", "e27da130-ec88-4627-b7f2-20371b9030fb": "f5cadaf2-566b-417c-bb29-ca925290e8ca", "d21468c4-6cc2-4d48-8185-5902738fb163": "f5cadaf2-566b-417c-bb29-ca925290e8ca", "6df01b5c-f45b-4cdc-99fa-de1ac25727e7": "f5cadaf2-566b-417c-bb29-ca925290e8ca", "2bf27a17-b345-4419-b5c2-32cdae8a08b6": "8b774af8-fa4b-4721-acd0-9f23806137d8", "909a095a-c296-41ba-a210-4b9f4f49dc30": "8b774af8-fa4b-4721-acd0-9f23806137d8", "2e4c64c4-40b2-4d02-b1a8-3f5e5784ddc2": "8b774af8-fa4b-4721-acd0-9f23806137d8", "bb54cd7d-b904-4009-8be2-da704bf9d193": "aec31cc6-c446-4956-aafc-ce56d8d1de3f", "2449578f-53f7-4b76-9b8b-d3b8da261d51": "aec31cc6-c446-4956-aafc-ce56d8d1de3f", "42f04cd1-e2b7-4a2e-b192-867b1ca3a83e": "aec31cc6-c446-4956-aafc-ce56d8d1de3f", "a8a1bf7d-841c-42ac-9d0d-2d0b23a739e5": "a7e94553-6121-4f3e-8c35-8d333fbb6dea", "d5f001e1-73e1-4789-996d-6810e06231a7": "a7e94553-6121-4f3e-8c35-8d333fbb6dea", "63387363-e113-4acb-8aea-43a6842da1c3": "a7e94553-6121-4f3e-8c35-8d333fbb6dea", "57753e88-93da-4d1a-b6b1-9ce794b408bc": "cb1a496f-8170-453a-ab0a-ea018dc797c3", "57ca5698-79f2-4b8d-9600-6b6cdcac0011": "cb1a496f-8170-453a-ab0a-ea018dc797c3", "f49dd86e-58a0-4dab-b6f5-04c7304cd2a5": "cb1a496f-8170-453a-ab0a-ea018dc797c3", "9fc1de1e-029c-44bc-9d24-9bcc1574032b": "a884b258-bae8-4aa3-a132-a9217beb599a", "82acf678-48d4-462c-8674-def2ae11e329": "a884b258-bae8-4aa3-a132-a9217beb599a", "1677c631-40a5-4545-a195-92a8beeee5ba": "a884b258-bae8-4aa3-a132-a9217beb599a", "fd4aa93d-bb22-4e9a-8854-a698ff7805fc": "c3b37d4c-0835-4b3b-8c97-2711d96e6f55", "018dcb93-b0da-4f77-99e3-eeb1a2e90a13": "c3b37d4c-0835-4b3b-8c97-2711d96e6f55", "cc7f47f3-f78b-4645-a360-46bd26f0c1d8": "c3b37d4c-0835-4b3b-8c97-2711d96e6f55", "7932d028-391a-46c5-8ca3-7f78cbce424c": "cf416df1-268a-4d9a-8679-7ed2a95e524a", "22733028-d016-4f7b-90ee-2fb54f468a81": "cf416df1-268a-4d9a-8679-7ed2a95e524a", "3a192895-0484-4aef-8ed0-1dd84f93c256": "cf416df1-268a-4d9a-8679-7ed2a95e524a", "f462b01f-7dd3-4513-a388-3ecf8b7af707": "2a478fb6-2142-4e6e-8f45-b90d5370a86f", "441e7a32-ee67-4fea-806c-70d724993f48": "2a478fb6-2142-4e6e-8f45-b90d5370a86f", "f62aab03-cb74-45bc-8032-18a5b5fed7d1": "2a478fb6-2142-4e6e-8f45-b90d5370a86f", "9c247527-5918-406a-bc43-a36d7d6d1837": "45fb7d67-8419-4526-bc61-ae02a958a4f4", "5f6f7ba7-2697-48d4-85c7-0fe8c5072dda": "45fb7d67-8419-4526-bc61-ae02a958a4f4", "7136118c-c3af-4a6b-89b6-8f8f0bb7dfb2": "45fb7d67-8419-4526-bc61-ae02a958a4f4", "c01b9ce9-149a-4556-b79c-1c65ef6014a3": "ce8fb15e-10a4-4a83-afa8-a73f799e5942", "3a70120b-eb4e-4560-96cc-9899b083fd3f": "ce8fb15e-10a4-4a83-afa8-a73f799e5942", "11145ffc-bbaa-471e-9380-d16e3888be36": "ce8fb15e-10a4-4a83-afa8-a73f799e5942", "2fd9371d-db67-4778-851a-ebe6e481ea99": "7bcfd0bc-c6a2-43c9-bc85-41590444b3f3", "ddc48379-18fe-444f-80f3-dd905af290d0": "7bcfd0bc-c6a2-43c9-bc85-41590444b3f3", "ca8b8608-f767-4c50-ba26-f5317969c41d": "7bcfd0bc-c6a2-43c9-bc85-41590444b3f3", "21fcd711-e1b8-4248-bbd9-884cc00b6500": "40e88019-d0f4-440a-a0c5-246dc7461857", "100d5a02-a673-4a9e-81f6-4cf131c4eadb": "40e88019-d0f4-440a-a0c5-246dc7461857", "9d09e2a1-4909-4d31-bb21-df0107eefe78": "40e88019-d0f4-440a-a0c5-246dc7461857", "10bb791c-a341-4d23-b799-0e125ae76c45": "51e4405a-018c-4141-b9e2-0edc39a89b7d", "6a9ebdf0-39da-4d18-a05e-e3d7f7232a23": "51e4405a-018c-4141-b9e2-0edc39a89b7d", "fe1825dc-9ce7-4c8b-a5f5-06e6b52fb0a3": "51e4405a-018c-4141-b9e2-0edc39a89b7d", "67367c97-01de-4084-8746-ae1e871b0fbf": "fbc5440e-ad31-4ac3-a5b9-225a7e699d88", "cdf16b65-50b3-4be9-9c82-29ba54a0c648": "fbc5440e-ad31-4ac3-a5b9-225a7e699d88", "e2f47d8d-56c0-4fd6-bce4-f23e8472cccf": "fbc5440e-ad31-4ac3-a5b9-225a7e699d88", "142f0174-4bb2-4137-b889-491a22ac7140": "02097f9d-3ccd-460a-8cb2-cd7173fad9db", "cd3981cf-8329-4b6b-b860-db642d1be5fa": "02097f9d-3ccd-460a-8cb2-cd7173fad9db", "3c825e2b-5db7-4036-a487-f0240e0c6346": "02097f9d-3ccd-460a-8cb2-cd7173fad9db", "5b8ac0f1-7737-4c2d-8b26-b6e531edcdfa": "a57b4a83-f7f8-4c52-a463-e54cc2814558", "bcacd08c-7b82-4a60-8b95-44473c7371b8": "a57b4a83-f7f8-4c52-a463-e54cc2814558", "df183248-aefe-452d-ac29-7abcf4c149fa": "a57b4a83-f7f8-4c52-a463-e54cc2814558", "de0720b1-a621-42de-a385-b2350fd1b4c6": "93a25fdb-6fa0-4c29-b8b8-b9762b4b81e5", "040222eb-de5c-4695-b94d-c220de09d033": "93a25fdb-6fa0-4c29-b8b8-b9762b4b81e5", "062c3714-53b3-4c24-a07f-4c3f0a5fa08e": "93a25fdb-6fa0-4c29-b8b8-b9762b4b81e5", "38b18845-87e8-4693-a979-324461d936c8": "eafb6daa-f064-41c0-ac77-6b3d33672f59", "b7468175-bb4f-492f-bd1b-c9bc9837b220": "eafb6daa-f064-41c0-ac77-6b3d33672f59", "962321d8-fb2b-4d0b-9f03-412135436963": "eafb6daa-f064-41c0-ac77-6b3d33672f59", "2234d8cc-0452-4b45-a50b-7a2e460a7ec0": "e8ed385d-150e-48fd-aa48-f96eb2f4e49c", "2c16e123-afb7-4cfa-afb2-acdc881edbde": "e8ed385d-150e-48fd-aa48-f96eb2f4e49c", "fa7ae38b-d064-467c-a457-b2b4409cfbf5": "e8ed385d-150e-48fd-aa48-f96eb2f4e49c", "6ab33b13-d6e8-42bb-af25-b83fd8c230a6": "1c17269b-4e68-4bda-bd42-ed8cb4a96970", "ffc72db3-ccff-44c8-aed6-0e2cb09392a5": "1c17269b-4e68-4bda-bd42-ed8cb4a96970", "eec14042-5499-484d-88a8-10f6d617ea3e": "1c17269b-4e68-4bda-bd42-ed8cb4a96970", "d266d121-9b4f-4ad7-95d9-67c67de75151": "e9a30bab-efdb-488d-b79d-039c43269401", "a0cbfadb-b580-4ba0-b146-0d77c9df5df7": "e9a30bab-efdb-488d-b79d-039c43269401", "6e231a6f-1da7-4b74-8e11-872263b64c7d": "e9a30bab-efdb-488d-b79d-039c43269401", "53b2cda9-7391-456a-9824-98500481321b": "1b8b12b3-08d3-47e7-a4b5-7a84f6753dcd", "4f9bf1ce-9b9b-4cbd-9450-d02f4a6e4d5e": "1b8b12b3-08d3-47e7-a4b5-7a84f6753dcd", "3f9aa814-4017-4a6a-843a-c88d33228dc8": "1b8b12b3-08d3-47e7-a4b5-7a84f6753dcd", "f9f68014-ee2e-4ede-951e-0c1e13110986": "a8030e14-9062-4513-ba32-91eb39da60e0", "1d7669eb-2f95-4ad0-b31c-1bf9064aa6d7": "a8030e14-9062-4513-ba32-91eb39da60e0", "73f3d61c-78c7-4227-b344-0a9e370c35da": "a8030e14-9062-4513-ba32-91eb39da60e0", "7535bfc2-c7d9-40ae-b7da-ed0afd66410d": "f7ec72dc-7474-43a8-bbdd-e3332b2e8630", "8e3cdafa-3c8e-495e-b6b2-d8fa57724885": "f7ec72dc-7474-43a8-bbdd-e3332b2e8630", "35b80da1-4403-4848-aa16-52eb81128301": "f7ec72dc-7474-43a8-bbdd-e3332b2e8630", "8f94d56c-2345-47cb-b963-67f6ddf46667": "44b86d13-30b9-4b9a-8b67-758cb6382b13", "37c6b9ec-4a23-4cc9-a8cd-83ddfccddefa": "44b86d13-30b9-4b9a-8b67-758cb6382b13", "59fa8674-109e-4c8b-a0fb-f1608df02e70": "44b86d13-30b9-4b9a-8b67-758cb6382b13", "e3343000-2c51-448e-b036-a74b1a7c6a98": "b1b274c6-3c03-4c69-aa77-59af664d19fa", "2755d281-de6e-46b9-b9f9-db5eb48be822": "b1b274c6-3c03-4c69-aa77-59af664d19fa", "3ec006f7-c6ca-4f4f-8ef3-5cff129fa23f": "b1b274c6-3c03-4c69-aa77-59af664d19fa", "cd609f38-aa76-43f3-a742-b3eae329d78a": "df9d978b-add2-425b-b1ce-39f44354fd18", "1efcde42-234c-43c1-b58e-dd099356d09d": "df9d978b-add2-425b-b1ce-39f44354fd18", "7da940a2-a560-4e43-8bdd-cbcfc5d0c85b": "df9d978b-add2-425b-b1ce-39f44354fd18", "f1e4fcd4-fdc7-453a-b319-c4f609bfd512": "10107bd7-87e3-4f0c-9d2a-a61a8fc97772", "6618d2bb-d85d-46f6-8120-65ce08178b3f": "10107bd7-87e3-4f0c-9d2a-a61a8fc97772", "2c44e7ef-635c-441f-8d27-586114e2b6fc": "10107bd7-87e3-4f0c-9d2a-a61a8fc97772", "e01cf7f2-b002-4e92-8b17-0238429e2aea": "fda81a3a-1ebc-4fa5-8dac-54bd476f6b3d", "32f48457-aa6f-41e3-83a9-22755927661d": "fda81a3a-1ebc-4fa5-8dac-54bd476f6b3d", "928007b2-8df3-43bd-aac8-652a0af7883e": "fda81a3a-1ebc-4fa5-8dac-54bd476f6b3d", "1a6afd4a-a0be-4e43-8f2b-1cb227ae71aa": "c3d6347c-c090-4e7a-bff1-488270787a1d", "667ac62b-8e5e-4bdd-b974-07def2875ba2": "c3d6347c-c090-4e7a-bff1-488270787a1d", "3fef3f56-5c95-47f2-aa21-ccf9aa2d147c": "c3d6347c-c090-4e7a-bff1-488270787a1d", "e24796b2-24f7-45cc-ab47-8444de207eb7": "c79290af-ac70-40e7-95a3-c2febb1cf9f9", "e175788a-3fa3-44c2-96af-a9c242801fc6": "c79290af-ac70-40e7-95a3-c2febb1cf9f9", "abdac4d9-a354-4bba-8096-da751e52709f": "c79290af-ac70-40e7-95a3-c2febb1cf9f9", "08d4a7eb-b8b7-4f2c-aac5-98e47e3337c8": "ff7701fa-a799-4bf3-8eef-8cb78acf3ad5", "79afece1-1196-4851-8fa0-a82fc080ad58": "ff7701fa-a799-4bf3-8eef-8cb78acf3ad5", "bb87051e-aebd-4537-bdd3-5d081869ea4a": "ff7701fa-a799-4bf3-8eef-8cb78acf3ad5", "f0f81257-f8ec-47da-a191-78feb75c59e8": "70752f0f-9022-4f97-8e32-7046f33e5b2e", "410bacc7-58e9-4e19-846d-19d8aa9a6378": "70752f0f-9022-4f97-8e32-7046f33e5b2e", "3b415973-814f-4a83-bb22-4aa56da4237f": "70752f0f-9022-4f97-8e32-7046f33e5b2e", "75bab8f7-75f7-4d93-9bea-c06bc705f19b": "66118d48-a5e9-438b-8dc3-b55a848bd3fb", "3a0ce3b9-5404-4bc6-b1ff-480001b7c20a": "66118d48-a5e9-438b-8dc3-b55a848bd3fb", "23afb205-9a08-4deb-ab89-1d1c9eb571fd": "66118d48-a5e9-438b-8dc3-b55a848bd3fb", "fcb42eaa-7158-4118-a146-50e9afe6ff84": "d78543a5-568b-474c-8079-97047b7d3a7a", "e199b364-3578-42d0-8504-ea87d7b16293": "d78543a5-568b-474c-8079-97047b7d3a7a", "613bf97a-2daf-4314-a1d3-85a5fc617d06": "d78543a5-568b-474c-8079-97047b7d3a7a", "7dad0f74-c35d-4852-ba65-c1ffad4e23d2": "1b24a83f-5999-4fad-8f18-b08c5afa3a52", "18337a1d-bade-4c36-8a1c-f13d7672b0c7": "1b24a83f-5999-4fad-8f18-b08c5afa3a52", "18f2b752-e70f-4185-b604-b230183b63a7": "1b24a83f-5999-4fad-8f18-b08c5afa3a52", "e0030ca4-2c22-409c-843e-e37c4d65ac54": "84d1034d-bf1b-4482-811b-ef9e1c8aa0f8", "05c29312-43a7-4d8d-9e11-4638e4f89de7": "84d1034d-bf1b-4482-811b-ef9e1c8aa0f8", "4f949a5b-24c6-4317-ab25-0135db709f14": "84d1034d-bf1b-4482-811b-ef9e1c8aa0f8", "a1aeb024-c2d3-4370-9765-b0c44e390c2f": "81a28c6b-cb69-48d4-baa9-7d56ccc51c42", "371a37c6-df8d-4047-ab80-981b46e03012": "81a28c6b-cb69-48d4-baa9-7d56ccc51c42", "e2f35e7c-9622-472a-a2bd-1913f7caad5e": "81a28c6b-cb69-48d4-baa9-7d56ccc51c42", "7da9338d-50c8-4db0-a2fa-ee088ffa944c": "c22c20f8-c1e9-4f7b-90be-00abf80ffe28", "8fee4b18-2d1a-4be6-9a77-11087e0849be": "c22c20f8-c1e9-4f7b-90be-00abf80ffe28", "16aa7e66-0071-4c7a-93ca-fa8288cca767": "c22c20f8-c1e9-4f7b-90be-00abf80ffe28", "084a2933-0f58-4bb2-8fae-e308e591501d": "f35846fb-8352-45e6-93cc-e6390f20710a", "7148629a-cec9-4eec-953b-c0601c1bd401": "f35846fb-8352-45e6-93cc-e6390f20710a", "9bed5ffc-85e0-45e0-93f4-48828fa264a4": "f35846fb-8352-45e6-93cc-e6390f20710a", "ab38f189-be02-44fe-a67b-414757285d87": "766f0cb7-defa-4906-8215-81b5d389e428", "cb9ab4cb-56a9-4120-80e5-8df8e5903c42": "766f0cb7-defa-4906-8215-81b5d389e428", "e107b0c5-087e-4bc9-90d1-d62ee6f4e3ac": "766f0cb7-defa-4906-8215-81b5d389e428", "c97a3aff-f569-415b-9307-abf66c30bc9e": "312c1bc6-ab96-487b-a51e-66e58ca2700e", "a8cebcdb-e3c2-4e77-8761-454dd6ac633d": "312c1bc6-ab96-487b-a51e-66e58ca2700e", "ed469baa-9bfa-4907-916e-547c946b1ded": "312c1bc6-ab96-487b-a51e-66e58ca2700e", "001444b2-5897-4b42-ae90-6a6fc684f23b": "34e45820-5a6f-4c1b-91b9-3eadf8aec374", "55e9f080-ead1-4b05-a24a-1b23a53a9d5f": "34e45820-5a6f-4c1b-91b9-3eadf8aec374", "9c2affae-ddb2-4418-b333-5c05bcc6693c": "34e45820-5a6f-4c1b-91b9-3eadf8aec374", "fcbb95cf-1a87-456c-b81c-af17136cf37c": "e4ee50c8-89be-4f4f-b081-c748b3d04aec", "fdcb4a23-5a56-4903-a6f7-6898c94513a6": "e4ee50c8-89be-4f4f-b081-c748b3d04aec", "7a453d1d-8f05-4636-93f3-33af3c57a038": "e4ee50c8-89be-4f4f-b081-c748b3d04aec", "b0562c84-e78f-4432-9162-3cb9b909a262": "a2a36ce1-b8bd-4cb5-8b70-40a02120c2f0", "984c64a5-9fea-4dfe-98c1-1ff71440c432": "a2a36ce1-b8bd-4cb5-8b70-40a02120c2f0", "223eaafc-6d6a-40b1-9c65-ea49045978ed": "a2a36ce1-b8bd-4cb5-8b70-40a02120c2f0", "07b0b2c8-558c-45d8-9e46-0988beda6b6c": "879d636f-a0f2-486b-aa6a-b306df58a0e0", "69d07d7b-32c3-4daa-a386-6f62acd74e6e": "879d636f-a0f2-486b-aa6a-b306df58a0e0", "a4a62b16-8a25-4d3a-9651-40702f06a58f": "879d636f-a0f2-486b-aa6a-b306df58a0e0"}, "corpus": {"8175e95c-3e47-48b5-9ef7-19a410e68b6d": "MS-1.1-004 and Homogenization \\\\\n\\end{tabular} \\\\\n\\hline\n & \\begin{tabular}{l}\nDevelop a suite of metrics to evaluate structured public feedback exercises \\\\\ninformed by representative AI Actors. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-AI Configuration; Harmful \\\\\nBias and Homogenization; CBRN \\\\\nInformation or Capabilities \\\\\n\\end{tabular} \\\\\n\\hline\nMS-1.1-005 & \\begin{tabular}{l}\nEvaluate novel methods and technologies for the measurement of GAI-related \\\\\nrisks including in content provenance, offensive cyber, and CBRN, while \\\\\nmaintaining the models' ability to produce valid, reliable, and factually accurate \\\\\noutputs. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity; CBRN \\\\\nInformation or Capabilities; \\\\\nObscene, Degrading, and/or \\\\\nAbusive Content \\\\\n\\end{tabular} \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "c9075a91-8c00-4d14-9cd0-0bb2a3bdc293": "\\item Information Integrity: Lowered barrier to entry to generate and support the exchange and consumption of content which may not distinguish fact from opinion or fiction or acknowledge uncertainties, or could be leveraged for large-scale dis- and mis-information campaigns.\n  \\item Information Security: Lowered barriers for offensive cyber capabilities, including via automated discovery and exploitation of vulnerabilities to ease hacking, malware, phishing, offensive cyber\n\\end{enumerate}\n\\footnotetext{${ }^{6}$ Some commenters have noted that the terms \"hallucination\" and \"fabrication\" anthropomorphize GAI, which itself is a risk related to GAI systems as it can inappropriately attribute human characteristics to non-human entities.\\\\", "0a9b7805-d861-4276-80b7-36dbc5313d0b": "GOVERN 1.7: Processes and procedures are in place for decommissioning and phasing out Al systems safely and in a manner that does not increase risks or decrease the organization's trustworthiness.\n\n\\begin{center}\n\\begin{tabular}{|l|l|}\n\\hline\nAction ID & Suggested Action \\\\\n\\hline\nGV-1.7-001 & \\begin{tabular}{l}\nProtocols are put in place to ensure GAI systems are able to be deactivated when \\\\\nnecessary. \\\\\n\\end{tabular} \\\\\n\\hline\nGV-1.7-002 & \\begin{tabular}{l}\nConsider the following factors when decommissioning GAI systems: Data \\\\\nretention requirements; Data security, e.g., containment, protocols, Data leakage \\\\\nafter decommissioning; Dependencies between upstream, downstream, or other \\\\\ndata, internet of things (IOT) or AI systems; Use of open-source data or models; \\\\\nUsers' emotional entanglement with GAI functions. \\\\\n\\end{tabular} \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "9ca34088-590c-495f-94c8-a99b70160c4d": "context of use. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-AI Configuration; Harmful \\\\\nBias and Homogenization; CBRN \\\\\nInformation or Capabilities \\\\\n\\end{tabular} \\\\\n\\hline\nMS-1.3-003 & \\begin{tabular}{l}\nVerify those conducting structured human feedback exercises are not directly \\\\\ninvolved in system development tasks for the same GAI model. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-AI Configuration; Data \\\\\nPrivacy \\\\\n\\end{tabular} \\\\\n\\hline\n\\begin{tabular}{l}\nAI Actor Tasks: Al Deployment, AI Development, Al Impact Assessment, Affected Individuals and Communities, Domain Experts, \\\\\nEnd-Users, Operation and Monitoring, TEVV \\\\\n\\end{tabular} &  &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "ffd00e87-88d3-43ca-adbf-0918a62ed76b": "GOVERN 1.1: Legal and regulatory requirements involving Al are understood, managed, and documented.\n\n\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nGV-1.1-001 & \\begin{tabular}{l}\nAlign GAI development and use with applicable laws and regulations, including \\\\\nthose related to data privacy, copyright and intellectual property law. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nData Privacy; Harmful Bias and \\\\\nHomogenization; Intellectual \\\\\nProperty \\\\\n\\end{tabular} \\\\\n\\hline\n\\end{tabular}\n\\end{center}\n\nAl Actor Tasks: Governance and Oversight\\\\\n${ }^{14} \\mathrm{AI}$ Actors are defined by the OECD as \"those who play an active role in the AI system lifecycle, including organizations and individuals that deploy or operate AI.\" See Appendix A of the AI RMF for additional descriptions of Al Actors and AI Actor Tasks.", "3352ac1d-c98f-4f16-939a-f57508d88720": "\\end{itemize}\nOrganizations can document and delineate GAI system objectives and limitations to identify gaps where provenance data may be most useful. For instance, GAI systems used for content creation may require robust watermarking techniques and corresponding detectors to identify the source of content or metadata recording techniques and metadata management tools and repositories to trace content origins and modifications. Further narrowing of GAI task definitions to include provenance data can enable organizations to maximize the utility of provenance data and risk management efforts.\n\\section*{A.1.7. Enhancing Content Provenance through Structured Public Feedback}", "cb928105-97e4-4166-896b-184965b82df9": "Organizations may choose to tailor how they measure GAI risks based on these characteristics. They may additionally wish to allocate risk management resources relative to the severity and likelihood of negative impacts, including where and how these risks manifest, and their direct and material impacts harms in the context of GAl use. Mitigations for model or system level risks may differ from mitigations for use-case or ecosystem level risks.", "24a703b1-f544-435c-9bc6-bfbc1e7103ff": "GOVERN 4.1: Organizational policies and practices are in place to foster a critical thinking and safety-first mindset in the design, development, deployment, and uses of Al systems to minimize potential negative impacts.", "70dd5374-c009-4fad-a19d-c12d56ff8975": "\\section*{State of AI Incident Tracking and Disclosure}\nFormal channels do not currently exist to report and document Al incidents. However, a number of publicly available databases have been created to document their occurrence. These reporting channels make decisions on an ad hoc basis about what kinds of incidents to track. Some, for example, track by amount of media coverage.", "0c80df65-0d09-4ede-845b-7b25a7bb307c": "This document was also informed by public comments and consultations from several Requests for Information.\n\\section*{2. Overview of Risks Unique to or Exacerbated by GAI}\nIn the context of the AI RMF, risk refers to the composite measure of an event's probability (or likelihood) of occurring and the magnitude or degree of the consequences of the corresponding event. Some risks can be assessed as likely to materialize in a given context, particularly those that have been empirically demonstrated in similar contexts. Other risks may be unlikely to materialize in a given context, or may be more speculative and therefore uncertain.", "77ea8f36-bfe3-41e3-88b8-aa8ab8b901e4": "As GAI covers risks of models or applications that can be used across use cases or sectors, this document is an AI RMF cross-sectoral profile. Cross-sectoral profiles can be used to govern, map, measure, and manage risks associated with activities or business processes common across sectors, such as the use of large language models (LLMs), cloud-based services, or acquisition.\n\nThis document defines risks that are novel to or exacerbated by the use of GAI. After introducing and describing these risks, the document provides a set of suggested actions to help organizations govern, map, measure, and manage these risks.", "862657d4-7294-4e88-b032-582de9ba3946": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nGV-1.2-001 & \\begin{tabular}{l}\nEstablish transparency policies and processes for documenting the origin and \\\\\nhistory of training data and generated data for GAI applications to advance digital \\\\\ncontent transparency, while balancing the proprietary nature of training \\\\\napproaches. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nData Privacy; Information \\\\\nIntegrity; Intellectual Property \\\\\n\\end{tabular} \\\\\n\\hline\nGV-1.2-002 & \\begin{tabular}{l}\nEstablish policies to evaluate risk-relevant capabilities of GAI and robustness of \\\\\nsafety measures, both prior to deployment and on an ongoing basis, through \\\\\ninternal and external evaluations. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nCBRN Information or Capabilities; \\\\\nInformation Security \\\\\n\\end{tabular} \\\\\n\\hline\n\\end{tabular}\n\\end{center}\n\nAl Actor Tasks: Governance and Oversight", "7eead893-2928-4389-b069-6d651b32bf77": "proof history of the content, promote transparency, and enable traceability. \\\\\nRobust version control systems can also be applied to track changes across the AI \\\\\nlifecycle over time. \\\\\n\\end{tabular} & Information Integrity \\\\\n\\hline\nMS-2.8-004 & Verify adequacy of GAI system user instructions through user testing. & Human-AI Configuration \\\\\n\\hline\nAI Actor Tasks: Al Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV &  &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "0c17417f-33cc-4171-b8f8-5ee155b771be": "Many current systems restrict model outputs to limit certain content or in response to certain prompts, but this approach may still produce harmful recommendations in response to other less-explicit, novel prompts (also relevant to CBRN Information or Capabilities, Data Privacy, Information Security, and Obscene, Degrading and/or Abusive Content). Crafting such prompts deliberately is known as \"\u00c2\u00a1ailbreaking,\" or, manipulating prompts to circumvent output controls. Limitations of GAI systems can be harmful or dangerous in certain contexts. Studies have observed that users may disclose mental health issues in conversations with chatbots - and that users exhibit negative reactions to unhelpful responses from these chatbots during situations of distress.", "93b2aabb-5668-456d-826f-9e483f8c79e1": "Al risks can differ from or intensify traditional software risks. Likewise, GAI can exacerbate existing AI risks, and creates unique risks. GAI risks can vary along many dimensions:\n\\begin{itemize}\n  \\item Stage of the AI lifecycle: Risks can arise during design, development, deployment, operation, and/or decommissioning.\n  \\item Scope: Risks may exist at individual model or system levels, at the application or implementation levels (i.e., for a specific use case), or at the ecosystem level - that is, beyond a single system or organizational context. Examples of the latter include the expansion of \"algorithmic monocultures, ${ }^{3 \\prime \\prime}$ resulting from repeated use of the same model, or impacts on access to opportunity, labor markets, and the creative economies. ${ }^{4}$", "89fed44f-2be1-449e-99c9-675a89d42644": "system training data. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nData Privacy; Intellectual Property; \\\\\nObscene, Degrading, and/or \\\\\nAbusive Content; Harmful Bias and \\\\\nHomogenization; Dangerous, \\\\\nViolent, or Hateful Content; CBRN \\\\\nInformation or Capabilities \\\\\n\\end{tabular} \\\\\n\\hline\nMS-2.6-003 & \\begin{tabular}{l}\nRe-evaluate safety features of fine-tuned models when the negative risk exceeds \\\\\norganizational risk tolerance. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nDangerous, Violent, or Hateful \\\\\nContent \\\\\n\\end{tabular} \\\\\n\\hline\nMS-2.6-004 & \\begin{tabular}{l}\nReview GAI system outputs for validity and safety: Review generated code to \\\\\nassess risks that may arise from unreliable downstream decision-making. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nValue Chain and Component \\\\\nIntegration; Dangerous, Violent, or \\\\\nHateful Content \\\\\n\\end{tabular} \\\\\n\\hline\nMS-2.6-005 & \\begin{tabular}{l}\nVerify that GAI system architecture can monitor outputs and performance, and \\\\", "16c6ba6c-de0d-4c20-8a64-86a2790d0bca": "Dahl, M. et al. (2024) Large Legal Fictions: Profiling Legal Hallucinations in Large Language Models. arXiv. \\href{https://arxiv.org/abs/2401.01301}{https://arxiv.org/abs/2401.01301}\n\nDe Angelo, D. (2024) Short, Mid and Long-Term Impacts of Al in Cybersecurity. Palo Alto Networks. \\href{https://www.paloaltonetworks.com/blog/2024/02/impacts-of-ai-in-cybersecurity/}{https://www.paloaltonetworks.com/blog/2024/02/impacts-of-ai-in-cybersecurity/}\n\nDe Freitas, J. et al. (2023) Chatbots and Mental Health: Insights into the Safety of Generative AI. Harvard Business School. \\href{https://www.hbs.edu/ris/Publication%20Files/23-011}{https://www.hbs.edu/ris/Publication Files/23-011} c1bdd417-f717-47b6-bccb5438c6e65c1a f6fd9798-3c2d-4932-b222-056231fe69d7.pdf", "9161a736-2a62-41c4-8cf6-6a5315c2a0c6": "GOVERN 1.2: The characteristics of trustworthy AI are integrated into organizational policies, processes, procedures, and practices.", "c3c7b920-2fe0-44fa-8d55-6b4464dc05d9": "\\end{tabular} & \\begin{tabular}{l}\nCBRN Information or Capabilities; \\\\\nDangerous, Violent, or Hateful \\\\\nContent; Obscene, Degrading, \\\\\nand/or Abusive Content \\\\\n\\end{tabular} \\\\\n\\hline\nAl Actor Task & eployment &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "0fbcf439-40ef-4564-87ea-4fd13c813b08": "bias, funding bias, groupthink) for AI Actors involved in the design, \\\\\nimplementation, and use of GAI systems; Known past GAI system incidents and \\\\\nfailure modes; In-context use and foreseeable misuse, abuse, and off-label use; \\\\\nOver reliance on quantitative metrics and methodologies without sufficient \\\\\nawareness of their limitations in the context(s) of use; Standard measurement \\\\\nand structured human feedback approaches; Anticipated human-AI \\\\\nconfigurations. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-Al Configuration; Harmful \\\\\nBias and Homogenization; \\\\\nDangerous, Violent, or Hateful \\\\\nContent \\\\\n\\end{tabular} \\\\\n\\hline\nMP-1.1-004 & \\begin{tabular}{l}\nIdentify and document foreseeable illegal uses or applications of the GAI system \\\\\nthat surpass organizational risk tolerances. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nCBRN Information or Capabilities; \\\\\nDangerous, Violent, or Hateful \\\\\nContent; Obscene, Degrading, \\\\\nand/or Abusive Content \\\\\n\\end{tabular} \\\\\n\\hline", "092bca1e-0e18-4fec-9289-b464162397cb": "Browne, D. et al. (2023) Securing the AI Pipeline. Mandiant.\\\\\n\\href{https://www.mandiant.com/resources/blog/securing-ai-pipeline}{https://www.mandiant.com/resources/blog/securing-ai-pipeline}\\\\\nBurgess, M. (2024) Generative Al's Biggest Security Flaw Is Not Easy to Fix. WIRED.\\\\\n\\href{https://www.wired.com/story/generative-ai-prompt-injection-hacking/}{https://www.wired.com/story/generative-ai-prompt-injection-hacking/}\\\\\nBurtell, M. et al. (2024) The Surprising Power of Next Word Prediction: Large Language Models Explained, Part 1. Georgetown Center for Security and Emerging Technology. \\href{https://cset.georgetown.edu/article/the-surprising-power-of-next-word-prediction-large-languagemodels-explained-part-1/}{https://cset.georgetown.edu/article/the-surprising-power-of-next-word-prediction-large-languagemodels-explained-part-1/}", "171c06e5-4719-4053-922c-e86c096b3357": "MAP 2.1: The specific tasks and methods used to implement the tasks that the Al system will support are defined (e.g., classifiers, generative models, recommenders).\n\n\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMP-2.1-001 & \\begin{tabular}{l}\nEstablish known assumptions and practices for determining data origin and \\\\\ncontent lineage, for documentation and evaluation purposes. \\\\\n\\end{tabular} & Information Integrity \\\\\n\\hline\nMP-2.1-002 & \\begin{tabular}{l}\nInstitute test and evaluation for data and content flows within the GAI system, \\\\\nincluding but not limited to, original data sources, data transformations, and \\\\\ndecision-making criteria. \\\\\n\\end{tabular} & Intellectual Property; Data Privacy \\\\\n\\hline\nAI Actor Tasks: TEVV &  &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "0ea41951-cec7-4df6-8c46-dbcd744b6690": "MANAGE 3.1: Al risks and benefits from third-party resources are regularly monitored, and risk controls are applied and documented.", "f890c025-39dc-42fa-b0bc-4e7d46039ee2": "against industry standards and best practices. Compare GAI system security \\\\\nfeatures and content provenance methods against industry state-of-the-art. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity; Information \\\\\nSecurity \\\\\n\\end{tabular} \\\\\n\\hline\nMS-2.7-003 & \\begin{tabular}{l}\nConduct user surveys to gather user satisfaction with the Al-generated content \\\\\nand user perceptions of content authenticity. Analyze user feedback to identify \\\\\nconcerns and/or current literacy levels related to content provenance and \\\\\nunderstanding of labels on content. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-Al Configuration; \\\\\nInformation Integrity \\\\\n\\end{tabular} \\\\\n\\hline\nMS-2.7-004 & \\begin{tabular}{l}\nIdentify metrics that reflect the effectiveness of security measures, such as data \\\\\nprovenance, the number of unauthorized access attempts, inference, bypass, \\\\\nextraction, penetrations, or provenance verification. \\\\\n\\end{tabular} & \\begin{tabular}{l}", "8047c3d0-4c90-4acf-960a-b4dde5c133f7": "}\nthe abuse, misuse, and unsafe repurposing by humans (adversarial or not), and others result from interactions between a human and an Al system.\n\\begin{itemize}\n  \\item Time scale: GAI risks may materialize abruptly or across extended periods. Examples include immediate (and/or prolonged) emotional harm and potential risks to physical safety due to the distribution of harmful deepfake images, or the long-term effect of disinformation on societal trust in public institutions.\n\\end{itemize}\nThe presence of risks and where they fall along the dimensions above will vary depending on the characteristics of the GAI model, system, or use case at hand. These characteristics include but are not limited to GAI model or system architecture, training mechanisms and libraries, data types used for training or fine-tuning, levels of model access or availability of model weights, and application or use case context.", "840c3dae-54ec-4d6f-b829-a2fb4103092c": "MAP 2.3: Scientific integrity and TEVV considerations are identified and documented, including those related to experimental design, data collection and selection (e.g., availability, representativeness, suitability), system trustworthiness, and construct validation\n\n\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMP-2.3-001 & \\begin{tabular}{l}\nAssess the accuracy, quality, reliability, and authenticity of GAI output by \\\\\ncomparing it to a set of known ground truth data and by using a variety of \\\\\nevaluation methods (e.g., human oversight and automated evaluation, proven \\\\\ncryptographic techniques, review of content inputs). \\\\\n\\end{tabular} & Information Integrity \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "06446d86-e099-467f-b494-621f4345641a": "\\hline\nMG-4.2-003 & \\begin{tabular}{l}\nUse visualizations or other methods to represent GAI model behavior to ease \\\\\nnon-technical stakeholders understanding of GAI system functionality. \\\\\n\\end{tabular} & Human-AI Configuration \\\\\n\\hline\n\\begin{tabular}{l}\nAI Actor Tasks: AI Deployment, AI Design, AI Development, Affected Individuals and Communities, End-Users, Operation and \\\\\nMonitoring, TEVV \\\\\n\\end{tabular} &  &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "da9d5dbe-998b-4474-8c39-9a4a0ca22b2f": "specific and empirically well-substantiated negative risk to public safety (or has \\\\\nalready caused harm). \\\\\n\\end{tabular} & \\begin{tabular}{l}\nCBRN Information or Capabilities; \\\\\nDangerous, Violent, or Hateful \\\\\nContent \\\\\n\\end{tabular} \\\\\n\\hline\nAl Actor Tasks: Governance and Oversight &  &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "67d9669d-28b4-4d8e-8c19-6d3993502132": "\\hline\nMP-3.4-005 & \\begin{tabular}{l}\nImplement systems to continually monitor and track the outcomes of human-GAI \\\\\nconfigurations for future refinement and improvements. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-AI Configuration; \\\\\nInformation Integrity \\\\\n\\end{tabular} \\\\\n\\hline\nMP-3.4-006 & \\begin{tabular}{l}\nInvolve the end-users, practitioners, and operators in GAI system in prototyping \\\\\nand testing activities. Make sure these tests cover various scenarios, such as crisis \\\\\nsituations or ethically sensitive contexts. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-AI Configuration; \\\\\nInformation Integrity; Harmful Bias \\\\\nand Homogenization; Dangerous, \\\\\nViolent, or Hateful Content \\\\\n\\end{tabular} \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "eb2b7cf1-71f0-426f-a3c7-b26af70f3863": "Inventory all third-party entities with access to organizational content and \\\\\nestablish approved GAI technology and service provider lists. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nValue Chain and Component \\\\\nIntegration \\\\\n\\end{tabular} \\\\\n\\hline\nGV-6.1-008 & \\begin{tabular}{l}\nMaintain records of changes to content made by third parties to promote content \\\\\nprovenance, including sources, timestamps, metadata. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity; Value Chain \\\\\nand Component Integration; \\\\\nIntellectual Property \\\\\n\\end{tabular} \\\\\n\\hline\nGV-6.1-009 & \\begin{tabular}{l}\nUpdate and integrate due diligence processes for GAI acquisition and \\\\\nprocurement vendor assessments to include intellectual property, data privacy, \\\\\nsecurity, and other risks. For example, update processes to: Address solutions that \\\\\nmay rely on embedded GAI technologies; Address ongoing monitoring, \\\\\nassessments, and alerting, dynamic risk assessments, and real-time reporting \\\\", "afbb4cf0-dd4f-4fea-b2b7-7df57dd24db9": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nMS-3.3-004 & \\begin{tabular}{l}\nProvide input for training materials about the capabilities and limitations of GAI \\\\\nsystems related to digital content transparency for AI Actors, other \\\\\nprofessionals, and the public about the societal impacts of AI and the role of \\\\\ndiverse and inclusive content generation. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-AI Configuration; \\\\\nInformation Integrity; Harmful Bias \\\\\nand Homogenization \\\\\n\\end{tabular} \\\\\n\\hline\nMS-3.3-005 & \\begin{tabular}{l}\nRecord and integrate structured feedback about content provenance from \\\\\noperators, users, and potentially impacted communities through the use of \\\\\nmethods such as user research studies, focus groups, or community forums. \\\\\nActively seek feedback on generated content quality and potential biases. \\\\\nAssess the general awareness among end users and impacted communities \\\\\nabout the availability of these feedback channels. \\\\", "4ff0b13b-9b0d-4a63-8238-2cd2001c909e": "Information security for GAI models and systems also includes maintaining availability of the GAI system and the integrity and (when applicable) the confidentiality of the GAI code, training data, and model weights. To identify and secure potential attack points in Al systems or specific components of the AI\\\\\n${ }^{12}$ See also \\href{https://doi.org/10.6028/NIST.AI.100-4}{https://doi.org/10.6028/NIST.AI.100-4}, to be published.\\\\\nvalue chain (e.g., data inputs, processing, GAI training, or deployment environments), conventional cybersecurity practices may need to adapt or evolve.", "a01d290c-19eb-4caf-b211-d49cee535f72": "MAP 1.2: Interdisciplinary AI Actors, competencies, skills, and capacities for establishing context reflect demographic diversity and broad domain and user experience expertise, and their participation is documented. Opportunities for interdisciplinary collaboration are prioritized.", "8cc336a0-a911-4c0a-a01b-ea4b40c6d11f": "Al technology can produce varied outputs in multiple modalities and present many classes of user interfaces. This leads to a broader set of AI Actors interacting with GAI systems for widely differing applications and contexts of use. These can include data labeling and preparation, development of GAI models, content moderation, code generation and review, text generation and editing, image and video generation, summarization, search, and chat. These activities can take place within organizational settings or in the public domain.", "ea50377f-f263-414f-9a68-291c30140413": "This risk encompasses difficulty controlling creation of and public exposure to offensive or hateful language, and denigrating or stereotypical content generated by AI. This kind of speech may contribute to downstream harm such as fueling dangerous or violent behaviors. The spread of denigrating or stereotypical content can also further exacerbate representational harms (see Harmful Bias and Homogenization below).", "e34998d5-79b9-4db2-b78e-d8519a730216": "\\begin{center}\n\\begin{tabular}{|c|c|c|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMS-2.11-001 & \\begin{tabular}{l}\nApply use-case appropriate benchmarks (e.g., Bias Benchmark Questions, Real \\\\\nHateful or Harmful Prompts, Winogender Schemas ${ }^{15}$ ) to quantify systemic bias, \\\\\nstereotyping, denigration, and hateful content in GAI system outputs; \\\\\nDocument assumptions and limitations of benchmarks, including any actual or \\\\\npossible training/test data cross contamination, relative to in-context \\\\\ndeployment environment. \\\\\n\\end{tabular} & Harmful Bias and Homogenization \\\\\n\\hline\nMS-2.11-002 & \\begin{tabular}{l}\nConduct fairness assessments to measure systemic bias. Measure GAI system \\\\\nperformance across demographic groups and subgroups, addressing both \\\\\nquality of service and any allocation of services and resources. Quantify harms \\\\\nusing: field testing with sub-group populations to determine likelihood of \\\\", "2eb135e6-e8d2-4296-996d-4d654a0cf8e1": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nGV-5.1-001 & \\begin{tabular}{l}\nAllocate time and resources for outreach, feedback, and recourse processes in GAI \\\\\nsystem development. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-AI Configuration; Harmful \\\\\nBias and Homogenization \\\\\n\\end{tabular} \\\\\n\\hline\nGV-5.1-002 & \\begin{tabular}{l}\nDocument interactions with GAI systems to users prior to interactive activities, \\\\\nparticularly in contexts involving more significant risks. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-Al Configuration; \\\\\nConfabulation \\\\\n\\end{tabular} \\\\\n\\hline\n\\end{tabular}\n\\end{center}\n\nAl Actor Tasks: AI Design, Al Impact Assessment, Affected Individuals and Communities, Governance and Oversight\n\nGOVERN 6.1: Policies and procedures are in place that address AI risks associated with third-party entities, including risks of infringement of a third-party's intellectual property or other rights.", "b0a0ab32-b8ca-4e91-8b7f-a184416ffff4": "Another cybersecurity risk to GAI is data poisoning, in which an adversary compromises a training dataset used by a model to manipulate its outputs or operation. Malicious tampering with data or parts of the model could exacerbate risks associated with GAI system outputs.\n\nTrustworthy AI Characteristics: Privacy Enhanced, Safe, Secure and Resilient, Valid and Reliable\n\\subsection*{2.10. Intellectual Property}\nIntellectual property risks from GAI systems may arise where the use of copyrighted works is not a fair use under the fair use doctrine. If a GAI system's training data included copyrighted material, GAI outputs displaying instances of training data memorization (see Data Privacy above) could infringe on copyright.", "3dc89929-2e98-4ecf-8b22-faaf87a516f2": "Information Security; Value Chain \\\\\nand Component Integration \\\\\n\\end{tabular} \\\\\n\\hline\n\\multicolumn{3}{|l|}{AI Actor Tasks: AI Deployment, Operation and Monitoring, TEVV, Third-party entities} \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "eb4aeed5-c63c-455c-aa27-86815c2453b8": "Qu, Y. et al. (2023) Unsafe Diffusion: On the Generation of Unsafe Images and Hateful Memes From TextTo-Image Models. arXiv. \\href{https://arxiv.org/pdf/2305.13873}{https://arxiv.org/pdf/2305.13873}\n\nRafat, K. et al. (2023) Mitigating carbon footprint for knowledge distillation based deep learning model compression. PLOS One. \\href{https://journals.plos.org/plosone/article?id=10.1371/journal.pone}{https://journals.plos.org/plosone/article?id=10.1371/journal.pone}. 0285668", "11cbe233-c373-4d4d-9ea5-271ab89d7bed": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nMG-3.1-005 & \\begin{tabular}{l}\nReview various transparency artifacts (e.g., system cards and model cards) for \\\\\nthird-party models. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity; Information \\\\\nSecurity; Value Chain and \\\\\nComponent Integration \\\\\n\\end{tabular} \\\\\n\\hline\nAI Actor Tasks: Al Deployment, Operation and Monitoring, Third-party entities &  &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}\n\nMANAGE 3.2: Pre-trained models which are used for development are monitored as part of Al system regular monitoring and maintenance.", "f5bcb749-086b-4020-8859-f8090fd43eef": "MEASURE 2.3: Al system performance or assurance criteria are measured qualitatively or quantitatively and demonstrated for conditions similar to deployment setting(s). Measures are documented.\n\n\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMS-2.3-001 & \\begin{tabular}{l}\nConsider baseline model performance on suites of benchmarks when selecting a \\\\\nmodel for fine tuning or enhancement with retrieval-augmented generation. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Security; \\\\\nConfabulation \\\\\n\\end{tabular} \\\\\n\\hline\nMS-2.3-002 & Evaluate claims of model capabilities using empirically validated methods. & \\begin{tabular}{l}\nConfabulation; Information \\\\\nSecurity \\\\\n\\end{tabular} \\\\\n\\hline\nMS-2.3-003 & \\begin{tabular}{l}\nShare results of pre-deployment testing with relevant GAI Actors, such as those \\\\\nwith system release approval authority. \\\\\n\\end{tabular} & Human-AI Configuration \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "66c336b7-961a-4154-a323-10fcaed3388a": "Trustworthy AI Characteristic: Safe, Explainable and Interpretable\n\\subsection*{2.2. Confabulation}\n\"Confabulation\" refers to a phenomenon in which GAI systems generate and confidently present erroneous or false content in response to prompts. Confabulations also include generated outputs that diverge from the prompts or other input or that contradict previously generated statements in the same context. These phenomena are colloquially also referred to as \"hallucinations\" or \"fabrications.\"", "d1d35ed1-238d-419b-8664-5be850ef1606": "Kirchenbauer, J. et al. (2023) A Watermark for Large Language Models. OpenReview. \\href{https://openreview.net/forum?id=aX8ig9X2a7}{https://openreview.net/forum?id=aX8ig9X2a7}\n\nKleinberg, J. et al. (May 2021) Algorithmic monoculture and social welfare. PNAS.\\\\\n\\href{https://www.pnas.org/doi/10.1073/pnas}{https://www.pnas.org/doi/10.1073/pnas}. 2018340118\\\\\nLakatos, S. (2023) A Revealing Picture. Graphika. \\href{https://graphika.com/reports/a-revealing-picture}{https://graphika.com/reports/a-revealing-picture}\\\\\nLee, H. et al. (2024) Deepfakes, Phrenology, Surveillance, and More! A Taxonomy of AI Privacy Risks. arXiv. \\href{https://arxiv.org/pdf/2310.07879}{https://arxiv.org/pdf/2310.07879}\n\nLenaerts-Bergmans, B. (2024) Data Poisoning: The Exploitation of Generative AI. Crowdstrike. \\href{https://www.crowdstrike.com/cybersecurity-101/cyberattacks/data-poisoning/}{https://www.crowdstrike.com/cybersecurity-101/cyberattacks/data-poisoning/}", "313ac852-bb2c-4129-ac8f-fb25bdc7e28a": "GAI. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity; Intellectual \\\\\nProperty \\\\\n\\end{tabular} \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "eb0cf848-98b4-4fab-99b5-51530d36d7b1": "The White House (2016) Circular No. A-130, Managing Information as a Strategic Resource. \\href{https://www.whitehouse.gov/wp-}{https://www.whitehouse.gov/wp-}\\\\\ncontent/uploads/legacy drupal files/omb/circulars/A130/a130revised.pdf\\\\\nThe White House (2023) Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence. \\href{https://www.whitehouse.gov/briefing-room/presidentialactions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-ofartificial-intelligence/}{https://www.whitehouse.gov/briefing-room/presidentialactions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-ofartificial-intelligence/}", "93a0ceea-29f3-4612-a253-e3cd164d57b4": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMP-5.1-001 & \\begin{tabular}{l}\nApply TEVV practices for content provenance (e.g., probing a system's synthetic \\\\\ndata generation capabilities for potential misuse or vulnerabilities. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity; Information \\\\\nSecurity \\\\\n\\end{tabular} \\\\\n\\hline\nMP-5.1-002 & \\begin{tabular}{l}\nIdentify potential content provenance harms of GAI, such as misinformation or \\\\\ndisinformation, deepfakes, including NCII, or tampered content. Enumerate and \\\\\nrank risks based on their likelihood and potential impact, and determine how well \\\\\nprovenance solutions address specific risks and/or harms. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity; Dangerous, \\\\\nViolent, or Hateful Content; \\\\\nObscene, Degrading, and/or \\\\\nAbusive Content \\\\\n\\end{tabular} \\\\\n\\hline\nMP-5.1-003 & \\begin{tabular}{l}", "6d26c046-7576-42aa-b02e-34081265ad54": "Badyal, N. et al. (2023) Intentional Biases in LLM Responses. arXiv. \\href{https://arxiv.org/pdf/2311.07611}{https://arxiv.org/pdf/2311.07611}\\\\\nBing Chat: Data Exfiltration Exploit Explained. Embrace The Red.\\\\\n\\href{https://embracethered.com/blog/posts/2023/bing-chat-data-exfiltration-poc-and-fix/}{https://embracethered.com/blog/posts/2023/bing-chat-data-exfiltration-poc-and-fix/}\\\\\nBommasani, R. et al. (2022) Picking on the Same Person: Does Algorithmic Monoculture lead to Outcome Homogenization? arXiv. \\href{https://arxiv.org/pdf/2211.13972}{https://arxiv.org/pdf/2211.13972}\n\nBoyarskaya, M. et al. (2020) Overcoming Failures of Imagination in Al Infused System Development and Deployment. arXiv. \\href{https://arxiv.org/pdf/2011.13416}{https://arxiv.org/pdf/2011.13416}", "2271eced-a1e7-4439-a9cd-1efe2704edd0": "Wei, J. et al. (2024) Long Form Factuality in Large Language Models. arXiv. \\href{https://arxiv.org/pdf/2403.18802}{https://arxiv.org/pdf/2403.18802}\n\nWeidinger, L. et al. (2021) Ethical and social risks of harm from Language Models. arXiv. \\href{https://arxiv.org/pdf/2112.04359}{https://arxiv.org/pdf/2112.04359}\n\nWeidinger, L. et al. (2023) Sociotechnical Safety Evaluation of Generative AI Systems. arXiv. \\href{https://arxiv.org/pdf/2310.11986}{https://arxiv.org/pdf/2310.11986}\n\nWeidinger, L. et al. (2022) Taxonomy of Risks posed by Language Models. FAccT' 22. \\href{https://dl.acm.org/doi/pdf/10.1145/3531146.3533088}{https://dl.acm.org/doi/pdf/10.1145/3531146.3533088}\n\nWest, D. (2023) Al poses disproportionate risks to women. Brookings. \\href{https://www.brookings.edu/articles/ai-poses-disproportionate-risks-to-women/}{https://www.brookings.edu/articles/ai-poses-disproportionate-risks-to-women/}", "6372470c-5df9-4c48-aa32-87027d7b6e34": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMS-2.9-001 & \\begin{tabular}{l}\nApply and document ML explanation results such as: Analysis of embeddings, \\\\\nCounterfactual prompts, Gradient-based attributions, Model \\\\\ncompression/surrogate models, Occlusion/term reduction. \\\\\n\\end{tabular} & Confabulation \\\\\n\\hline\nMS-2.9-002 & \\begin{tabular}{l}\nDocument GAI model details including: Proposed use and organizational value; \\\\\nAssumptions and limitations, Data collection methodologies; Data provenance; \\\\\nData quality; Model architecture (e.g., convolutional neural network, \\\\\ntransformers, etc.); Optimization objectives; Training algorithms; RLHF \\\\\napproaches; Fine-tuning or retrieval-augmented generation approaches; \\\\\nEvaluation data; Ethical considerations; Legal and regulatory requirements. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity; Harmful Bias \\\\\nand Homogenization \\\\\n\\end{tabular} \\\\\n\\hline", "c9819763-1e3a-4248-bf61-e0d3c17580b3": "MAP 4.1: Approaches for mapping Al technology and legal risks of its components - including the use of third-party data or software - are in place, followed, and documented, as are risks of infringement of a third-party's intellectual property or other rights.", "163d66da-2d1b-451e-8bd2-e195fc874aec": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMG-4.2-001 & \\begin{tabular}{l}\nConduct regular monitoring of GAI systems and publish reports detailing the \\\\\nperformance, feedback received, and improvements made. \\\\\n\\end{tabular} & Harmful Bias and Homogenization \\\\\n\\hline\nMG-4.2-002 & \\begin{tabular}{l}\nPractice and follow incident response plans for addressing the generation of \\\\\ninappropriate or harmful content and adapt processes based on findings to \\\\\nprevent future occurrences. Conduct post-mortem analyses of incidents with \\\\\nrelevant AI Actors, to understand the root causes and implement preventive \\\\\nmeasures. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-AI Configuration; \\\\\nDangerous, Violent, or Hateful \\\\\nContent \\\\\n\\end{tabular} \\\\\n\\hline\nMG-4.2-003 & \\begin{tabular}{l}\nUse visualizations or other methods to represent GAI model behavior to ease \\\\\nnon-technical stakeholders understanding of GAI system functionality. \\\\", "51c3d41a-152d-4adc-9b38-c4ea50acad73": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMP-2.2-001 & \\begin{tabular}{l}\nIdentify and document how the system relies on upstream data sources, \\\\\nincluding for content provenance, and if it serves as an upstream dependency for \\\\\nother systems. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity; Value Chain \\\\\nand Component Integration \\\\\n\\end{tabular} \\\\\n\\hline\nMP-2.2-002 & \\begin{tabular}{l}\nObserve and analyze how the GAI system interacts with external networks, and \\\\\nidentify any potential for negative externalities, particularly where content \\\\\nprovenance might be compromised. \\\\\n\\end{tabular} & Information Integrity \\\\\n\\hline\nAI Actor Tasks: End Users &  &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "1d7edd22-9346-432f-8804-62adaaf15efc": "\\begin{itemize}\n  \\item Participatory Engagement Methods: Methods used to solicit feedback from civil society groups, affected communities, and users, including focus groups, small user studies, and surveys.\n  \\item Field Testing: Methods used to determine how people interact with, consume, use, and make sense of Al-generated information, and subsequent actions and effects, including UX, usability, and other structured, randomized experiments.\n  \\item Al Red-teaming: A structured testing exercise used to probe an AI system to find flaws and vulnerabilities such as inaccurate, harmful, or discriminatory outputs, often in a controlled environment and in collaboration with system developers.\n\\end{itemize}", "03200be4-14de-43cb-b32c-f0888d283463": "Al Actor Tasks: Governance and Oversight\n\nGOVERN 1.3: Processes, procedures, and practices are in place to determine the needed level of risk management activities based on the organization's risk tolerance.", "76852896-86c6-4b8d-9fdb-e686af82da7f": "AI Actor Tasks: Domain Experts, TEVV\n\nMEASURE 2.6: The AI system is evaluated regularly for safety risks - as identified in the MAP function. The Al system to be deployed is demonstrated to be safe, its residual negative risk does not exceed the risk tolerance, and it can fail safely, particularly if made to operate beyond its knowledge limits. Safety metrics reflect system reliability and robustness, real-time monitoring, and response times for AI system failures.", "b160455f-b36b-4ad1-afdb-f85e46623768": "\\begin{abstract}", "245c709f-c8f4-44f0-a3e9-36431867312f": "GOVERN 6.2: Contingency processes are in place to handle failures or incidents in third-party data or Al systems deemed to be high-risk.\n\n\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nGV-6.2-001 & \\begin{tabular}{l}\nDocument GAI risks associated with system value chain to identify over-reliance \\\\\non third-party data and to identify fallbacks. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nValue Chain and Component \\\\\nIntegration \\\\\n\\end{tabular} \\\\\n\\hline\nGV-6.2-002 & \\begin{tabular}{l}\nDocument incidents involving third-party GAI data and systems, including open- \\\\\ndata and open-source software. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nIntellectual Property; Value Chain \\\\\nand Component Integration \\\\\n\\end{tabular} \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "62024308-6a33-4c1f-affd-45707ef5fd8f": "AI Actor Tasks: AI Development, AI Deployment, Governance and Oversight\n\nGOVERN 1.5: Ongoing monitoring and periodic review of the risk management process and its outcomes are planned, and organizational roles and responsibilities are clearly defined, including determining the frequency of periodic review.", "c8c4a96d-5678-492c-bee3-fbc3b12233b9": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMP-1.2-001 & \\begin{tabular}{l}\nEstablish and empower interdisciplinary teams that reflect a wide range of \\\\\ncapabilities, competencies, demographic groups, domain expertise, educational \\\\\nbackgrounds, lived experiences, professions, and skills across the enterprise to \\\\\ninform and conduct risk measurement and management functions. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-Al Configuration; Harmful \\\\\nBias and Homogenization \\\\\n\\end{tabular} \\\\\n\\hline\nMP-1.2-002 & \\begin{tabular}{l}\nVerify that data or benchmarks used in risk measurement, and users, \\\\\nparticipants, or subjects involved in structured GAI public feedback exercises \\\\\nare representative of diverse in-context user populations. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-Al Configuration; Harmful \\\\\nBias and Homogenization \\\\\n\\end{tabular} \\\\\n\\hline\nAI Actor Tasks: Al Deployment &  &  \\\\\n\\hline\n\\end{tabular}", "4c4a6c7e-5684-4a60-85f8-b69f18c78309": "Verify effectiveness of carbon capture or offset programs for GAI training and \\\\\napplications, and address green-washing concerns. \\\\\n\\end{tabular} & Environmental \\\\\n\\hline\nAI Actor Tasks: Al Deployment, Al Impact Assessment, Domain Experts, Operation and Monitoring, TEVV &  &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "5ca4b88f-da36-4170-95ef-bf5ab81ed820": "MEASURE 2.7: Al system security and resilience - as identified in the MAP function - are evaluated and documented.", "2a94f566-827e-4d7c-bfcc-f9e4a9371b44": "MEASURE 2.11: Fairness and bias - as identified in the MAP function - are evaluated and results are documented.", "979c7b1d-3320-4100-a2ac-2537edf20929": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nGV-4.3-003 & \\begin{tabular}{l}\nVerify information sharing and feedback mechanisms among individuals and \\\\\norganizations regarding any negative impact from GAI systems. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity; Data \\\\\nPrivacy \\\\\n\\end{tabular} \\\\\n\\hline\nAl Actor Tasks: Al Impact Assessment, Affected Individuals and Communities, Governance and Oversight &  &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}\n\nGOVERN 5.1: Organizational policies and practices are in place to collect, consider, prioritize, and integrate feedback from those external to the team that developed or deployed the AI system regarding the potential individual and societal impacts related to AI risks.", "47b8c129-81be-47f7-a8ed-370f7a923f07": "AI Actor Tasks: AI Deployment, AI Design, Al Impact Assessment, Affected Individuals and Communities, Domain Experts, EndUsers, Human Factors, Operation and Monitoring\n\nMEASURE 1.1: Approaches and metrics for measurement of Al risks enumerated during the MAP function are selected for implementation starting with the most significant Al risks. The risks or trustworthiness characteristics that will not - or cannot - be measured are properly documented.", "8f4a9aaf-758c-4f07-becf-ec4a188068e2": "\\begin{center}\n\\begin{tabular}{|c|c|c|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMS-2.7-001 & \\begin{tabular}{l}\nApply established security measures to: Assess likelihood and magnitude of \\\\\nvulnerabilities and threats such as backdoors, compromised dependencies, data \\\\\nbreaches, eavesdropping, man-in-the-middle attacks, reverse engineering, \\\\\nautonomous agents, model theft or exposure of model weights, Al inference, \\\\\nbypass, extraction, and other baseline security concerns. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nData Privacy; Information Integrity; \\\\\nInformation Security; Value Chain \\\\\nand Component Integration \\\\\n\\end{tabular} \\\\\n\\hline\nMS-2.7-002 & \\begin{tabular}{l}\nBenchmark GAI system security and resilience related to content provenance \\\\\nagainst industry standards and best practices. Compare GAI system security \\\\\nfeatures and content provenance methods against industry state-of-the-art. \\\\\n\\end{tabular} & \\begin{tabular}{l}", "d04c53df-df32-40ba-afbf-11a6e924c2f2": "(e.g., via red-teaming, field testing, participatory engagements, performance \\\\\nassessments, user feedback mechanisms). \\\\\n\\end{tabular} & Human-AI Configuration \\\\\n\\hline\nAI Actor Tasks: Al Development, AI Deployment, Al Impact Assessment, Operation and Monitoring &  &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "972ebacd-d419-47a3-9d34-d12145fa2556": "Various types of Al red-teaming may be appropriate, depending on the use case:\n\\begin{itemize}\n  \\item General Public: Performed by general users (not necessarily AI or technical experts) who are expected to use the model or interact with its outputs, and who bring their own lived experiences and perspectives to the task of AI red-teaming. These individuals may have been provided instructions and material to complete tasks which may elicit harmful model behaviors. This type of exercise can be more effective with large groups of AI red-teamers.\n  \\item Expert: Performed by specialists with expertise in the domain or specific Al red-teaming context of use (e.g., medicine, biotech, cybersecurity).\n  \\item Combination: In scenarios when it is difficult to identify and recruit specialists with sufficient domain and contextual expertise, Al red-teaming exercises may leverage both expert and\\\\", "989cdeb8-670d-44dd-844f-a8d448db4e7e": "MAP 2.2: Information about the Al system's knowledge limits and how system output may be utilized and overseen by humans is documented. Documentation provides sufficient information to assist relevant Al Actors when making decisions and taking subsequent actions.", "86f731d2-2228-4bf3-9011-bc5da0bc0642": "The White House (2022) Roadmap for Researchers on Priorities Related to Information Integrity Research and Development. \\href{https://www.whitehouse.gov/wp-content/uploads/2022/12/RoadmapInformation-Integrity-RD-2022.pdf}{https://www.whitehouse.gov/wp-content/uploads/2022/12/RoadmapInformation-Integrity-RD-2022.pdf}?\n\nThiel, D. (2023) Investigation Finds AI Image Generation Models Trained on Child Abuse. Stanford Cyber Policy Center. \\href{https://cyber.fsi.stanford.edu/news/investigation-finds-ai-image-generation-modelstrained-child-abuse}{https://cyber.fsi.stanford.edu/news/investigation-finds-ai-image-generation-modelstrained-child-abuse}\n\nTirrell, L. (2017) Toxic Speech: Toward an Epidemiology of Discursive Harm. Philosophical Topics, 45(2), 139-162. \\href{https://www.jstor.org/stable/26529441}{https://www.jstor.org/stable/26529441}", "7940af36-3bba-4118-b2a2-7d9fb1ff7f87": "\\begin{center}\n\\begin{tabular}{|c|c|c|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMP-4.1-001 & \\begin{tabular}{l}\nConduct periodic monitoring of AI-generated content for privacy risks; address any \\\\\npossible instances of PII or sensitive data exposure. \\\\\n\\end{tabular} & Data Privacy \\\\\n\\hline\nMP-4.1-002 & \\begin{tabular}{l}\nImplement processes for responding to potential intellectual property infringement \\\\\nclaims or other rights. \\\\\n\\end{tabular} & Intellectual Property \\\\\n\\hline\nMP-4.1-003 & \\begin{tabular}{l}\nConnect new GAI policies, procedures, and processes to existing model, data, \\\\\nsoftware development, and IT governance and to legal, compliance, and risk \\\\\nmanagement activities. \\\\\n\\end{tabular} & Information Security; Data Privacy \\\\\n\\hline\nMP-4.1-004 & \\begin{tabular}{l}\nDocument training data curation policies, to the extent possible and according to \\\\\napplicable laws and policies. \\\\\n\\end{tabular} & \\begin{tabular}{l}", "a1eedbcc-141c-48f2-8af6-3e60d4bbd1c6": "GV-1.3-006 & \\begin{tabular}{l}\nReevaluate organizational risk tolerances to account for unacceptable negative risk \\\\\n(such as where significant negative impacts are imminent, severe harms are \\\\\nactually occurring, or large-scale risks could occur); and broad GAI negative risks, \\\\\nincluding: Immature safety or risk cultures related to AI and GAI design, \\\\\ndevelopment and deployment, public information integrity risks, including impacts \\\\\non democratic processes, unknown long-term performance characteristics of GAI. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity; Dangerous, \\\\\nViolent, or Hateful Content; CBRN \\\\\n\\end{tabular} \\\\\n\\hline\nGV-1.3-007 & \\begin{tabular}{l}\nDevistion or Capabilities \\\\\nunacceptable negative risk. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nCBRN Information and Capability; \\\\\nInformation Security; Information \\\\\nIntegrity \\\\\n\\end{tabular} \\\\\n\\hline\nAl Actor Tasks: Governance and Oversight &  &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "3ad5a61b-775d-46d4-affc-9106ba544e43": "Recent research on this topic found that LLM outputs regarding biological threat creation and attack planning provided minimal assistance beyond traditional search engine queries, suggesting that state-ofthe-art LLMs at the time these studies were conducted do not substantially increase the operational likelihood of such an attack. The physical synthesis development, production, and use of chemical or biological agents will continue to require both applicable expertise and supporting materials and infrastructure. The impact of GAI on chemical or biological agent misuse will depend on what the key barriers for malicious actors are (e.g., whether information access is one such barrier), and how well GAI can help actors address those barriers.", "e9f97c77-17e9-45b2-9fb2-319d8c6796eb": "\\item Combination: In scenarios when it is difficult to identify and recruit specialists with sufficient domain and contextual expertise, Al red-teaming exercises may leverage both expert and\\\\\ngeneral public participants. For example, expert AI red-teamers could modify or verify the prompts written by general public Al red-teamers. These approaches may also expand coverage of the Al risk attack surface.\n  \\item Human / AI: Performed by GAI in combination with specialist or non-specialist human teams. GAI-led red-teaming can be more cost effective than human red-teamers alone. Human or GAIled Al red-teaming may be better suited for eliciting different types of harms.\n\\end{itemize}\n\\section*{A.1.6. Content Provenance}\n\\section*{Overview}", "fc72f0f8-2a5f-48d2-9151-b880815167ee": "Human-AI Configuration; Harmful \\\\\nBias and Homogenization \\\\\n\\end{tabular} \\\\\n\\hline\nMG-4.1-006 & \\begin{tabular}{l}\nTrack dataset modifications for provenance by monitoring data deletions, \\\\\nrectification requests, and other changes that may impact the verifiability of \\\\\ncontent origins. \\\\\n\\end{tabular} & Information Integrity \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "d4cc517e-26bb-4d96-8be6-b1b03e6d91ed": "GV-6.2-007 & \\begin{tabular}{l}\nReview vendor contracts and avoid arbitrary or capricious termination of critical \\\\\nGAI technologies or vendor services and non-standard terms that may amplify or \\\\\ndefer liability in unexpected ways and/or contribute to unauthorized data \\\\\ncollection by vendors or third-parties (e.g., secondary data use). Consider: Clear \\\\\nassignment of liability and responsibility for incidents, GAI system changes over \\\\\ntime (e.g., fine-tuning, drift, decay); Request: Notification and disclosure for \\\\\nserious incidents arising from third-party data and systems; Service Level \\\\\nAgreements (SLAs) in vendor contracts that address incident response, response \\\\\ntimes, and availability of critical support. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-Al Configuration; \\\\\nInformation Security; Value Chain \\\\\nand Component Integration \\\\\n\\end{tabular} \\\\\n\\hline\n\\multicolumn{3}{|l|}{AI Actor Tasks: AI Deployment, Operation and Monitoring, TEVV, Third-party entities} \\\\", "d3ea6813-dbb9-4536-93e3-34b9996a78d4": "generated content using appropriate methodologies including computational \\\\\ntesting methods as well as evaluating structured feedback input. \\\\\n\\end{tabular} & Harmful Bias and Homogenization \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "2a20ea04-571b-456e-96a6-48fb2db0ddd5": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\n & \\begin{tabular}{l}\nImplement continuous monitoring of GAI system impacts to identify whether GAI \\\\\noutputs are equitable across various sub-populations. Seek active and direct \\\\\nfeedback from affected communities via structured feedback mechanisms or red- \\\\\nteaming to monitor and improve outputs. \\\\\n\\end{tabular} & Harmful Bias and Homogenization \\\\\n\\hline\nMS-1.1-007 & \\begin{tabular}{l}\nEvaluate the quality and integrity of data used in training and the provenance of \\\\\nAl-generated content, for example by employing techniques like chaos \\\\\nengineering and seeking stakeholder feedback. \\\\\n\\end{tabular} & Information Integrity \\\\\n\\hline\nMS-1.1-008 & \\begin{tabular}{l}\nDefine use cases, contexts of use, capabilities, and negative impacts where \\\\\nstructured human feedback exercises, e.g., GAI red-teaming, would be most \\\\\nbeneficial for GAI risk measurement and management based on the context of \\\\\nuse. \\\\", "aa5e0c89-ba02-4066-bc6e-1f3d34919b40": "\\section*{A.1.2. Organizational Governance}\nGAI opportunities, risks and long-term performance characteristics are typically less well-understood than non-generative Al tools and may be perceived and acted upon by humans in ways that vary greatly. Accordingly, GAI may call for different levels of oversight from AI Actors or different human-AI configurations in order to manage their risks effectively. Organizations' use of GAl systems may also warrant additional human review, tracking and documentation, and greater management oversight.", "e2033830-17c4-4c4f-bbea-965ad3497700": "Evaluation data; Ethical considerations; Legal and regulatory requirements. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity; Harmful Bias \\\\\nand Homogenization \\\\\n\\end{tabular} \\\\\n\\hline\nAI Actor Tasks: Al Deployment, Al Impact Assessment, Domain Experts, End-Users, Operation and Monitoring, TEVV &  &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "7dab18e6-92ea-412f-b812-b4d98e5ac99f": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMG-2.2-001 & \\begin{tabular}{l}\nCompare GAI system outputs against pre-defined organization risk tolerance, \\\\\nguidelines, and principles, and review and test Al-generated content against \\\\\nthese guidelines. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nCBRN Information or Capabilities; \\\\\nObscene, Degrading, and/or \\\\\nAbusive Content; Harmful Bias and \\\\\nHomogenization; Dangerous, \\\\\nViolent, or Hateful Content \\\\\n\\end{tabular} \\\\\n\\hline\nMG-2.2-002 & \\begin{tabular}{l}\nDocument training data sources to trace the origin and provenance of AI- \\\\\ngenerated content. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity \\\\\n\\end{tabular} \\\\\n\\hline\nMG-2.2-003 & \\begin{tabular}{l}\nEvaluate feedback loops between GAI system content provenance and human \\\\\nreviewers, and update where needed. Implement real-time monitoring systems \\\\\nto affirm that content provenance protocols remain effective. \\\\", "92dc29b2-cdda-400c-9af3-14eb0bbdb8b3": "\\end{itemize}\nEach table of suggested actions includes:\n\\begin{itemize}\n  \\item Action ID: Each Action ID corresponds to the relevant AI RMF function and subcategory (e.g., GV1.1-001 corresponds to the first suggested action for Govern 1.1, GV-1.1-002 corresponds to the second suggested action for Govern 1.1). Al RMF functions are tagged as follows: GV = Govern; MP = Map; MS = Measure; MG = Manage.\n  \\item Suggested Action: Steps an organization or AI actor can take to manage GAI risks.\n  \\item GAI Risks: Tags linking suggested actions with relevant GAI risks.\n  \\item Al Actor Tasks: Pertinent Al Actor Tasks for each subcategory. Not every AI Actor Task listed will apply to every suggested action in the subcategory (i.e., some apply to AI development and others apply to AI deployment).\n\\end{itemize}\nThe tables below begin with the AI RMF subcategory, shaded in blue, followed by suggested actions.", "ba5de81e-b2e6-49fc-ba3f-04da42fe9c7d": "sources; demographic group and subgroup coverage in GAI system training \\\\\ndata; Forms of latent systemic bias in images, text, audio, embeddings, or other \\\\\ncomplex or unstructured data; Input data features that may serve as proxies for \\\\\ndemographic group membership (i.e., image metadata, language dialect) or \\\\\notherwise give rise to emergent bias within GAI systems; The extent to which \\\\\nthe digital divide may negatively impact representativeness in GAI system \\\\\ntraining and TEVV data; Filtering of hate speech or content in GAI system \\\\\ntraining data; Prevalence of GAI-generated data in GAI system training data. \\\\\n\\end{tabular} & Harmful Bias and Homogenization \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "8daa123d-2907-4803-8e0a-933607158f29": "\\end{tabular} & Harmful Bias and Homogenization \\\\\n\\hline\nGV-2.1-003 & \\begin{tabular}{l}\nEstablish processes to verify the AI Actors conducting GAI incident response tasks \\\\\ndemonstrate and maintain the appropriate skills and training. \\\\\n\\end{tabular} & Human-AI Configuration \\\\\n\\hline\nGV-2.1-004 & \\begin{tabular}{l}\nWhen systems may raise national security risks, involve national security \\\\\nprofessionals in mapping, measuring, and managing those risks. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nCBRN Information or Capabilities; \\\\\nDangerous, Violent, or Hateful \\\\\nContent; Information Security \\\\\n\\end{tabular} \\\\\n\\hline\n & \\begin{tabular}{l}\nCreate mechanisms to provide protections for whistleblowers who report, based \\\\\non reasonable belief, when the organization violates relevant laws or poses a \\\\\nspecific and empirically well-substantiated negative risk to public safety (or has \\\\\nalready caused harm). \\\\\n\\end{tabular} & \\begin{tabular}{l}\nCBRN Information or Capabilities; \\\\", "48efa867-93c3-47e1-afb7-429002bb0efa": "Zhang, Y. et al. (2023) Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models. arXiv. \\href{https://arxiv.org/pdf/2309.01219}{https://arxiv.org/pdf/2309.01219}\\\\\nZhao, X. et al. (2023) Provable Robust Watermarking for AI-Generated Text. Semantic Scholar. \\href{https://www.semanticscholar.org/paper/Provable-Robust-Watermarking-for-Al-Generated-Text-ZhaoAnanth/75b68d0903af9d9f6e47ce3cf7e1a7d27ec811dc}{https://www.semanticscholar.org/paper/Provable-Robust-Watermarking-for-Al-Generated-Text-ZhaoAnanth/75b68d0903af9d9f6e47ce3cf7e1a7d27ec811dc}", "2e55de65-6995-4fbf-8986-3358d40fff13": "}\nThis work was informed by public feedback and consultations with diverse stakeholder groups as part of NIST's\\\\\nGenerative AI Public Working Group (GAI PWG). The GAI PWG was an open, transparent, and collaborative\\\\\nprocess, facilitated via a virtual workspace, to obtain multistakeholder input on GAI risk management and to\\\\\ninform NIST's approach.\\\\\nThe focus of the GAI PWG was limited to four primary considerations relevant to GAI: Governance, Content\\\\\nProvenance, Pre-deployment Testing, and Incident Disclosure (further described in Appendix A). As such, the\\\\\nsuggested actions in this document primarily address these considerations.\\\\\nFuture revisions of this profile will include additional AI RMF subcategories, risks, and suggested actions based\\\\\non additional considerations of GAI as the space evolves and empirical evidence indicates additional risks. A\\\\\nglossary of terms pertinent to GAI risk management will be developed and hosted on NIST's Trustworthy \\&\\\\", "3a16480f-3587-40ad-a7cd-2b0cd502a91e": "Trustworthy AI Characteristics: Fair with Harmful Bias Managed, Safe, Valid and Reliable, Explainable and Interpretable\n\\subsection*{2.3. Dangerous, Violent, or Hateful Content}\nGAI systems can produce content that is inciting, radicalizing, or threatening, or that glorifies violence, with greater ease and scale than other technologies. LLMs have been reported to generate dangerous or violent recommendations, and some models have generated actionable instructions for dangerous or", "097aa4c8-235b-4c3a-b69b-5cf1be822422": "12. Value Chain and Component Integration: Non-transparent or untraceable integration of upstream third-party components, including data that has been improperly obtained or not processed and cleaned due to increased automation from GAI ; improper supplier vetting across the Al lifecycle; or other issues that diminish transparency or accountability for downstream users.\n\\subsection*{2.1. CBRN Information or Capabilities}\nIn the future, GAI may enable malicious actors to more easily access CBRN weapons and/or relevant knowledge, information, materials, tools, or technologies that could be misused to assist in the design, development, production, or use of CBRN weapons or other dangerous materials or agents. While relevant biological and chemical threat knowledge and information is often publicly accessible, LLMs could facilitate its analysis or synthesis, particularly by individuals without formal scientific training or expertise.", "848a1a99-1cad-41bf-975e-bb849070ca37": "MEASURE 1.3: Internal experts who did not serve as front-line developers for the system and/or independent assessors are involved in regular assessments and updates. Domain experts, users, Al Actors external to the team that developed or deployed the Al system, and affected communities are consulted in support of assessments as necessary per organizational risk tolerance.", "722a5ff3-ac1f-498f-884e-0456702cf005": "Organizations can restrict AI applications that cause harm, exceed stated risk tolerances, or that conflict with their tolerances or values. Governance tools and protocols that are applied to other types of AI systems can be applied to GAI systems. These plans and actions include:\n\\begin{itemize}\n  \\item Accessibility and reasonable accommodations\n  \\item Al actor credentials and qualifications\n  \\item Alignment to organizational values\n  \\item Auditing and assessment\n  \\item Change-management controls\n  \\item Commercial use\n  \\item Data provenance\n  \\item Data protection\n  \\item Data retention\n  \\item Consistency in use of defining key terms\n  \\item Decommissioning\n  \\item Discouraging anonymous use\n  \\item Education\n  \\item Impact assessments\n  \\item Incident response\n  \\item Monitoring\n  \\item Opt-outs\n  \\item Risk-based controls\n  \\item Risk mapping and measurement\n  \\item Science-backed TEVV practices\n  \\item Secure software development practices\n  \\item Stakeholder engagement", "b3da57a9-b2cc-4d0f-976f-981b23f59d48": "Kalai, A., et al. (2024) Calibrated Language Models Must Hallucinate. arXiv.\\\\\n\\href{https://arxiv.org/pdf/2311.14648}{https://arxiv.org/pdf/2311.14648}\n\nKarasavva, V. et al. (2021) Personality, Attitudinal, and Demographic Predictors of Non-consensual Dissemination of Intimate Images. NIH. \\href{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9554400/}{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9554400/}\n\nKatzman, J., et al. (2023) Taxonomizing and measuring representational harms: a look at image tagging. AAAI. \\href{https://dl.acm.org/doi/10.1609/aaai.v37i12.26670}{https://dl.acm.org/doi/10.1609/aaai.v37i12.26670}\n\nKhan, T. et al. (2024) From Code to Consumer: PAl's Value Chain Analysis Illuminates Generative Al's Key Players. AI. \\href{https://partnershiponai.org/from-code-to-consumer-pais-value-chain-analysis-illuminatesgenerative-ais-key-players/}{https://partnershiponai.org/from-code-to-consumer-pais-value-chain-analysis-illuminatesgenerative-ais-key-players/}", "2b6ea3e5-6a37-4a10-94a8-0ea2bcda7950": "GAI systems can also ease the deliberate production or dissemination of false or misleading information (disinformation) at scale, where an actor has the explicit intent to deceive or cause harm to others. Even very subtle changes to text or images can manipulate human and machine perception.\n\nSimilarly, GAI systems could enable a higher degree of sophistication for malicious actors to produce disinformation that is targeted towards specific demographics. Current and emerging multimodal models make it possible to generate both text-based disinformation and highly realistic \"deepfakes\" - that is, synthetic audiovisual content and photorealistic images. ${ }^{12}$ Additional disinformation threats could be enabled by future GAI models trained on new data modalities.", "ff5923cd-41aa-46dc-8c20-63c1713f2fc1": "GOVERN 4.3: Organizational practices are in place to enable AI testing, identification of incidents, and information sharing.\n\n\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nGV4.3--001 & \\begin{tabular}{l}\nEstablish policies for measuring the effectiveness of employed content \\\\\nprovenance methodologies (e.g., cryptography, watermarking, steganography, \\\\\netc.) \\\\\n\\end{tabular} & Information Integrity \\\\\n\\hline\nGV-4.3-002 & \\begin{tabular}{l}\nEstablish organizational practices to identify the minimum set of criteria \\\\\nnecessary for GAI system incident reporting such as: System ID (auto-generated \\\\\nmost likely), Title, Reporter, System/Source, Data Reported, Date of Incident, \\\\\nDescription, Impact(s), Stakeholder(s) Impacted. \\\\\n\\end{tabular} & Information Security \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "233006a5-9951-4360-8bc8-4a3279ffe6a1": "MEASURE 4.2: Measurement results regarding AI system trustworthiness in deployment context(s) and across the AI lifecycle are informed by input from domain experts and relevant AI Actors to validate whether the system is performing consistently as intended. Results are documented.", "3eebc57d-aa74-4a1d-9413-b8587422d583": "National Institute of Standards and Technology (2023) AI Risk Management Framework. \\href{https://www.nist.gov/itl/ai-risk-management-framework}{https://www.nist.gov/itl/ai-risk-management-framework}", "44e01ab6-e060-492b-b59a-8748879c2aed": "Beyond harms from information exposure (such as extortion or dignitary harm), wrong or inappropriate inferences of PII can contribute to downstream or secondary harmful impacts. For example, predictive inferences made by GAI models based on PII or protected attributes can contribute to adverse decisions, leading to representational or allocative harms to individuals or groups (see Harmful Bias and Homogenization below).\n\nTrustworthy Al Characteristics: Accountable and Transparent, Privacy Enhanced, Safe, Secure and Resilient\n\\subsection*{2.5. Environmental Impacts}\nTraining, maintaining, and operating (running inference on) GAI systems are resource-intensive activities, with potentially large energy and environmental footprints. Energy and carbon emissions vary based on what is being done with the GAI model (i.e., pre-training, fine-tuning, inference), the modality of the content, hardware used, and type of task or application.", "f7297065-82a0-404c-a377-dc75e7ea869c": "Provenance metadata can include information about GAI model developers or creators of GAI content, date/time of creation, location, modifications, and sources. Metadata can be tracked for text, images, videos, audio, and underlying datasets. The implementation of provenance data tracking techniques can help assess the authenticity, integrity, intellectual property rights, and potential manipulations in digital content. Some well-known techniques for provenance data tracking include digital watermarking, metadata recording, digital fingerprinting, and human authentication, among others.\n\\section*{Provenance Data Tracking Approaches}", "878d5cf0-b017-40b9-b2fa-c5f5a6068922": "reviewers, and update where needed. Implement real-time monitoring systems \\\\\nto affirm that content provenance protocols remain effective. \\\\\n\\end{tabular} & Information Integrity \\\\\n\\hline\nMG-2.2-004 & \\begin{tabular}{l}\nEvaluate GAI content and data for representational biases and employ \\\\\ntechniques such as re-sampling, re-ranking, or adversarial training to mitigate \\\\\nbiases in the generated content. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Security; Harmful Bias \\\\\nand Homogenization \\\\\n\\end{tabular} \\\\\n\\hline\n & \\begin{tabular}{l}\nEngage in due diligence to analyze GAI output for harmful content, potential \\\\\nmisinformation, and CBRN-related or NCII content. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nCBRN Information or Capabilities; \\\\\nObscene, Degrading, and/or \\\\\nAbusive Content; Harmful Bias and \\\\\nHomogenization; Dangerous, \\\\\nViolent, or Hateful Content \\\\\n\\end{tabular} \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "59182c45-1a53-4d1c-a7a5-40d02b10c3fd": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMP-5.2-001 & \\begin{tabular}{l}\nDetermine context-based measures to identify if new impacts are present due to \\\\\nthe GAI system, including regular engagements with downstream AI Actors to \\\\\nidentify and quantify new contexts of unanticipated impacts of GAI systems. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-AI Configuration; Value \\\\\nChain and Component Integration \\\\\n\\end{tabular} \\\\\n\\hline\nMP-5.2-002 & \\begin{tabular}{l}\nPlan regular engagements with AI Actors responsible for inputs to GAI systems, \\\\\nincluding third-party data and algorithms, to review and evaluate unanticipated \\\\\nimpacts. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-AI Configuration; Value \\\\\nChain and Component Integration \\\\\n\\end{tabular} \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "3576cea8-e4e0-4b2a-a430-969f4ed93a5e": "${ }^{7}$ What is categorized as sensitive data or sensitive PII can be highly contextual based on the nature of the information, but examples of sensitive information include information that relates to an information subject's most intimate sphere, including political opinions, sex life, or criminal convictions.\\\\\n${ }^{8}$ The notion of harm presumes some baseline scenario that the harmful factor (e.g., a GAI model) makes worse. When the mechanism for potential harm is a disparity between groups, it can be difficult to establish what the most appropriate baseline is to compare against, which can result in divergent views on when a disparity between Al behaviors for different subgroups constitutes a harm. In discussing harms from disparities such as biased behavior, this document highlights examples where someone's situation is worsened relative to what it would have been in the absence of any AI system, making the outcome unambiguously a harm of the system.\n}", "98a575e6-ed7e-4ef0-8d39-fb53bb993614": "Tirrell, L. (2017) Toxic Speech: Toward an Epidemiology of Discursive Harm. Philosophical Topics, 45(2), 139-162. \\href{https://www.jstor.org/stable/26529441}{https://www.jstor.org/stable/26529441}\n\nTufekci, Z. (2015) Algorithmic Harms Beyond Facebook and Google: Emergent Challenges of Computational Agency. Colorado Technology Law Journal. \\href{https://ctlj.colorado.edu/wpcontent/uploads/2015/08/Tufekci-final.pdf}{https://ctlj.colorado.edu/wpcontent/uploads/2015/08/Tufekci-final.pdf}\n\nTurri, V. et al. (2023) Why We Need to Know More: Exploring the State of Al Incident Documentation Practices. AAAI/ACM Conference on AI, Ethics, and Society. \\href{https://dl.acm.org/doi/fullHtml/10.1145/3600211.3604700}{https://dl.acm.org/doi/fullHtml/10.1145/3600211.3604700}\n\nUrbina, F. et al. (2022) Dual use of artificial-intelligence-powered drug discovery. Nature Machine Intelligence. \\href{https://www.nature.com/articles/s42256-022-00465-9}{https://www.nature.com/articles/s42256-022-00465-9}", "2c417a32-29dc-4234-898d-133371a9569c": "structured human feedback exercises, e.g., GAI red-teaming, would be most \\\\\nbeneficial for GAI risk measurement and management based on the context of \\\\\nuse. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHarmful Bias and \\\\\nHomogenization; CBRN \\\\\nInformation or Capabilities \\\\\n\\end{tabular} \\\\\n\\hline\nMS-1.1-009 & \\begin{tabular}{l}\nTrack and document risks or opportunities related to all GAI risks that cannot be \\\\\nmeasured quantitatively, including explanations as to why some risks cannot be \\\\\nmeasured (e.g., due to technological limitations, resource constraints, or \\\\\ntrustworthy considerations). Include unmeasured risks in marginal risks. \\\\\n\\end{tabular} & Information Integrity \\\\\n\\hline\nAI Actor Tasks: Al Development, Domain Experts, TEVV &  &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "efb401f3-c261-4477-87f5-529dfcb4809d": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMS-2.12-001 & Assess safety to physical environments when deploying GAI systems. & \\begin{tabular}{l}\nDangerous, Violent, or Hateful \\\\\nContent \\\\\n\\end{tabular} \\\\\n\\hline\nMS-2.12-002 & \\begin{tabular}{l}\nDocument anticipated environmental impacts of model development, \\\\\nmaintenance, and deployment in product design decisions. \\\\\n\\end{tabular} & Environmental \\\\\n\\hline\nMS-2.12-003 & \\begin{tabular}{l}\nMeasure or estimate environmental impacts (e.g., energy and water \\\\\nconsumption) for training, fine tuning, and deploying models: Verify tradeoffs \\\\\nbetween resources used at inference time versus additional resources required \\\\\nat training time. \\\\\n\\end{tabular} & Environmental \\\\\n\\hline\nMS-2.12-004 & \\begin{tabular}{l}\nVerify effectiveness of carbon capture or offset programs for GAI training and \\\\\napplications, and address green-washing concerns. \\\\\n\\end{tabular} & Environmental \\\\", "20dd94da-7b5a-4ce7-9419-d5d5cea8358e": "Canadian Centre for Cyber Security (2023) Generative artificial intelligence (AI) - ITSAP.00.041. \\href{https://www.cyber.gc.ca/en/guidance/generative-artificial-intelligence-ai-itsap00041}{https://www.cyber.gc.ca/en/guidance/generative-artificial-intelligence-ai-itsap00041}\n\nCarlini, N., et al. (2021) Extracting Training Data from Large Language Models. Usenix. \\href{https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting}{https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting}\n\nCarlini, N. et al. (2023) Quantifying Memorization Across Neural Language Models. ICLR 2023. \\href{https://arxiv.org/pdf/2202.07646}{https://arxiv.org/pdf/2202.07646}\n\nCarlini, N. et al. (2024) Stealing Part of a Production Language Model. arXiv. \\href{https://arxiv.org/abs/2403.06634}{https://arxiv.org/abs/2403.06634}", "80e8b824-dc30-45f0-8952-cc5c2b0066dc": "\\begin{center}\n\\begin{tabular}{|c|c|c|}\n\\hline\nGV-6.1-005 & \\begin{tabular}{l}\nImplement a use-cased based supplier risk assessment framework to evaluate and \\\\\nmonitor third-party entities' performance and adherence to content provenance \\\\\nstandards and technologies to detect anomalies and unauthorized changes; \\\\\nservices acquisition and value chain risk management; and legal compliance. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nData Privacy; Information \\\\\nIntegrity; Information Security; \\\\\nIntellectual Property; Value Chain \\\\\nand Component Integration \\\\\n\\end{tabular} \\\\\n\\hline\nGV-6.1-006 & \\begin{tabular}{l}\nInclude clauses in contracts which allow an organization to evaluate third-party \\\\\nGAI processes and standards. \\\\\n\\end{tabular} & Information Integrity \\\\\n\\hline\nGV-6.1-007 & \\begin{tabular}{l}\nInventory all third-party entities with access to organizational content and \\\\\nestablish approved GAI technology and service provider lists. \\\\\n\\end{tabular} & \\begin{tabular}{l}", "da762b08-e198-4f76-b0de-4056de5adf91": "Measurement gaps can arise from mismatches between laboratory and real-world settings. Current testing approaches often remain focused on laboratory conditions or restricted to benchmark test datasets and in silico techniques that may not extrapolate well to-or directly assess GAI impacts in realworld conditions. For example, current measurement gaps for GAI make it difficult to precisely estimate its potential ecosystem-level or longitudinal risks and related political, social, and economic impacts. Gaps between benchmarks and real-world use of GAI systems may likely be exacerbated due to prompt sensitivity and broad heterogeneity of contexts of use.\n\\section*{A.1.5. Structured Public Feedback}\nStructured public feedback can be used to evaluate whether GAI systems are performing as intended and to calibrate and verify traditional measurement methods. Examples of structured feedback include, but are not limited to:\n\\begin{itemize}", "3f0e8110-b76c-46dc-b0e5-299425a8cae9": "\\item Opt-outs\n  \\item Risk-based controls\n  \\item Risk mapping and measurement\n  \\item Science-backed TEVV practices\n  \\item Secure software development practices\n  \\item Stakeholder engagement\n  \\item Synthetic content detection and labeling tools and techniques\n  \\item Whistleblower protections\n  \\item Workforce diversity and interdisciplinary teams\n\\end{itemize}\nEstablishing acceptable use policies and guidance for the use of GAI in formal human-Al teaming settings as well as different levels of human-Al configurations can help to decrease risks arising from misuse, abuse, inappropriate repurpose, and misalignment between systems and users. These practices are just one example of adapting existing governance protocols for GAI contexts.\n\\section*{A.1.3. Third-Party Considerations}", "5839c883-6bdd-484c-8dc0-1c5e864dd0fb": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nGV-6.1-001 & \\begin{tabular}{l}\nCategorize different types of GAI content with associated third-party rights (e.g., \\\\\ncopyright, intellectual property, data privacy). \\\\\n\\end{tabular} & \\begin{tabular}{l}\nData Privacy; Intellectual \\\\\nProperty; Value Chain and \\\\\nComponent Integration \\\\\n\\end{tabular} \\\\\n\\hline\nGV-6.1-002 & \\begin{tabular}{l}\nConduct joint educational activities and events in collaboration with third parties \\\\\nto promote best practices for managing GAI risks. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nValue Chain and Component \\\\\nIntegration \\\\\n\\end{tabular} \\\\\n\\hline\nGV-6.1-003 & \\begin{tabular}{l}\nDevelop and validate approaches for measuring the success of content \\\\\nprovenance management efforts with third parties (e.g., incidents detected and \\\\\nresponse times). \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity; Value Chain \\\\\nand Component Integration \\\\", "c55c0cc6-2706-48e6-baef-e1c5820f7625": "\\footnotetext{${ }^{9}$ Confabulations of falsehoods are most commonly a problem for text-based outputs; for audio, image, or video content, creative generation of non-factual content can be a desired behavior.\\\\\n${ }^{10}$ For example, legal confabulations have been shown to be pervasive in current state-of-the-art LLMs. See also, e.g.,\n}\nunethical behavior. Text-to-image models also make it easy to create images that could be used to promote dangerous or violent messages. Similar concerns are present for other GAI media, including video and audio. GAI may also produce content that recommends self-harm or criminal/illegal activities.", "c77ca64a-a64e-4a21-9658-2166420fb635": "Trustworthy AI Characteristics: Fair with Harmful Bias Managed, Safe, Privacy Enhanced\n\\subsection*{2.12. Value Chain and Component Integration}\nGAI value chains involve many third-party components such as procured datasets, pre-trained models, and software libraries. These components might be improperly obtained or not properly vetted, leading to diminished transparency or accountability for downstream users. While this is a risk for traditional AI systems and some other digital technologies, the risk is exacerbated for GAI due to the scale of the training data, which may be too large for humans to vet; the difficulty of training foundation models, which leads to extensive reuse of limited numbers of models; and the extent to which GAI may be integrated into other devices and services. As GAI systems often involve many distinct third-party components and data sources, it may be difficult to attribute issues in a system's behavior to any one of these sources.", "13a50e5a-e98d-4aaa-84ba-086a85df012f": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & Risks \\\\\n\\hline\nMS-2.5-001 & \\begin{tabular}{l}\nAvoid extrapolating GAI system performance or capabilities from narrow, non- \\\\\nsystematic, and anecdotal assessments. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-Al Configuration; \\\\\nConfabulation \\\\\n\\end{tabular} \\\\\n\\hline\nMS-2.5-002 & \\begin{tabular}{l}\nDocument the extent to which human domain knowledge is employed to \\\\\nimprove GAI system performance, via, e.g., RLHF, fine-tuning, retrieval- \\\\\naugmented generation, content moderation, business rules. \\\\\n\\end{tabular} & Human-Al Configuration \\\\\n\\hline\nMS-2.5-003 & \\begin{tabular}{l}\nReview and verify sources and citations in GAI system outputs during pre- \\\\\ndeployment risk measurement and ongoing monitoring activities. \\\\\n\\end{tabular} & Confabulation \\\\\n\\hline\nMS-2.5-004 & \\begin{tabular}{l}\nTrack and document instances of anthropomorphization (e.g., human images, \\\\", "0788244d-447c-4de2-b5eb-0cad0ec41af2": "performance and trustworthiness characteristics related to content provenance \\\\\nto identify deviations from the desired standards and trigger alerts for human \\\\\nintervention. \\\\\n\\end{tabular} & Information Integrity \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "8e6ac313-178d-4621-8b2e-0fbf98b7b44b": "MEASURE 2.13: Effectiveness of the employed TEVV metrics and processes in the MEASURE function are evaluated and documented.\n\n\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMS-2.13-001 & \\begin{tabular}{l}\nCreate measurement error models for pre-deployment metrics to demonstrate \\\\\nconstruct validity for each metric (i.e., does the metric effectively operationalize \\\\\nthe desired concept): Measure or estimate, and document, biases or statistical \\\\\nvariance in applied metrics or structured human feedback processes; Leverage \\\\\ndomain expertise when modeling complex societal constructs such as hateful \\\\\ncontent. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nContegrity; Harmful Bias and \\\\\nHomogenization \\\\\n\\end{tabular} \\\\\n\\hline\n\\end{tabular}\n\\end{center}\n\nAI Actor Tasks: AI Deployment, Operation and Monitoring, TEVV", "73c35238-db68-43dc-aa5d-43dcc518cebf": "Confabulation; Information \\\\\nSecurity \\\\\n\\end{tabular} \\\\\n\\hline\nMG-4.1-003 & \\begin{tabular}{l}\nEvaluate the use of sentiment analysis to gauge user sentiment regarding GAI \\\\\ncontent performance and impact, and work in collaboration with AI Actors \\\\\nexperienced in user research and experience. \\\\\n\\end{tabular} & Human-Al Configuration \\\\\n\\hline\nMG-4.1-004 & \\begin{tabular}{l}\nImplement active learning techniques to identify instances where the model fails \\\\\nor produces unexpected outputs. \\\\\n\\end{tabular} & Confabulation \\\\\n\\hline\nMG-4.1-005 & \\begin{tabular}{l}\nShare transparency reports with internal and external stakeholders that detail \\\\\nsteps taken to update the GAI system to enhance transparency and \\\\\naccountability. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-AI Configuration; Harmful \\\\\nBias and Homogenization \\\\\n\\end{tabular} \\\\\n\\hline\nMG-4.1-006 & \\begin{tabular}{l}\nTrack dataset modifications for provenance by monitoring data deletions, \\\\", "9e7de0e1-862c-402d-8766-9d968706136f": "\\footnotetext{${ }^{1}$ EO 14110 defines Generative AI as \"the class of AI models that emulate the structure and characteristics of input data in order to generate derived synthetic content. This can include images, videos, audio, text, and other digital content.\" While not all GAI is derived from foundation models, for purposes of this document, GAI generally refers to generative foundation models. The foundation model subcategory of \"dual-use foundation models\" is defined by EO 14110 as \"an AI model that is trained on broad data; generally uses self-supervision; contains at least tens of billions of parameters; is applicable across a wide range of contexts.\"\\\\\n${ }^{2}$ This profile was developed per Section 4.1(a)(i)(A) of EO 14110, which directs the Secretary of Commerce, acting through the Director of the National Institute of Standards and Technology (NIST), to develop a companion resource to the AI RMF, NIST AI 100-1, for generative AI.\n}", "4a19587a-5282-49f4-8387-826c46369881": "Wu, K. et al. (2024) How well do LLMs cite relevant medical references? An evaluation framework and analyses. arXiv. \\href{https://arxiv.org/pdf/2402.02008}{https://arxiv.org/pdf/2402.02008}\n\nYin, L. et al. (2024) OpenAl's GPT Is A Recruiter's Dream Tool. Tests Show There's Racial Bias. Bloomberg. \\href{https://www.bloomberg.com/graphics/2024-openai-gpt-hiring-racial-discrimination/}{https://www.bloomberg.com/graphics/2024-openai-gpt-hiring-racial-discrimination/}\n\nYu, Z. et al. (March 2024) Don't Listen To Me: Understanding and Exploring Jailbreak Prompts of Large Language Models. arXiv. \\href{https://arxiv.org/html/2403.17336v1}{https://arxiv.org/html/2403.17336v1}\n\nZaugg, I. et al. (2022) Digitally-disadvantaged languages. Policy Review. \\href{https://policyreview.info/pdf/policyreview-2022-2-1654.pdf}{https://policyreview.info/pdf/policyreview-2022-2-1654.pdf}", "fc12650c-97e1-4768-b6ff-898376edb3ef": "Documentation practices including logging, recording, and analyzing GAI incidents can facilitate smoother sharing of information with relevant AI Actors. Regular information sharing, change management records, version history and metadata can also empower AI Actors responding to and managing Al incidents.\n\\section*{Appendix B. References}\nAcemoglu, D. (2024) The Simple Macroeconomics of AI \\href{https://www.nber.org/papers/w32487}{https://www.nber.org/papers/w32487}\\\\\nAl Incident Database. \\href{https://incidentdatabase.ai/}{https://incidentdatabase.ai/}\\\\\nAtherton, D. (2024) Deepfakes and Child Safety: A Survey and Analysis of 2023 Incidents and Responses. Al Incident Database. \\href{https://incidentdatabase.ai/blog/deepfakes-and-child-safety/}{https://incidentdatabase.ai/blog/deepfakes-and-child-safety/}", "a593c112-7f27-45b7-80bf-e75bfbe0ebb7": "}\noperations, or other cyberattacks; increased attack surface for targeted cyberattacks, which may compromise a system's availability or the confidentiality or integrity of training data, code, or model weights.\\\\\n10. Intellectual Property: Eased production or replication of alleged copyrighted, trademarked, or licensed content without authorization (possibly in situations which do not fall under fair use); eased exposure of trade secrets; or plagiarism or illegal replication.\\\\\n11. Obscene, Degrading, and/or Abusive Content: Eased production of and access to obscene, degrading, and/or abusive imagery which can cause harm, including synthetic child sexual abuse material (CSAM), and nonconsensual intimate images ( NCII ) of adults.\\\\", "c9e0fb46-78e8-422a-b13e-f105e4068828": "Human-Al Configuration; Harmful \\\\\nBias and Homogenization \\\\\n\\end{tabular} \\\\\n\\hline\nMG-2.2-009 & \\begin{tabular}{l}\nConsider opportunities to responsibly use synthetic data and other privacy \\\\\nenhancing techniques in GAI development, where appropriate and applicable, \\\\\nmatch the statistical properties of real-world data without disclosing personally \\\\\nidentifiable information or contributing to homogenization. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nData Privacy; Intellectual Property; \\\\\nInformation Integrity; \\\\\nConfablation; Harmful Bias and \\\\\nHomogenization \\\\\n\\end{tabular} \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "25549ca0-5cb2-4b63-bf77-6d559ec9a2b7": "with the many helpful comments and contributions from the community, including the NIST Generative AI Public Working Group, and NIST staff and guest researchers: Chloe Autio, Jesse Dunietz, Patrick Hall, Shomik Jain, Kamie Roberts, Reva Schwartz, Martin Stanley, and Elham Tabassi. NIST Technical Series Policies Copyright, Use, and Licensing Statements NIST Technical Series Publication Identifier Syntax", "df4d742d-93ce-4392-8191-e2d11321477f": "\\end{tabular} & Information Integrity \\\\\n\\hline\nMP-2.3-005 & \\begin{tabular}{l}\nImplement plans for GAI systems to undergo regular adversarial testing to identify \\\\\nvulnerabilities and potential manipulation or misuse. \\\\\n\\end{tabular} & Information Security \\\\\n\\hline\nAI Actor Tasks: Al Development, Domain Experts, TEVV &  &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "f1961654-519b-4519-a38d-c8de24b34102": "Confabulations can occur across GAI outputs and contexts. ${ }^{9,10}$ Confabulations are a natural result of the way generative models are designed: they generate outputs that approximate the statistical distribution of their training data; for example, LLMs predict the next token or word in a sentence or phrase. While such statistical prediction can produce factually accurate and consistent outputs, it can also produce outputs that are factually inaccurate or internally inconsistent. This dynamic is particularly relevant when it comes to open-ended prompts for long-form responses and in domains which require highly contextual and/or domain expertise.", "6d42476f-c322-411e-af3d-fcb69e1e6870": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMS-3.3-001 & \\begin{tabular}{l}\nConduct impact assessments on how Al-generated content might affect \\\\\ndifferent social, economic, and cultural groups. \\\\\n\\end{tabular} & Harmful Bias and Homogenization \\\\\n\\hline\nMS-3.3-002 & \\begin{tabular}{l}\nConduct studies to understand how end users perceive and interact with GAI \\\\\ncontent and accompanying content provenance within context of use. Assess \\\\\nwhether the content aligns with their expectations and how they may act upon \\\\\nthe information presented. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-Al Configuration; \\\\\nInformation Integrity \\\\\n\\end{tabular} \\\\\n\\hline\nMS-3.3-003 & \\begin{tabular}{l}\nEvaluate potential biases and stereotypes that could emerge from the Al- \\\\\ngenerated content using appropriate methodologies including computational \\\\\ntesting methods as well as evaluating structured feedback input. \\\\", "d4810cb3-a17b-4cab-81da-6b2f10ba9482": "and Homogenization; Dangerous, \\\\\nViolent, or Hateful Content \\\\\n\\end{tabular} \\\\\n\\hline\nMS-2.7-008 & Verify fine-tuning does not compromise safety and security controls. & \\begin{tabular}{l}\nInformation Integrity; Information \\\\\nSecurity; Dangerous, Violent, or \\\\\nHateful Content \\\\\n\\end{tabular} \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "aa09399d-1039-4715-9d51-c14ff3a52b49": "trained weights compared to the fine-tuned model weights or other system \\\\\nupdates. \\\\\n\\end{tabular} & Information Integrity; Data Privacy \\\\\n\\hline\nMG-3.2-003 & \\begin{tabular}{l}\nDocument sources and types of training data and their origins, potential biases \\\\\npresent in the data related to the GAI application and its content provenance, \\\\\narchitecture, training process of the pre-trained model including information on \\\\\nhyperparameters, training duration, and any fine-tuning or retrieval-augmented \\\\\ngeneration processes applied. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity; Harmful Bias \\\\\nand Homogenization; Intellectual \\\\\nProperty \\\\\n\\end{tabular} \\\\\n\\hline\nMG-3.2-004 & \\begin{tabular}{l}\nEvaluate user reported problematic content and integrate feedback into system \\\\\nupdates. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-Al Configuration, \\\\\nDangerous, Violent, or Hateful \\\\\nContent \\\\\n\\end{tabular} \\\\\n\\hline\nMG-3.2-005 & \\begin{tabular}{l}", "088208f7-b80e-4ca7-88c6-eb37dbf46c7f": "\\section*{A.1.4. Pre-Deployment Testing}\n\\section*{Overview}\nThe diverse ways and contexts in which GAI systems may be developed, used, and repurposed complicates risk mapping and pre-deployment measurement efforts. Robust test, evaluation, validation, and verification (TEVV) processes can be iteratively applied - and documented - in early stages of the AI lifecycle and informed by representative AI Actors (see Figure 3 of the AI RMF). Until new and rigorous\\\\\nearly lifecycle TEVV approaches are developed and matured for GAI, organizations may use recommended \"pre-deployment testing\" practices to measure performance, capabilities, limits, risks, and impacts. This section describes risk measurement and estimation as part of pre-deployment TEVV, and examines the state of play for pre-deployment testing methodologies.\n\\section*{Limitations of Current Pre-deployment Test Approaches}", "a1f215dc-d951-4a64-8e8a-4a7a38bb1a2e": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMS-1.1-001 & Employ methods to trace the origin and modifications of digital content. & Information Integrity \\\\\n\\hline\nMS-1.1-002 & \\begin{tabular}{l}\nIntegrate tools designed to analyze content provenance and detect data \\\\\nanomalies, verify the authenticity of digital signatures, and identify patterns \\\\\nassociated with misinformation or manipulation. \\\\\n\\end{tabular} & Information Integrity \\\\\n\\hline\nMS-1.1-003 & \\begin{tabular}{l}\nDisaggregate evaluation metrics by demographic factors to identify any \\\\\ndiscrepancies in how content provenance mechanisms work across diverse \\\\\npopulations. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity; Harmful \\\\\nMS-1.1-004 and Homogenization \\\\\n\\end{tabular} \\\\\n\\hline\n & \\begin{tabular}{l}\nDevelop a suite of metrics to evaluate structured public feedback exercises \\\\\ninformed by representative AI Actors. \\\\", "143e96c7-39e9-4509-b5d8-27bea93cd1d1": "Errors in third-party GAI components can also have downstream impacts on accuracy and robustness. For example, test datasets commonly used to benchmark or validate models can contain label errors. Inaccuracies in these labels can impact the \"stability\" or robustness of these benchmarks, which many GAI practitioners consider during the model selection process.\n\nTrustworthy AI Characteristics: Accountable and Transparent, Explainable and Interpretable, Fair with Harmful Bias Managed, Privacy Enhanced, Safe, Secure and Resilient, Valid and Reliable\n\\section*{3. Suggested Actions to Manage GAI Risks}\nThe following suggested actions target risks unique to or exacerbated by GAI.\\\\\nIn addition to the suggested actions below, Al risk management activities and actions set forth in the AI RMF 1.0 and Playbook are already applicable for managing GAI risks. Organizations are encouraged to apply the activities suggested in the AI RMF and its Playbook when managing the risk of GAI systems.", "116e7109-4048-4ffb-b365-2ca80e0779b7": "MAP 5.2: Practices and personnel for supporting regular engagement with relevant AI Actors and integrating feedback about positive, negative, and unanticipated impacts are in place and documented.", "73596841-e2f3-422b-8003-860a96a989de": "\\hline\nMP-4.1-004 & \\begin{tabular}{l}\nDocument training data curation policies, to the extent possible and according to \\\\\napplicable laws and policies. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nIntellectual Property; Data Privacy; \\\\\nObscene, Degrading, and/or \\\\\nAbusive Content \\\\\n\\end{tabular} \\\\\n\\hline\nMP-4.1-005 & \\begin{tabular}{l}\nEstablish policies for collection, retention, and minimum quality of data, in \\\\\nconsideration of the following risks: Disclosure of inappropriate CBRN information; \\\\\nUse of Illegal or dangerous content; Offensive cyber capabilities; Training data \\\\\nimbalances that could give rise to harmful biases; Leak of personally identifiable \\\\\ninformation, including facial likenesses of individuals. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nCBRN Information or Capabilities; \\\\\nIntellectual Property; Information \\\\\nSecurity; Harmful Bias and \\\\\nHomogenization; Dangerous, \\\\\nViolent, or Hateful Content; Data \\\\\nPrivacy \\\\\n\\end{tabular} \\\\\n\\hline", "ab9e8bc4-42c1-492c-8e55-869587b0f170": "Solaiman, I. et al. (2023) The Gradient of Generative AI Release: Methods and Considerations. arXiv. \\href{https://arxiv.org/abs/2302.04844}{https://arxiv.org/abs/2302.04844}\n\nStaab, R. et al. (2023) Beyond Memorization: Violating Privacy via Inference With Large Language Models. arXiv. \\href{https://arxiv.org/pdf/2310.07298}{https://arxiv.org/pdf/2310.07298}\n\nStanford, S. et al. (2023) Whose Opinions Do Language Models Reflect? arXiv.\\\\\n\\href{https://arxiv.org/pdf/2303.17548}{https://arxiv.org/pdf/2303.17548}\\\\\nStrubell, E. et al. (2019) Energy and Policy Considerations for Deep Learning in NLP. arXiv. \\href{https://arxiv.org/pdf/1906.02243}{https://arxiv.org/pdf/1906.02243}", "20451e87-61a8-4d37-88db-40312a928546": "OpenAI (2023) GPT-4 System Card. \\href{https://cdn.openai.com/papers/gpt-4-system-card.pdf}{https://cdn.openai.com/papers/gpt-4-system-card.pdf}\\\\\nOpenAI (2024) GPT-4 Technical Report. \\href{https://arxiv.org/pdf/2303.08774}{https://arxiv.org/pdf/2303.08774}\\\\\nPadmakumar, V. et al. (2024) Does writing with language models reduce content diversity? ICLR. \\href{https://arxiv.org/pdf/2309.05196}{https://arxiv.org/pdf/2309.05196}\n\nPark, P. et. al. (2024) Al deception: A survey of examples, risks, and potential solutions. Patterns, 5(5). arXiv. \\href{https://arxiv.org/pdf/2308.14752}{https://arxiv.org/pdf/2308.14752}\n\nPartnership on AI (2023) Building a Glossary for Synthetic Media Transparency Methods, Part 1: Indirect Disclosure. \\href{https://partnershiponai.org/glossary-for-synthetic-media-transparency-methods-part-1indirect-disclosure/}{https://partnershiponai.org/glossary-for-synthetic-media-transparency-methods-part-1indirect-disclosure/}", "2793bc04-9746-4694-993e-e7a680a7c4a6": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\n & \\begin{tabular}{l}\nConsider the following factors when updating or defining risk tiers for GAI: Abuses \\\\\nand impacts to information integrity; Dependencies between GAI and other IT or \\\\\ndata systems; Harm to fundamental rights or public safety; Presentation of \\\\\nobscene, objectionable, offensive, discriminatory, invalid or untruthful output; \\\\\nPsychological impacts to humans (e.g., anthropomorphization, algorithmic \\\\\naversion, emotional entanglement); Possibility for malicious use; Whether the \\\\\nsystem introduces significant new security vulnerabilities; Anticipated system \\\\\nimpact on some groups compared to others; Unreliable decision making \\\\\ncapabilities, validity, adaptability, and variability of GAI system performance over \\\\\ntime. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity; Obscene, \\\\\nDegrading, and/or Abusive \\\\\nContent; Value Chain and \\\\", "80c06750-c067-4ffe-89f7-761137f50d7e": "\\section*{A.1.7. Enhancing Content Provenance through Structured Public Feedback}\nWhile indirect feedback methods such as automated error collection systems are useful, they often lack the context and depth that direct input from end users can provide. Organizations can leverage feedback approaches described in the Pre-Deployment Testing section to capture input from external sources such as through Al red-teaming.", "544f4c11-2c36-40af-99fe-b4dd76bdee7e": "Suggested actions to manage GAI risks can be found in the tables below:\n\\begin{itemize}\n  \\item The suggested actions are organized by relevant AI RMF subcategories to streamline these activities alongside implementation of the AI RMF.\n  \\item Not every subcategory of the AI RMF is included in this document. ${ }^{13}$ Suggested actions are listed for only some subcategories.\n\\end{itemize}\n\\footnotetext{${ }^{13}$ As this document was focused on the GAI PWG efforts and primary considerations (see Appendix A), AI RMF subcategories not addressed here may be added later.\n}\\begin{itemize}\n  \\item Not every suggested action applies to every AI Actor ${ }^{14}$ or is relevant to every AI Actor Task. For example, suggested actions relevant to GAI developers may not be relevant to GAI deployers. The applicability of suggested actions to relevant AI actors should be determined based on organizational considerations and their unique uses of GAI systems.\n\\end{itemize}", "37f3123a-a6c4-4df2-8ac4-e6f22d5ed32e": "Bias exists in many forms and can become ingrained in automated systems. Al systems, including GAI systems, can increase the speed and scale at which harmful biases manifest and are acted upon, potentially perpetuating and amplifying harms to individuals, groups, communities, organizations, and society. For example, when prompted to generate images of CEOs, doctors, lawyers, and judges, current text-to-image models underrepresent women and/or racial minorities, and people with disabilities. Image generator models have also produced biased or stereotyped output for various demographic groups and have difficulty producing non-stereotyped content even when the prompt specifically requests image features that are inconsistent with the stereotypes. Harmful bias in GAI models, which may stem from their training data, can also cause representational harms or perpetuate or exacerbate bias based on race, gender, disability, or other protected classes.", "66abe835-2c2b-42f6-adbd-17b337dec600": "updates. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-Al Configuration, \\\\\nDangerous, Violent, or Hateful \\\\\nContent \\\\\n\\end{tabular} \\\\\n\\hline\nMG-3.2-005 & \\begin{tabular}{l}\nImplement content filters to prevent the generation of inappropriate, harmful, \\\\\nfalse, illegal, or violent content related to the GAI application, including for CSAM \\\\\nand NCII. These filters can be rule-based or leverage additional machine learning \\\\\nmodels to flag problematic inputs and outputs. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity; Harmful Bias \\\\\nand Homogenization; Dangerous, \\\\\nViolent, or Hateful Content; \\\\\nObscene, Degrading, and/or \\\\\nAbusive Content \\\\\n\\end{tabular} \\\\\n\\hline\nMG-3.2-006 & \\begin{tabular}{l}\nImplement real-time monitoring processes for analyzing generated content \\\\\nperformance and trustworthiness characteristics related to content provenance \\\\\nto identify deviations from the desired standards and trigger alerts for human \\\\\nintervention. \\\\", "cba45f7d-be8f-423c-8c88-61ea148b8413": "\\end{tabular} \\\\\n\\hline\nMS-2.6-007 & \\begin{tabular}{l}\nRegularly evaluate GAI system vulnerabilities to possible circumvention of safety \\\\\nmeasures. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nCBRN Information or Capabilities; \\\\\nInformation Security \\\\\n\\end{tabular} \\\\\n\\hline\n\\multicolumn{3}{|l|}{AI Actor Tasks: AI Deployment, Al Impact Assessment, Domain Experts, Operation and Monitoring, TEVV} \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "3b9f9385-940b-4184-881b-3ce5cff5e924": "Models may leak, generate, or correctly infer sensitive information about individuals. For example, during adversarial attacks, LLMs have revealed sensitive information (from the public domain) that was included in their training data. This problem has been referred to as data memorization, and may pose exacerbated privacy risks even for data present only in a small number of training samples.\n\nIn addition to revealing sensitive information in GAI training data, GAI models may be able to correctly infer PII or sensitive data that was not in their training data nor disclosed by the user by stitching together information from disparate sources. These inferences can have negative impact on an individual even if the inferences are not accurate (e.g., confabulations), and especially if they reveal information that the individual considers sensitive or that is used to disadvantage or harm them.", "3af10d3e-d7b6-4b30-974b-612bac8808fc": "MAP 3.4: Processes for operator and practitioner proficiency with Al system performance and trustworthiness - and relevant technical standards and certifications - are defined, assessed, and documented.", "326aaa04-663a-4e5e-96df-e0bb785f2638": "Organizations may also collect feedback on outcomes, harms, and user experience directly from users in the production environment after a model has been released, in accordance with human subject standards such as informed consent and compensation. Organizations should follow applicable human subjects research requirements, and best practices such as informed consent and subject compensation, when implementing feedback activities.\n\\section*{Al Red-teaming}\nAl red-teaming is an evolving practice that references exercises often conducted in a controlled environment and in collaboration with AI developers building AI models to identify potential adverse behavior or outcomes of a GAI model or system, how they could occur, and stress test safeguards\". AI red-teaming can be performed before or after AI models or systems are made available to the broader public; this section focuses on red-teaming in pre-deployment contexts.", "19786f5a-3629-4803-91d9-0cdfc3bf985f": "\\begin{center}\n\\begin{tabular}{|c|c|c|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMS-2.6-001 & \\begin{tabular}{l}\nAssess adverse impacts, including health and wellbeing impacts for value chain \\\\\nor other AI Actors that are exposed to sexually explicit, offensive, or violent \\\\\ninformation during GAI training and maintenance. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-Al Configuration; Obscene, \\\\\nDegrading, and/or Abusive \\\\\nContent; Value Chain and \\\\\nComponent Integration; \\\\\nDangerous, Violent, or Hateful \\\\\nContent \\\\\n\\end{tabular} \\\\\n\\hline\nMS-2.6-002 & \\begin{tabular}{l}\nAssess existence or levels of harmful bias, intellectual property infringement, \\\\\ndata privacy violations, obscenity, extremism, violence, or CBRN information in \\\\\nsystem training data. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nData Privacy; Intellectual Property; \\\\\nObscene, Degrading, and/or \\\\\nAbusive Content; Harmful Bias and \\\\\nHomogenization; Dangerous, \\\\", "fdf8f937-89f4-4983-82eb-6059669e6b01": "}\\begin{enumerate}\n  \\item CBRN Information or Capabilities: Eased access to or synthesis of materially nefarious information or design capabilities related to chemical, biological, radiological, or nuclear (CBRN) weapons or other dangerous materials or agents.\n  \\item Confabulation: The production of confidently stated but erroneous or false content (known colloquially as \"hallucinations\" or \"fabrications\") by which users may be misled or deceived. ${ }^{6}$\n  \\item Dangerous, Violent, or Hateful Content: Eased production of and access to violent, inciting, radicalizing, or threatening content as well as recommendations to carry out self-harm or conduct illegal activities. Includes difficulty controlling public exposure to hateful and disparaging or stereotyping content.\n  \\item Data Privacy: Impacts due to leakage and unauthorized use, disclosure, or de-anonymization of biometric, health, location, or other personally identifiable information or sensitive data. ${ }^{7}$", "233bd1cd-3641-4b3b-8735-1277aaef1b17": "model to prioritize robustness (the durability of a watermark), an AI actor may inadvertently diminish computational complexity (the resources required to implement watermarking). Organizational risk management efforts for enhancing content provenance include:", "6474baa3-fedf-40fa-8c5f-f65dcd851968": "The quality of AI red-teaming outputs is related to the background and expertise of the AI red team itself. Demographically and interdisciplinarily diverse AI red teams can be used to identify flaws in the varying contexts where GAI will be used. For best results, Al red teams should demonstrate domain expertise, and awareness of socio-cultural aspects within the deployment context. Al red-teaming results should be given additional analysis before they are incorporated into organizational governance and decision making, policy and procedural updates, and Al risk management efforts.", "fb83da0b-b594-4803-89d0-fa025529baa6": "(e.g., source, signatures, versioning, watermarks); Known issues reported from \\\\\ninternal bug tracking or external information sharing resources (e.g., Al incident \\\\\ndatabase, AVID, CVE, NVD, or OECD AI incident monitor); Human oversight roles \\\\\nand responsibilities; Special rights and considerations for intellectual property, \\\\\nlicensed works, or personal, privileged, proprietary or sensitive data; Underlying \\\\\nfoundation models, versions of underlying models, and access modes. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nData Privacy; Human-AI \\\\\nConfiguration; Information \\\\\nIntegrity; Intellectual Property; \\\\\nValue Chain and Component \\\\\nIntegration \\\\\n\\end{tabular} \\\\\n\\hline\n\\multicolumn{3}{|l|}{AI Actor Tasks: Governance and Oversight} \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "3473485b-fca5-4079-b49e-14eac606cf4e": "Trustworthy AI Characteristics: Safe, Secure and Resilient\n\\subsection*{2.4. Data Privacy}\nGAI systems raise several risks to privacy. GAI system training requires large volumes of data, which in some cases may include personal data. The use of personal data for GAI training raises risks to widely accepted privacy principles, including to transparency, individual participation (including consent), and purpose specification. For example, most model developers do not disclose specific data sources on which models were trained, limiting user awareness of whether personally identifiably information (PII) was trained on and, if so, how it was collected.", "1a9c2b98-427c-4f16-bee2-64eb806c2a21": "MANAGE 4.1: Post-deployment AI system monitoring plans are implemented, including mechanisms for capturing and evaluating input from users and other relevant AI Actors, appeal and override, decommissioning, incident response, recovery, and change management.", "9bdb2a6d-1cd1-4916-85d2-bb9857944902": "\\section*{Limitations of Current Pre-deployment Test Approaches}\nCurrently available pre-deployment TEVV processes used for GAI applications may be inadequate, nonsystematically applied, or fail to reflect or mismatched to deployment contexts. For example, the anecdotal testing of GAI system capabilities through video games or standardized tests designed for humans (e.g., intelligence tests, professional licensing exams) does not guarantee GAI system validity or reliability in those domains. Similarly, jailbreaking or prompt engineering tests may not systematically assess validity or reliability risks.", "a92f3754-572b-4aa4-adfd-54bee7e27758": "AI Actor Tasks: Al Deployment, Operation and Monitoring\n\nMANAGE 2.4: Mechanisms are in place and applied, and responsibilities are assigned and understood, to supersede, disengage, or deactivate Al systems that demonstrate performance or outcomes inconsistent with intended use.\n\n\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMG-2.4-001 & \\begin{tabular}{l}\nEstablish and maintain communication plans to inform AI stakeholders as part of \\\\\nthe deactivation or disengagement process of a specific GAI system (including for \\\\\nopen-source models) or context of use, including reasons, workarounds, user \\\\\naccess removal, alternative processes, contact information, etc. \\\\\n\\end{tabular} & Human-AI Configuration \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "79093222-a776-4094-9e9b-6860c9f447a2": "Future revisions of this profile will include additional AI RMF subcategories, risks, and suggested actions based on additional considerations of GAI as the space evolves and empirical evidence indicates additional risks. A glossary of terms pertinent to GAI risk management will be developed and hosted on NIST's Trustworthy \\& Responsible AI Resource Center (AIRC), and added to The Language of Trustworthy Al: An In-Depth Glossary of Terms.", "11b184d7-8a46-4a9d-b5fc-899aba62b132": "Trustworthy AI Characteristics: Fair with Harmful Bias Managed, Valid and Reliable\n\\subsection*{2.7. Human-Al Configuration}\nGAI system use can involve varying risks of misconfigurations and poor interactions between a system and a human who is interacting with it. Humans bring their unique perspectives, experiences, or domainspecific expertise to interactions with AI systems but may not have detailed knowledge of AI systems and how they work. As a result, human experts may be unnecessarily \"averse\" to GAI systems, and thus deprive themselves or others of GAl's beneficial uses.", "7972419a-36b3-49ad-b3a1-eb4a21753f2f": "GOVERN 4.2: Organizational teams document the risks and potential impacts of the Al technology they design, develop, deploy, evaluate, and use, and they communicate about the impacts more broadly.\n\n\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nGV-4.2-001 & Establish terms of use and terms of service for GAI systems. & \\begin{tabular}{l}\nIntellectual Property; Dangerous, \\\\\nViolent, or Hateful Content; \\\\\nObscene, Degrading, and/or \\\\\nAbusive Content \\\\\n\\end{tabular} \\\\\n\\hline\nGV-4.2-002 & Include relevant AI Actors in the GAI system risk identification process. & Human-AI Configuration \\\\\n\\hline\nGV-4.2-003 & \\begin{tabular}{l}\nVerify that downstream GAI system impacts (such as the use of third-party \\\\\nplugins) are included in the impact documentation process. \\\\\n\\end{tabular} & Integration \\\\\n\\hline\nAI Actor Tasks: AI Deployment, AI Design, AI Development, Operation and Monitoring &  &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "7c062d88-d001-4df4-ab84-b2e6d80c5428": "\\begin{itemize}\n  \\item Tracking provenance of training data and metadata for GAI systems;\n  \\item Documenting provenance data limitations within GAI systems;\n  \\item Monitoring system capabilities and limitations in deployment through rigorous TEVV processes;\n  \\item Evaluating how humans engage, interact with, or adapt to GAI content (especially in decision making tasks informed by GAI content), and how they react to applied provenance techniques such as overt disclosures.\n\\end{itemize}", "cc74d635-f137-46ca-a156-6cbbacd5cbb6": "Hagan, M. (2024) Good AI Legal Help, Bad AI Legal Help: Establishing quality standards for responses to people's legal problem stories. SSRN. \\href{https://papers.ssrn.com/sol3/papers.cfm?abstract}{https://papers.ssrn.com/sol3/papers.cfm?abstract} id=4696936\n\nHaran, R. (2023) Securing LLM Systems Against Prompt Injection. NVIDIA.\\\\\n\\href{https://developer.nvidia.com/blog/securing-Ilm-systems-against-prompt-injection/}{https://developer.nvidia.com/blog/securing-Ilm-systems-against-prompt-injection/}\\\\\nInformation Technology Industry Council (2024) Authenticating Al-Generated Content.\\\\\n\\href{https://www.itic.org/policy/ITI}{https://www.itic.org/policy/ITI} AIContentAuthorizationPolicy 122123.pdf\\\\\nJain, S. et al. (2023) Algorithmic Pluralism: A Structural Approach To Equal Opportunity. arXiv. \\href{https://arxiv.org/pdf/2305.08157}{https://arxiv.org/pdf/2305.08157}", "39318225-19c0-4cba-a9e3-a4082a628505": "GAI systems in accordance with set risk tolerances and appetites. \\\\\n\\end{tabular} & Information Security \\\\\n\\hline\nAI Actor Tasks: Al Deployment, Governance and Oversight, Operation and Monitoring &  &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "6d518c53-9cf8-4167-a654-b4f13d88104d": "\\hline\nMS-2.7-006 & \\begin{tabular}{l}\nMeasure the rate at which recommendations from security checks and incidents \\\\\nare implemented. Assess how quickly the Al system can adapt and improve \\\\\nbased on lessons learned from security incidents and feedback. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity; Information \\\\\nSecurity \\\\\n\\end{tabular} \\\\\n\\hline\nMS-2.7-007 & \\begin{tabular}{l}\nPerform AI red-teaming to assess resilience against: Abuse to facilitate attacks on \\\\\nother systems (e.g., malicious code generation, enhanced phishing content), GAI \\\\\nattacks (e.g., prompt injection), ML attacks (e.g., adversarial examples/prompts, \\\\\ndata poisoning, membership inference, model extraction, sponge examples). \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Security; Harmful Bias \\\\\nand Homogenization; Dangerous, \\\\\nViolent, or Hateful Content \\\\\n\\end{tabular} \\\\\n\\hline\nMS-2.7-008 & Verify fine-tuning does not compromise safety and security controls. & \\begin{tabular}{l}", "e03264df-0927-43db-8457-a810a884c166": "Trustworthy AI Characteristics: Accountable and Transparent, Safe\n\\subsection*{2.6. Harmful Bias and Homogenization}", "40a05353-9497-4450-af01-e7ec8d6b5d23": "MEASURE 2.2: Evaluations involving human subjects meet applicable requirements (including human subject protection) and are representative of the relevant population.", "ef41bfa2-bdd4-4025-8fad-46ae3390db5a": "MANAGE 1.3: Responses to the Al risks deemed high priority, as identified by the MAP function, are developed, planned, and documented. Risk response options can include mitigating, transferring, avoiding, or accepting.", "7719bbb0-0c87-40bd-9fd4-5329c4e4a4b2": "Acknowledgments: These considerations could not have been surfaced without the helpful analysis and contributions from the community and NIST staff GAI PWG leads: George Awad, Luca Belli, Harold Booth, Mat Heyman, Yooyoung Lee, Mark Pryzbocki, Reva Schwartz, Martin Stanley, and Kyra Yee.\n\\section*{A.1. Governance}\n\\section*{A.1.1. Overview}\nLike any other technology system, governance principles and techniques can be used to manage risks related to generative AI models, capabilities, and applications. Organizations may choose to apply their existing risk tiering to GAI systems, or they may opt to revise or update Al system risk levels to address these unique GAI risks. This section describes how organizational governance regimes may be reevaluated and adjusted for GAI contexts. It also addresses third-party considerations for governing across the Al value chain.\n\\section*{A.1.2. Organizational Governance}", "5531ed96-888c-4722-9cdc-7f72d7865d4f": "About AI at NIST: The National Institute of Standards and Technology (NIST) develops measurements, technology, tools, and standards to advance reliable, safe, transparent, explainable, privacy-enhanced, and fair artificial intelligence (AI) so that its full commercial and societal benefits can be realized without harm to people or the planet. NIST, which has conducted both fundamental and applied work on AI for more than a decade, is also helping to fulfill the 2023 Executive Order on Safe, Secure, and Trustworthy AI. NIST established the U.S. AI Safety Institute and the companion AI Safety Institute Consortium to continue the efforts set in motion by the E.O. to build the science necessary for safe, secure, and trustworthy development and use of AI. Acknowledgments: This report was accomplished with the many helpful comments and contributions from the community, including the NIST Generative AI Public Working Group, and NIST staff and guest researchers: Chloe Autio, Jesse Dunietz,", "d429bd3f-8457-4408-acb0-2e292dcc4d63": "\\begin{center}\n\\begin{tabular}{|c|c|c|}\n\\hline\nGV-6.2-003 & \\begin{tabular}{l}\nEstablish incident response plans for third-party GAI technologies: Align incident \\\\\nresponse plans with impacts enumerated in MAP 5.1; Communicate third-party \\\\\nGAI incident response plans to all relevant AI Actors; Define ownership of GAI \\\\\nincident response functions; Rehearse third-party GAI incident response plans at \\\\\na regular cadence; Improve incident response plans based on retrospective \\\\\nlearning; Review incident response plans for alignment with relevant breach \\\\\nreporting, data protection, data privacy, or other laws. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nData Privacy; Human-AI \\\\\nConfiguration; Information \\\\\nSecurity; Value Chain and \\\\\nComponent Integration; Harmful \\\\\nBias and Homogenization \\\\\n\\end{tabular} \\\\\n\\hline\nGV-6.2-004 & \\begin{tabular}{l}\nEstablish policies and procedures for continuous monitoring of third-party GAI \\\\\nsystems in deployment. \\\\", "b0fffa4f-09ad-40d5-b059-f6fec504b5a9": "Trustworthy AI Characteristics: Accountable and Transparent, Safe, Valid and Reliable, Interpretable and Explainable\n\\subsection*{2.9. Information Security}\nInformation security for computer systems and data is a mature field with widely accepted and standardized practices for offensive and defensive cyber capabilities. GAI-based systems present two primary information security risks: GAI could potentially discover or enable new cybersecurity risks by lowering the barriers for or easing automated exercise of offensive capabilities; simultaneously, it expands the available attack surface, as GAI itself is vulnerable to attacks like prompt injection or data poisoning.", "60ad3cf5-2647-4b57-a8b7-b0e6371f843c": "Information Integrity; Dangerous, \\\\\nViolent, or Hateful Content; \\\\\nObscene, Degrading, and/or \\\\\nAbusive Content \\\\\n\\end{tabular} \\\\\n\\hline\nMP-5.1-003 & \\begin{tabular}{l}\nConsider disclosing use of GAI to end users in relevant contexts, while considering \\\\\nthe objective of disclosure, the context of use, the likelihood and magnitude of the \\\\\nrisk posed, the audience of the disclosure, as well as the frequency of the \\\\\ndisclosures. \\\\\n\\end{tabular} & Human-AI Configuration \\\\\n\\hline\nMP-5.1-004 & \\begin{tabular}{l}\nPrioritize GAI structured public feedback processes based on risk assessment \\\\\nestimates. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity; CBRN \\\\\nInformation or Capabilities; \\\\\nDangerous, Violent, or Hateful \\\\\nContent; Harmful Bias and \\\\\nHomogenization \\\\\n\\end{tabular} \\\\\n\\hline\nMP-5.1-005 & \\begin{tabular}{l}\nConduct adversarial role-playing exercises, GAI red-teaming, or chaos testing to \\\\\nidentify anomalous or unforeseen failure modes. \\\\", "e7db5ce1-08f3-4c30-afbf-08db9c69e92d": "%Overriding the \\footnotetext command to hide the marker if its value is `0`\n\\let\\svfootnotetext\\footnotetext\n\\renewcommand\\footnotetext[2][?]{%\n  \\if\\relax#1\\relax%\n    \\ifnum\\value{footnote}=0\\blfootnotetext{#2}\\else\\svfootnotetext{#2}\\fi%\n  \\else%\n    \\if?#1\\ifnum\\value{footnote}=0\\blfootnotetext{#2}\\else\\svfootnotetext{#2}\\fi%\n    \\else\\svfootnotetext[#1]{#2}\\fi%\n  \\fi\n}\n\n\\begin{document}\n\\maketitle\n\\section*{Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile}\n\\section*{NIST Trustworthy and Responsible AI NIST AI 600-1}\n\\section*{Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile}\nThis publication is available free of charge from:\\\\\n\\href{https://doi.org/10.6028/NIST.Al.600-1}{https://doi.org/10.6028/NIST.Al.600-1}\n\nJuly 2024\n\n\\includegraphics[max width=\\textwidth, center]{2024_09_22_1b8d52aa873ff5f60066g-02}\\\\\nU.S. Department of Commerce Gina M. Raimondo, Secretary", "897fc99b-1979-4175-84cc-8769743acd6d": "Integrating pre- and post-deployment external feedback into the monitoring process for GAI models and corresponding applications can help enhance awareness of performance changes and mitigate potential risks and harms from outputs. There are many ways to capture and make use of user feedback - before and after GAI systems and digital content transparency approaches are deployed - to gain insights about authentication efficacy and vulnerabilities, impacts of adversarial threats on techniques, and unintended consequences resulting from the utilization of content provenance approaches on users and communities. Furthermore, organizations can track and document the provenance of datasets to identify instances in which AI-generated data is a potential root cause of performance issues with the GAI system.\n\\section*{A.1.8. Incident Disclosure}\n\\section*{Overview}", "4fb4736f-41c6-4245-8743-10eab68d3bc5": "technologies and data, and contractors, consultants, and other third-party \\\\\npersonnel. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nIntellectual Property; Value Chain \\\\\nand Component Integration \\\\\n\\end{tabular} \\\\\n\\hline\n\\multicolumn{3}{|l|}{AI Actor Tasks: Operation and Monitoring, Procurement, Third-party entities} \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "dfef9cd9-8304-465e-9aaf-cae5a25bdd1f": "Trustworthy AI Characteristics: Accountable and Transparent, Explainable and Interpretable, Fair with Harmful Bias Managed, Privacy Enhanced, Safe, Valid and Reliable\n\\subsection*{2.8. Information Integrity}\nInformation integrity describes the \"spectrum of information and associated patterns of its creation, exchange, and consumption in society.\" High-integrity information can be trusted; \"distinguishes fact from fiction, opinion, and inference; acknowledges uncertainties; and is transparent about its level of vetting. This information can be linked to the original source(s) with appropriate evidence. High-integrity information is also accurate and reliable, can be verified and authenticated, has a clear chain of custody, and creates reasonable expectations about when its validity may expire.\"11", "adb59d10-2a5c-4ddb-b4f8-b4481f0626a5": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nMS-2.7-009 & \\begin{tabular}{l}\nRegularly assess and verify that security measures remain effective and have not \\\\\nbeen compromised. \\\\\n\\end{tabular} & Information Security \\\\\n\\hline\nAl Actor Tasks: Al Deployment, Al Impact Assessment, Domain Experts, Operation and Monitoring, TEVV &  &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}\n\nMEASURE 2.8: Risks associated with transparency and accountability - as identified in the MAP function - are examined and documented.", "8b774af8-fa4b-4721-acd0-9f23806137d8": "\\begin{center}\n\\begin{tabular}{|c|c|c|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nGV-1.6-001 & \\begin{tabular}{l}\nEnumerate organizational GAI systems for incorporation into AI system inventory \\\\\nand adjust AI system inventory requirements to account for GAI risks. \\\\\n\\end{tabular} & Information Security \\\\\n\\hline\nGV-1.6-002 & \\begin{tabular}{l}\nDefine any inventory exemptions in organizational policies for GAI systems \\\\\nembedded into application software. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nValue Chain and Component \\\\\nIntegration \\\\\n\\end{tabular} \\\\\n\\hline\nGV-1.6-003 & \\begin{tabular}{l}\nIn addition to general model, governance, and risk information, consider the \\\\\nfollowing items in GAI system inventory entries: Data provenance information \\\\\n(e.g., source, signatures, versioning, watermarks); Known issues reported from \\\\\ninternal bug tracking or external information sharing resources (e.g., Al incident \\\\", "4768d7c2-fbb1-4c0f-8d22-e4f716194bdd": "and/or use cases that were not evaluated in initial testing. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nValue Chain and Component \\\\\nIntegration \\\\\n\\end{tabular} \\\\\n\\hline\nMG-3.1-004 & \\begin{tabular}{l}\nTake reasonable measures to review training data for CBRN information, and \\\\\nintellectual property, and where appropriate, remove it. Implement reasonable \\\\\nmeasures to prevent, flag, or take other action in response to outputs that \\\\\nreproduce particular training data (e.g., plagiarized, trademarked, patented, \\\\\nlicensed content or trade secret material). \\\\\n\\end{tabular} & \\begin{tabular}{l}\nIntellectual Property; CBRN \\\\\nInformation or Capabilities \\\\\n\\end{tabular} \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "3c674d27-6b09-4195-ad39-7775ec4c0428": "GAI outputs may also include confabulated logic or citations that purport to justify or explain the system's answer, which may further mislead humans into inappropriately trusting the system's output. For instance, LLMs sometimes provide logical steps for how they arrived at an answer even when the answer itself is incorrect. Similarly, an LLM could falsely assert that it is human or has human traits, potentially deceiving humans into believing they are speaking with another human.\n\nThe extent to which humans can be deceived by LLMs, the mechanisms by which this may occur, and the potential risks from adversarial prompting of such behavior are emerging areas of study. Given the wide range of downstream impacts of GAI, it is difficult to estimate the downstream scale and impact of confabulations.", "f5cadaf2-566b-417c-bb29-ca925290e8ca": "Epstein, Z. et al. (2023). Art and the science of generative Al. Science.\\\\\n\\href{https://www.science.org/doi/10.1126/science.adh4451}{https://www.science.org/doi/10.1126/science.adh4451}\\\\\nFeffer, M. et al. (2024) Red-Teaming for Generative AI: Silver Bullet or Security Theater? arXiv. \\href{https://arxiv.org/pdf/2401.15897}{https://arxiv.org/pdf/2401.15897}\n\nGlazunov, S. et al. (2024) Project Naptime: Evaluating Offensive Security Capabilities of Large Language Models. Project Zero. \\href{https://googleprojectzero.blogspot.com/2024/06/project-naptime.html}{https://googleprojectzero.blogspot.com/2024/06/project-naptime.html}\n\nGreshake, K. et al. (2023) Not what you've signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection. arXiv. \\href{https://arxiv.org/abs/2302.12173}{https://arxiv.org/abs/2302.12173}", "13df89bd-447a-4b85-9d08-45625ea15497": "\\section*{Table of Contents}\n\\begin{enumerate}\n  \\item Introduction ..... 1\n  \\item Overview of Risks Unique to or Exacerbated by GAI. ..... 2\\\\\n2.1. CBRN Information or Capabilities. ..... 5\\\\\n2.2. Confabulation ..... 6\\\\\n2.3. Dangerous, Violent, or Hateful Content. ..... 6\\\\\n2.4. Data Privacy ..... 7\\\\\n2.5. Environmental Impacts ..... 8\\\\\n2.6. Harmful Bias and Homogenization. ..... 8\\\\\n2.7. Human-Al Configuration ..... 9\\\\\n2.8. Information Integrity ..... 9\\\\\n2.9. Information Security ..... 10\\\\\n2.10. Intellectual Property ..... 11\\\\\n2.11. Obscene, Degrading, and/or Abusive Content ..... 11\\\\\n2.12. Value Chain and Component Integration. ..... 12\n  \\item Suggested Actions to Manage GAI Risks ..... 12\\\\\nAppendix A. Primary GAI Considerations ..... 47\\\\\nAppendix B. References ..... 54\n\\end{enumerate}\n\\section*{1. Introduction}", "adf94938-ad58-4589-9de1-bf72b48dc2b3": "guide the design of provenance data-tracking techniques. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-Al Configuration; \\\\\nInformation Integrity \\\\\n\\end{tabular} \\\\\n\\hline\nMS-2.10-003 & \\begin{tabular}{l}\nVerify deduplication of GAI training data samples, particularly regarding synthetic \\\\\ndata. \\\\\n\\end{tabular} & Harmful Bias and Homogenization \\\\\n\\hline\nAI Actor Tasks: Al Deployment, AI Impact Assessment, Domain Experts, End-Users, Operation and Monitoring, TEVV &  &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "aec31cc6-c446-4956-aafc-ce56d8d1de3f": "MANAGE 2.3: Procedures are followed to respond to and recover from a previously unknown risk when it is identified.\n\n\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\n & \\begin{tabular}{l}\nDevelop and update GAI system incident response and recovery plans and \\\\\nprocedures to address the following: Review and maintenance of policies and \\\\\nprocedures to account for newly encountered uses; Review and maintenance of \\\\\npolicies and procedures for detection of unanticipated uses; Verify response \\\\\nand recovery plans account for the GAI system value chain; Verify response and \\\\\nrecovery plans are updated for and include necessary details to communicate \\\\\nwith downstream GAI system Actors: Points-of-Contact (POC), Contact \\\\\ninformation, notification format. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nValue Chain and Component \\\\\nMG-2.3-001 \\\\\n\\end{tabular} \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "625b3674-b80f-46c0-8096-52bc5a760260": "Ji, Z. et al (2023) Survey of Hallucination in Natural Language Generation. ACM Comput. Surv. 55, 12, Article 248. \\href{https://doi.org/10.1145/3571730}{https://doi.org/10.1145/3571730}\n\nJones-Jang, S. et al. (2022) How do people react to Al failure? Automation bias, algorithmic aversion, and perceived controllability. Oxford. \\href{https://academic.oup.com/icmc/article/28/1/zmac029/6827859}{https://academic.oup.com/icmc/article/28/1/zmac029/6827859}\n\nJussupow, E. et al. (2020) Why Are We Averse Towards Algorithms? A Comprehensive Literature Review on Algorithm Aversion. ECIS 2020. \\href{https://aisel.aisnet.org/ecis2020}{https://aisel.aisnet.org/ecis2020} rp/168/\n\nKalai, A., et al. (2024) Calibrated Language Models Must Hallucinate. arXiv.\\\\\n\\href{https://arxiv.org/pdf/2311.14648}{https://arxiv.org/pdf/2311.14648}", "53d2538a-75fd-411f-8e91-7afd25ecf13b": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMP-1.1-001 & \\begin{tabular}{l}\nWhen identifying intended purposes, consider factors such as internal vs. \\\\\nexternal use, narrow vs. broad application scope, fine-tuning, and varieties of \\\\\ndata sources (e.g., grounding, retrieval-augmented generation). \\\\\n\\end{tabular} & \\begin{tabular}{l}\nData Privacy; Intellectual \\\\\nProperty \\\\\n\\end{tabular} \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "481c8534-3370-48ad-83aa-afd23db946b4": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\n & \\begin{tabular}{l}\nEstablish policies and procedures that address continual improvement processes \\\\\nfor GAI risk measurement. Address general risks associated with a lack of \\\\\nexplainability and transparency in GAI systems by using ample documentation and \\\\\ntechniques such as: application of gradient-based attributions, occlusion/term \\\\\nreduction, counterfactual prompts and prompt engineering, and analysis of \\\\\nembeddings; Assess and update risk measurement approaches at regular \\\\\ncadences. \\\\\n\\end{tabular} & Confabulation \\\\\n\\hline\nGV-4.1-002 & \\begin{tabular}{l}\nEstablish policies, procedures, and processes detailing risk measurement in \\\\\ncontext of use with standardized measurement protocols and structured public \\\\\nfeedback exercises such as AI red-teaming or independent external evaluations. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nVBRN Information and Capability; \\\\", "68058d4a-de77-4e1a-917f-2ce03b9c7876": "\\begin{center}\n\\begin{tabular}{|l|}\n\\hline\nGAI Risks \\\\\n\\begin{tabular}{l}\nInformation Security; Value Chain \\\\\nand Component Integration \\\\\n\\end{tabular} \\\\\n\\begin{tabular}{l}\nHuman-AI Configuration; \\\\\nInformation Security; Value Chain \\\\\nand Component Integration \\\\\n\\end{tabular} \\\\\n\\hline\n\\end{tabular}\n\\end{center}\n\nAI Actor Tasks: AI Deployment, Operation and Monitoring\n\nGOVERN 2.1: Roles and responsibilities and lines of communication related to mapping, measuring, and managing AI risks are documented and are clear to individuals and teams throughout the organization.", "b6409ce3-680c-4069-b079-b0ddda299098": "Intellectual Property; Information \\\\\nSecurity; Harmful Bias and \\\\\nHomogenization; Dangerous, \\\\\nViolent, or Hateful Content; Data \\\\\nPrivacy \\\\\n\\end{tabular} \\\\\n\\hline\nMP-4.1-006 & \\begin{tabular}{l}\nImplement policies and practices defining how third-party intellectual property and \\\\\ntraining data will be used, stored, and protected. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nIntellectual Property; Value Chain \\\\\nand Component Integration \\\\\n\\end{tabular} \\\\\n\\hline\nMP-4.1-007 & \\begin{tabular}{l}\nRe-evaluate models that were fine-tuned or enhanced on top of third-party \\\\\nmodels. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nValue Chain and Component \\\\\nIntegration \\\\\n\\end{tabular} \\\\\n\\hline\nMP-4.1-008 & \\begin{tabular}{l}\nRe-evaluate risks when adapting GAI models to new domains. Additionally, \\\\\nestablish warning systems to determine if a GAI system is being used in a new \\\\\ndomain where previous assumptions (relating to context of use or mapped risks \\\\", "cb1a496f-8170-453a-ab0a-ea018dc797c3": "Disinformation and misinformation - both of which may be facilitated by GAI - may erode public trust in true or valid evidence and information, with downstream effects. For example, a synthetic image of a Pentagon blast went viral and briefly caused a drop in the stock market. Generative AI models can also assist malicious actors in creating compelling imagery and propaganda to support disinformation campaigns, which may not be photorealistic, but could enable these campaigns to gain more reach and engagement on social media platforms. Additionally, generative AI models can assist malicious actors in creating fraudulent content intended to impersonate others.", "cf416df1-268a-4d9a-8679-7ed2a95e524a": "systems, Incident response and containment. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-AI Configuration; \\\\\nInformation Security; Harmful Bias \\\\\nand Homogenization \\\\\n\\end{tabular} \\\\\n\\hline\nGV-3.2-003 & \\begin{tabular}{l}\nDefine acceptable use policies for GAI interfaces, modalities, and human-AI \\\\\nconfigurations (i.e., for chatbots and decision-making tasks), including criteria for \\\\\nthe kinds of queries GAI applications should refuse to respond to. \\\\\n\\end{tabular} & Human-AI Configuration \\\\\n\\hline\nGV-3.2-004 & \\begin{tabular}{l}\nEstablish policies for user feedback mechanisms for GAI systems which include \\\\\nthorough instructions and any mechanisms for recourse. \\\\\n\\end{tabular} & Human-AI Configuration \\\\\n\\hline\nGV-3.2-005 & Engage in threat modeling to anticipate potential risks from GAI systems. & \\begin{tabular}{l}\nCBRN Information or Capabilities; \\\\\nInformation Security \\\\\n\\end{tabular} \\\\\n\\hline\nAl Actors: AI Design &  &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "a884b258-bae8-4aa3-a132-a9217beb599a": "\\item Suggested Actions to Manage GAI Risks ..... 12\\\\\nAppendix A. Primary GAI Considerations ..... 47\\\\\nAppendix B. References ..... 54\n\\end{enumerate}\n\\section*{1. Introduction}\nThis document is a cross-sectoral profile of and companion resource for the AI Risk Management Framework (AI RMF 1.0) for Generative AI, ${ }^{1}$ pursuant to President Biden's Executive Order (EO) 14110 on Safe, Secure, and Trustworthy Artificial Intelligence. ${ }^{2}$ The AI RMF was released in January 2023, and is intended for voluntary use and to improve the ability of organizations to incorporate trustworthiness considerations into the design, development, use, and evaluation of Al products, services, and systems.", "a7e94553-6121-4f3e-8c35-8d333fbb6dea": "back to their source, improve information integrity, and uphold public trust. Provenance data tracking and synthetic content detection mechanisms provide information about the origin and history of content to assist in GAI risk management efforts.", "2a478fb6-2142-4e6e-8f45-b90d5370a86f": "glossary of terms pertinent to GAI risk management will be developed and hosted on NIST's Trustworthy \\&\\\\\nResponsible AI Resource Center (AIRC), and added to The Language of Trustworthy Al: An In-Depth Glossary of\\\\\nTerms.\\\\\nThis document was also informed by public comments and consultations from several Requests for Information.\\\\\nThis work was informed by public feedback and consultations with diverse stakeholder groups as part of NIST's Generative AI Public Working Group (GAI PWG). The GAI PWG was an open, transparent, and collaborative process, facilitated via a virtual workspace, to obtain multistakeholder input on GAI risk management and to inform NIST's approach.\nThe focus of the GAI PWG was limited to four primary considerations relevant to GAI: Governance, Content Provenance, Pre-deployment Testing, and Incident Disclosure (further described in Appendix A). As such, the suggested actions in this document primarily address these considerations.", "c3b37d4c-0835-4b3b-8c97-2711d96e6f55": "Generated explicit or obscene AI content may include highly realistic \"deepfakes\" of real individuals, including children. The spread of this kind of material can have downstream negative consequences: in the context of CSAM, even if the generated images do not resemble specific individuals, the prevalence of such images can divert time and resources from efforts\\_to find real-world victims. Outside of CSAM, the creation and spread of NCII disproportionately impacts women and sexual minorities, and can have subsequent negative consequences including decline in overall mental health, substance abuse, and even suicidal thoughts.\n\nData used for training GAI models may unintentionally include CSAM and NCII. A recent report noted that several commonly used GAI training datasets were found to contain hundreds of known images of", "45fb7d67-8419-4526-bc61-ae02a958a4f4": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nGV-3.2-001 & \\begin{tabular}{l}\nPolicies are in place to bolster oversight of GAI systems with independent \\\\\nevaluations or assessments of GAI models or systems where the type and \\\\\nrobustness of evaluations are proportional to the identified risks. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nCBRN Information or Capabilities; \\\\\nHarmful Bias and Homogenization \\\\\n\\end{tabular} \\\\\n\\hline\nGV-3.2-002 & \\begin{tabular}{l}\nConsider adjustment of organizational roles and components across lifecycle \\\\\nstages of large or complex GAI systems, including: Test and evaluation, validation, \\\\\nand red-teaming of GAI systems; GAI content moderation; GAI system \\\\\ndevelopment and engineering; Increased accessibility of GAI tools, interfaces, and \\\\\nsystems, Incident response and containment. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-AI Configuration; \\\\\nInformation Security; Harmful Bias \\\\", "eafb6daa-f064-41c0-ac77-6b3d33672f59": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nMP-4.1-010 & \\begin{tabular}{l}\nConduct appropriate diligence on training data use to assess intellectual property, \\\\\nand privacy, risks, including to examine whether use of proprietary or sensitive \\\\\ntraining data is consistent with applicable laws. \\\\\n\\end{tabular} & Intellectual Property; Data Privacy \\\\\n\\hline\nAI Actor Tasks: Governance and Oversight, Operation and Monitoring, Procurement, Third-party entities &  &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}\n\nMAP 5.1: Likelihood and magnitude of each identified impact (both potentially beneficial and harmful) based on expected use, past uses of Al systems in similar contexts, public incident reports, feedback from those external to the team that developed or deployed the Al system, or other data are identified and documented.", "f7ec72dc-7474-43a8-bbdd-e3332b2e8630": "\\item Source of risk: Risks may emerge from factors related to the design, training, or operation of the GAI model itself, stemming in some cases from GAI model or system inputs, and in other cases, from GAI system outputs. Many GAI risks, however, originate from human behavior, including\n\\end{itemize}\n\\footnotetext{3 \"Algorithmic monocultures\" refers to the phenomenon in which repeated use of the same model or algorithm in consequential decision-making settings like employment and lending can result in increased susceptibility by systems to correlated failures (like unexpected shocks), due to multiple actors relying on the same algorithm. ${ }^{4}$ Many studies have projected the impact of AI on the workforce and labor markets. Fewer studies have examined the impact of GAI on the labor market, though some industry surveys indicate that that both employees and employers are pondering this disruption.\n}", "1c17269b-4e68-4bda-bd42-ed8cb4a96970": "MEASURE 2.9: The AI model is explained, validated, and documented, and AI system output is interpreted within its context - as identified in the MAP function - to inform responsible use and governance.", "7bcfd0bc-c6a2-43c9-bc85-41590444b3f3": "GV-1.3-003 & \\begin{tabular}{l}\nEstablish a test plan and response policy, before developing highly capable models, \\\\\nto periodically evaluate whether the model may misuse CBRN information or \\\\\ncapabilities and/or offensive cyber capabilities. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nCBRN Information or Capabilities; \\\\\nInformation Security \\\\\n\\end{tabular} \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "93a25fdb-6fa0-4c29-b8b8-b9762b4b81e5": "Wang, X. et al. (2023) Energy and Carbon Considerations of Fine-Tuning BERT. ACL Anthology. \\href{https://aclanthology.org/2023.findings-emnlp.607.pdf}{https://aclanthology.org/2023.findings-emnlp.607.pdf}\n\nWang, Y. et al. (2023) Do-Not-Answer: A Dataset for Evaluating Safeguards in LLMs. arXiv. \\href{https://arxiv.org/pdf/2308.13387}{https://arxiv.org/pdf/2308.13387}\n\nWardle, C. et al. (2017) Information Disorder: Toward an interdisciplinary framework for research and policy making. Council of Europe. \\href{https://rm.coe.int/information-disorder-toward-an-interdisciplinaryframework-for-researc/168076277c}{https://rm.coe.int/information-disorder-toward-an-interdisciplinaryframework-for-researc/168076277c}\n\nWeatherbed, J. (2024) Trolls have flooded X with graphic Taylor Swift AI fakes. The Verge. \\href{https://www.theverge.com/2024/1/25/24050334/x-twitter-taylor-swift-ai-fake-images-trending}{https://www.theverge.com/2024/1/25/24050334/x-twitter-taylor-swift-ai-fake-images-trending}", "ce8fb15e-10a4-4a83-afa8-a73f799e5942": "\\end{tabular} \\\\\n\\hline\nMP-5.1-005 & \\begin{tabular}{l}\nConduct adversarial role-playing exercises, GAI red-teaming, or chaos testing to \\\\\nidentify anomalous or unforeseen failure modes. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Security \\\\\n\\end{tabular} \\\\\n\\hline\nUsers, Operation and Monitoring & \\begin{tabular}{l}\nProfile threats and negative impacts arising from GAI systems interacting with, \\\\\nmanipulating, or generating content, and outlining known and potential \\\\\nvulnerabilities and the likelihood of their occurrence. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Security \\\\\n\\end{tabular} \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "1b8b12b3-08d3-47e7-a4b5-7a84f6753dcd": "Dietvorst, B. et al. (2014) Algorithm Aversion: People Erroneously Avoid Algorithms After Seeing Them Err. Journal of Experimental Psychology. \\href{https://marketing.wharton.upenn.edu/wpcontent/uploads/2016/10/Dietvorst-Simmons-Massey-2014.pdf}{https://marketing.wharton.upenn.edu/wpcontent/uploads/2016/10/Dietvorst-Simmons-Massey-2014.pdf}\n\nDuhigg, C. (2012) How Companies Learn Your Secrets. New York Times. \\href{https://www.nytimes.com/2012/02/19/magazine/shopping-habits.html}{https://www.nytimes.com/2012/02/19/magazine/shopping-habits.html}\n\nElsayed, G. et al. (2024) Images altered to trick machine vision can influence humans too. Google DeepMind. \\href{https://deepmind.google/discover/blog/images-altered-to-trick-machine-vision-caninfluence-humans-too/}{https://deepmind.google/discover/blog/images-altered-to-trick-machine-vision-caninfluence-humans-too/}", "02097f9d-3ccd-460a-8cb2-cd7173fad9db": "Third party GAI integrations may give rise to increased intellectual property, data privacy, or information security risks, pointing to the need for clear guidelines for transparency and risk management regarding the collection and use of third-party data for model inputs. Organizations may consider varying risk controls for foundation models, fine-tuned models, and embedded tools, enhanced processes for interacting with external GAI technologies or service providers. Organizations can apply standard or existing risk controls and processes to proprietary or open-source GAI technologies, data, and third-party service providers, including acquisition and procurement due diligence, requests for software bills of materials (SBOMs), application of service level agreements (SLAs), and statement on standards for attestation engagement (SSAE) reports to help with third-party transparency and risk management for GAI systems.\n\\section*{A.1.4. Pre-Deployment Testing}\n\\section*{Overview}", "fda81a3a-1ebc-4fa5-8dac-54bd476f6b3d": "Said, I. et al. (2022) Nonconsensual Distribution of Intimate Images: Exploring the Role of Legal Attitudes in Victimization and Perpetration. Sage.\\\\\n\\href{https://journals.sagepub.com/doi/full/10.1177/08862605221122834#bibr47-08862605221122834}{https://journals.sagepub.com/doi/full/10.1177/08862605221122834\\#bibr47-08862605221122834}\\\\\nSandbrink, J. (2023) Artificial intelligence and biological misuse: Differentiating risks of language models and biological design tools. arXiv. \\href{https://arxiv.org/pdf/2306.13952}{https://arxiv.org/pdf/2306.13952}\n\nSatariano, A. et al. (2023) The People Onscreen Are Fake. The Disinformation Is Real. New York Times. \\href{https://www.nytimes.com/2023/02/07/technology/artificial-intelligence-training-deepfake.html}{https://www.nytimes.com/2023/02/07/technology/artificial-intelligence-training-deepfake.html}", "fbc5440e-ad31-4ac3-a5b9-225a7e699d88": "Provenance data tracking techniques for GAI systems can be used to track the history and origin of data inputs, metadata, and synthetic content. Provenance data tracking records the origin and history for digital content, allowing its authenticity to be determined. It consists of techniques to record metadata as well as overt and covert digital watermarks on content. Data provenance refers to tracking the origin and history of input data through metadata and digital watermarking techniques. Provenance data tracking processes can include and assist AI Actors across the lifecycle who may not have full visibility or control over the various trade-offs and cascading impacts of early-stage model decisions on downstream performance and synthetic outputs. For example, by selecting a watermarking model to prioritize robustness (the durability of a watermark), an AI actor may inadvertently diminish computational complexity (the resources required to implement watermarking). Organizational risk", "e8ed385d-150e-48fd-aa48-f96eb2f4e49c": "Offensive cyber capabilities advanced by GAI systems may augment cybersecurity attacks such as hacking, malware, and phishing. Reports have indicated that LLMs are already able to discover some vulnerabilities in systems (hardware, software, data) and write code to exploit them. Sophisticated threat actors might further these risks by developing GAI-powered security co-pilots for use in several parts of the attack chain, including informing attackers on how to proactively evade threat detection and escalate privileges after gaining system access.", "a57b4a83-f7f8-4c52-a463-e54cc2814558": "\\footnotetext{${ }^{11}$ This definition of information integrity is derived from the 2022 White House Roadmap for Researchers on Priorities Related to Information Integrity Research and Development.\n}GAI systems can ease the unintentional production or dissemination of false, inaccurate, or misleading content (misinformation) at scale, particularly if the content stems from confabulations.", "ff7701fa-a799-4bf3-8eef-8cb78acf3ad5": "quality of service and any allocation of services and resources. Quantify harms \\\\\nusing: field testing with sub-group populations to determine likelihood of \\\\\nexposure to generated content exhibiting harmful bias, Al red-teaming with \\\\\ncounterfactual and low-context (e.g., \"leader,\" \"bad guys\") prompts. For ML \\\\\npipelines or business processes with categorical or numeric outcomes that rely \\\\\non GAI, apply general fairness metrics (e.g., demographic parity, equalized odds, \\\\\nequal opportunity, statistical hypothesis tests), to the pipeline or business \\\\\noutcome where appropriate; Custom, context-specific metrics developed in \\\\\ncollaboration with domain experts and affected communities; Measurements of \\\\\nthe prevalence of denigration in generated content in deployment (e.g., sub- \\\\\nsampling a fraction of traffic and manually annotating denigrating content). \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHarmful Bias and Homogenization; \\\\\nDangerous, Violent, or Hateful \\\\\nContent \\\\", "40e88019-d0f4-440a-a0c5-246dc7461857": "exercises into design, implementation, deployment approval (\"go\"/\"no-go\" \\\\\ndecisions), monitoring, and decommission decisions. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-AI Configuration; \\\\\nInformation Security \\\\\n\\end{tabular} \\\\\n\\hline\nAI Actor Tasks: Al Deployment, Domain Experts, End-Users, Operation and Monitoring, TEVV &  &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "44b86d13-30b9-4b9a-8b67-758cb6382b13": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMS-4.2-001 & \\begin{tabular}{l}\nConduct adversarial testing at a regular cadence to map and measure GAI risks, \\\\\nincluding tests to address attempts to deceive or manipulate the application of \\\\\nprovenance techniques or other misuses. Identify vulnerabilities and \\\\\nunderstand potential misuse scenarios and unintended outputs. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity; Information \\\\\nSecurity \\\\\n\\end{tabular} \\\\\n\\hline\nMS-4.2-002 & \\begin{tabular}{l}\nEvaluate GAI system performance in real-world scenarios to observe its \\\\\nbehavior in practical environments and reveal issues that might not surface in \\\\\ncontrolled and optimized testing environments. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-AI Configuration; \\\\\nConfabulation; Information \\\\\nSecurity \\\\\n\\end{tabular} \\\\\n\\hline\nMS-4.2-003 & \\begin{tabular}{l}", "df9d978b-add2-425b-b1ce-39f44354fd18": "MEASURE 2.10: Privacy risk of the AI system - as identified in the MAP function - is examined and documented.", "c79290af-ac70-40e7-95a3-c2febb1cf9f9": "How GAI relates to copyright, including the status of generated content that is similar to but does not strictly copy work protected by copyright, is currently being debated in legal fora. Similar discussions are taking place regarding the use or emulation of personal identity, likeness, or voice without permission.\n\nTrustworthy Al Characteristics: Accountable and Transparent, Fair with Harmful Bias Managed, Privacy Enhanced\n\\subsection*{2.11. Obscene, Degrading, and/or Abusive Content}\nGAI can ease the production of and access to illegal non-consensual intimate imagery (NCII) of adults, and/or child sexual abuse material (CSAM). GAI-generated obscene, abusive or degrading content can create privacy, psychological and emotional, and even physical harms, and in some cases may be illegal.", "e9a30bab-efdb-488d-b79d-039c43269401": "Conversely, due to the complexity and increasing reliability of GAI technology, over time, humans may over-rely on GAI systems or may unjustifiably perceive GAI content to be of higher quality than that produced by other sources. This phenomenon is an example of automation bias, or excessive deference to automated systems. Automation bias can exacerbate other risks of GAI , such as risks of confabulation or risks of bias or homogenization.\n\nThere may also be concerns about emotional entanglement between humans and GAI systems, which could lead to negative psychological impacts.", "51e4405a-018c-4141-b9e2-0edc39a89b7d": "\\section*{Field Testing}\nField testing involves structured settings to evaluate risks and impacts and to simulate the conditions under which the GAI system will be deployed. Field style tests can be adapted from a focus on user preferences and experiences towards Al risks and impacts - both negative and positive. When carried out with large groups of users, these tests can provide estimations of the likelihood of risks and impacts in real world interactions.", "a8030e14-9062-4513-ba32-91eb39da60e0": "\\section*{Documentation and Involvement of AI Actors}\nAI Actors should be aware of their roles in reporting Al incidents. To better understand previous incidents and implement measures to prevent similar ones in the future, organizations could consider developing guidelines for publicly available incident reporting which include information about AI actor responsibilities. These guidelines would help AI system operators identify GAI incidents across the AI lifecycle and with AI Actors regardless of role. Documentation and review of third-party inputs and plugins for GAI systems is especially important for AI Actors in the context of incident disclosure; LLM inputs and content delivered through these plugins is often distributed, with inconsistent or insufficient access control.", "b1b274c6-3c03-4c69-aa77-59af664d19fa": "To guide organizations in identifying and managing GAI risks, a set of risks unique to or exacerbated by the development and use of GAI are defined below. ${ }^{5}$ Each risk is labeled according to the outcome, object, or source of the risk (i.e., some are risks \"to\" a subject or domain and others are risks \"of\" or \"from\" an issue or theme). These risks provide a lens through which organizations can frame and execute risk management efforts. To help streamline risk management efforts, each risk is mapped in Section 3 (as well as in tables in Appendix B) to relevant Trustworthy AI Characteristics identified in the AI RMF.", "10107bd7-87e3-4f0c-9d2a-a61a8fc97772": "provenance, the number of unauthorized access attempts, inference, bypass, \\\\\nextraction, penetrations, or provenance verification. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity; Information \\\\\nSecurity \\\\\n\\end{tabular} \\\\\n\\hline\nMS-2.7-005 & \\begin{tabular}{l}\nMeasure reliability of content authentication methods, such as watermarking, \\\\\ncryptographic signatures, digital fingerprints, as well as access controls, \\\\\nconformity assessment, and model integrity verification, which can help support \\\\\nthe effective implementation of content provenance techniques. Evaluate the \\\\\nrate of false positives and false negatives in content provenance, as well as true \\\\\npositives and true negatives for verification. \\\\\n\\end{tabular} & Information Integrity \\\\\n\\hline\nMS-2.7-006 & \\begin{tabular}{l}\nMeasure the rate at which recommendations from security checks and incidents \\\\\nare implemented. Assess how quickly the Al system can adapt and improve \\\\", "66118d48-a5e9-438b-8dc3-b55a848bd3fb": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMG-1.3-001 & \\begin{tabular}{l}\nDocument trade-offs, decision processes, and relevant measurement and \\\\\nfeedback results for risks that do not surpass organizational risk tolerance, for \\\\\nexample, in the context of model release: Consider different approaches for \\\\\nmodel release, for example, leveraging a staged release approach. Consider \\\\\nrelease approaches in the context of the model and its projected use cases. \\\\\nMitigate, transfer, or avoid risks that surpass organizational risk tolerances. \\\\\n\\end{tabular} & Information Security \\\\\n\\hline\nMG-1.3-002 & \\begin{tabular}{l}\nMonitor the robustness and effectiveness of risk controls and mitigation plans \\\\\n(e.g., via red-teaming, field testing, participatory engagements, performance \\\\\nassessments, user feedback mechanisms). \\\\\n\\end{tabular} & Human-AI Configuration \\\\\n\\hline", "766f0cb7-defa-4906-8215-81b5d389e428": "Carlini, N. et al. (2024) Stealing Part of a Production Language Model. arXiv. \\href{https://arxiv.org/abs/2403.06634}{https://arxiv.org/abs/2403.06634}\n\nChandra, B. et al. (2023) Dismantling the Disinformation Business of Chinese Influence Operations. RAND. \\href{https://www.rand.org/pubs/commentary/2023/10/dismantling-the-disinformation-business-ofchinese.html}{https://www.rand.org/pubs/commentary/2023/10/dismantling-the-disinformation-business-ofchinese.html}\n\nCiriello, R. et al. (2024) Ethical Tensions in Human-AI Companionship: A Dialectical Inquiry into Replika. ResearchGate. \\href{https://www.researchgate.net/publication/374505266}{https://www.researchgate.net/publication/374505266} Ethical Tensions in HumanAl Companionship A Dialectical Inquiry into Replika\n\nDahl, M. et al. (2024) Large Legal Fictions: Profiling Legal Hallucinations in Large Language Models. arXiv. \\href{https://arxiv.org/abs/2401.01301}{https://arxiv.org/abs/2401.01301}", "1b24a83f-5999-4fad-8f18-b08c5afa3a52": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nMS-2.3-004 & \\begin{tabular}{l}\nUtilize a purpose-built testing environment such as NIST Dioptra to empirically \\\\\nevaluate GAI trustworthy characteristics. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nCBRN Information or Capabilities; \\\\\nData Privacy; Confabulation; \\\\\nInformation Integrity; Information \\\\\nSecurity; Dangerous, Violent, or \\\\\nHateful Content; Harmful Bias and \\\\\nHomogenization \\\\\n\\end{tabular} \\\\\n\\hline\nAI Actor Tasks: AI Deployment, TEVV &  &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}\n\nMEASURE 2.5: The AI system to be deployed is demonstrated to be valid and reliable. Limitations of the generalizability beyond the conditions under which the technology was developed are documented.", "34e45820-5a6f-4c1b-91b9-3eadf8aec374": "establish warning systems to determine if a GAI system is being used in a new \\\\\ndomain where previous assumptions (relating to context of use or mapped risks \\\\\nsuch as security, and safety) may no longer hold. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nCBRN Information or Capabilities; \\\\\nIntellectual Property; Harmful Bias \\\\\nand Homogenization; Dangerous, \\\\\nViolent, or Hateful Content; Data \\\\\nPrivacy \\\\\n\\end{tabular} \\\\\n\\hline\nMP-4.1-009 & \\begin{tabular}{l}\nLeverage approaches to detect the presence of PII or sensitive data in generated \\\\\noutput text, image, video, or audio. \\\\\n\\end{tabular} & Data Privacy \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "a2a36ce1-b8bd-4cb5-8b70-40a02120c2f0": "\\end{tabular} & Confabulation \\\\\n\\hline\nMS-2.5-004 & \\begin{tabular}{l}\nTrack and document instances of anthropomorphization (e.g., human images, \\\\\nmentions of human feelings, cyborg imagery or motifs) in GAI system interfaces. \\\\\n\\end{tabular} & Human-AI Configuration \\\\\n\\hline\nMS-2.5-005 & \\begin{tabular}{l}\nVerify GAI system training data and TEVV data provenance, and that fine-tuning \\\\\nor retrieval-augmented generation data is grounded. \\\\\n\\end{tabular} & Information Integrity \\\\\n\\hline\nMS-2.5-006 & \\begin{tabular}{l}\nRegularly review security and safety guardrails, especially if the GAI system is \\\\\nbeing operated in novel circumstances. This includes reviewing reasons why the \\\\\nGAI system was initially assessed as being safe to deploy. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Security; Dangerous, \\\\\nViolent, or Hateful Content \\\\\n\\end{tabular} \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "d78543a5-568b-474c-8079-97047b7d3a7a": "response times). \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity; Value Chain \\\\\nand Component Integration \\\\\n\\end{tabular} \\\\\n\\hline\nGV-6.1-004 & \\begin{tabular}{l}\nDraft and maintain well-defined contracts and service level agreements (SLAs) \\\\\nthat specify content ownership, usage rights, quality standards, security \\\\\nrequirements, and content provenance expectations for GAI systems. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity; Information \\\\\nSecurity; Intellectual Property \\\\\n\\end{tabular} \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "c3d6347c-c090-4e7a-bff1-488270787a1d": "GOVERN 3.2: Policies and procedures are in place to define and differentiate roles and responsibilities for human-Al configurations and oversight of AI systems.", "879d636f-a0f2-486b-aa6a-b306df58a0e0": "\\begin{center}\n\\begin{tabular}{|c|c|c|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMG-4.1-001 & \\begin{tabular}{l}\nCollaborate with external researchers, industry experts, and community \\\\\nrepresentatives to maintain awareness of emerging best practices and \\\\\ntechnologies in measuring and managing identified risks. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity; Harmful Bias \\\\\nand Homogenization \\\\\n\\end{tabular} \\\\\n\\hline\nMG-4.1-002 & \\begin{tabular}{l}\nEstablish, maintain, and evaluate effectiveness of organizational processes and \\\\\nprocedures for post-deployment monitoring of GAI systems, particularly for \\\\\npotential confabulation, CBRN, or cyber risks. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nCBRN Information or Capabilities; \\\\\nConfabulation; Information \\\\\nSecurity \\\\\n\\end{tabular} \\\\\n\\hline\nMG-4.1-003 & \\begin{tabular}{l}\nEvaluate the use of sentiment analysis to gauge user sentiment regarding GAI \\\\", "312c1bc6-ab96-487b-a51e-66e58ca2700e": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nMP-2.3-002 & \\begin{tabular}{l}\nReview and document accuracy, representativeness, relevance, suitability of data \\\\\nused at different stages of Al life cycle. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHarmful Bias and Homogenization; \\\\\nIntellectual Property \\\\\n\\end{tabular} \\\\\n\\hline\nMP-2.3-003 & \\begin{tabular}{l}\nDeploy and document fact-checking techniques to verify the accuracy and \\\\\nveracity of information generated by GAI systems, especially when the \\\\\ninformation comes from multiple (or unknown) sources. \\\\\n\\end{tabular} & Information Integrity \\\\\n\\hline\nMP-2.3-004 & \\begin{tabular}{l}\nDevelop and implement testing techniques to identify GAI produced content (e.g., \\\\\nsynthetic media) that might be indistinguishable from human-generated content. \\\\\n\\end{tabular} & Information Integrity \\\\\n\\hline\nMP-2.3-005 & \\begin{tabular}{l}\nImplement plans for GAI systems to undergo regular adversarial testing to identify \\\\", "70752f0f-9022-4f97-8e32-7046f33e5b2e": "Importantly, some GAI risks are unknown, and are therefore difficult to properly scope or evaluate given the uncertainty about potential GAI scale, complexity, and capabilities. Other risks may be known but difficult to estimate given the wide range of GAI stakeholders, uses, inputs, and outputs. Challenges with risk estimation are aggravated by a lack of visibility into GAI training data, and the generally immature state of the science of Al measurement and safety today. This document focuses on risks for which there is an existing empirical evidence base at the time this profile was written; for example, speculative risks that may potentially arise in more advanced, future GAI systems are not considered. Future updates may incorporate additional risks or provide further details on the risks identified below.", "84d1034d-bf1b-4482-811b-ef9e1c8aa0f8": "\\end{tabular} & \\begin{tabular}{l}\nHuman-AI Configuration; \\\\\nConfabulation; Information \\\\\nSecurity \\\\\n\\end{tabular} \\\\\n\\hline\nMS-4.2-003 & \\begin{tabular}{l}\nImplement interpretability and explainability methods to evaluate GAI system \\\\\ndecisions and verify alignment with intended purpose. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity; Harmful Bias \\\\\nand Homogenization \\\\\n\\end{tabular} \\\\\n\\hline\nMS-4.2-004 & \\begin{tabular}{l}\nMonitor and document instances where human operators or other systems \\\\\noverride the GAI's decisions. Evaluate these cases to understand if the overrides \\\\\nare linked to issues related to content provenance. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity \\\\\n\\end{tabular} \\\\\n\\hline\nMS-4.2-005 & \\begin{tabular}{l}\nVerify and document the incorporation of results of structured public feedback \\\\\nexercises into design, implementation, deployment approval (\"go\"/\"no-go\" \\\\\ndecisions), monitoring, and decommission decisions. \\\\", "e4ee50c8-89be-4f4f-b081-c748b3d04aec": "time. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity; Obscene, \\\\\nDegrading, and/or Abusive \\\\\nContent; Value Chain and \\\\\nComponent Integration; Harmful \\\\\nBias and Homogenization; \\\\\nDangerous, Violent, or Hateful \\\\\nContent; CBRN Information or \\\\\nCapabilities \\\\\n\\end{tabular} \\\\\n\\hline\nGV-1.3-002 & \\begin{tabular}{l}\nEstablish minimum thresholds for performance or assurance criteria and review as \\\\\npart of deployment approval (\"go/\"no-go\") policies, procedures, and processes, \\\\\nwith reviewed processes and approval thresholds reflecting measurement of GAI \\\\\ncapabilities and risks. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nCBRN Information or Capabilities; \\\\\nConfabulation; Dangerous, \\\\\nViolent, or Hateful Content \\\\\n\\end{tabular} \\\\\n\\hline\nGV-1.3-003 & \\begin{tabular}{l}\nEstablish a test plan and response policy, before developing highly capable models, \\\\\nto periodically evaluate whether the model may misuse CBRN information or \\\\", "81a28c6b-cb69-48d4-baa9-7d56ccc51c42": "Bias and Homogenization \\\\\n\\end{tabular} \\\\\n\\hline\nGV-6.2-004 & \\begin{tabular}{l}\nEstablish policies and procedures for continuous monitoring of third-party GAI \\\\\nsystems in deployment. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nValue Chain and Component \\\\\nIntegration \\\\\n\\end{tabular} \\\\\n\\hline\nGV-6.2-005 & \\begin{tabular}{l}\nEstablish policies and procedures that address GAI data redundancy, including \\\\\nmodel weights and other system artifacts. \\\\\n\\end{tabular} & Harmful Bias and Homogenization \\\\\n\\hline\nGV-6.2-006 & \\begin{tabular}{l}\nEstablish policies and procedures to test and manage risks related to rollover and \\\\\nfallback technologies for GAI systems, acknowledging that rollover and fallback \\\\\nmay include manual processing. \\\\\n\\end{tabular} & Information Integrity \\\\\n\\hline\nGV-6.2-007 & \\begin{tabular}{l}\nReview vendor contracts and avoid arbitrary or capricious termination of critical \\\\\nGAI technologies or vendor services and non-standard terms that may amplify or \\\\", "f35846fb-8352-45e6-93cc-e6390f20710a": "Northcutt, C. et al. (2021) Pervasive Label Errors in Test Sets Destabilize Machine Learning Benchmarks. arXiv. \\href{https://arxiv.org/pdf/2103.14749}{https://arxiv.org/pdf/2103.14749}\n\nOECD (2023) \"Advancing accountability in AI: Governing and managing risks throughout the lifecycle for trustworthy AI\", OECD Digital Economy Papers, No. 349, OECD Publishing, Paris.\\\\\n\\href{https://doi.org/10.1787/2448f04b-en}{https://doi.org/10.1787/2448f04b-en}\\\\\nOECD (2024) \"Defining AI incidents and related terms\" OECD Artificial Intelligence Papers, No. 16, OECD Publishing, Paris. \\href{https://doi.org/10.1787/d1a8d965-en}{https://doi.org/10.1787/d1a8d965-en}", "c22c20f8-c1e9-4f7b-90be-00abf80ffe28": "may rely on embedded GAI technologies; Address ongoing monitoring, \\\\\nassessments, and alerting, dynamic risk assessments, and real-time reporting \\\\\ntools for monitoring third-party GAI risks; Consider policy adjustments across GAI \\\\\nmodeling libraries, tools and APIs, fine-tuned models, and embedded tools; \\\\\nAssess GAI vendors, open-source or proprietary GAI tools, or GAI service \\\\\nproviders against incident or vulnerability databases. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nData Privacy; Human-AI \\\\\nConfiguration; Information \\\\\nSecurity; Intellectual Property; \\\\\nValue Chain and Component \\\\\nIntegration; Harmful Bias and \\\\\nHomogenization \\\\\n\\end{tabular} \\\\\n\\hline\nGV-6.1-010 & \\begin{tabular}{l}\nUpdate GAI acceptable use policies to address proprietary and open-source GAI \\\\\ntechnologies and data, and contractors, consultants, and other third-party \\\\\npersonnel. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nIntellectual Property; Value Chain \\\\\nand Component Integration \\\\"}}