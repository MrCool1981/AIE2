{"questions": {"ef34dfc6-9cb4-4800-93cc-8eb1550bc741": "What is a profile in the context of AI RMF?", "f86e7bbd-d547-49d5-a51d-3742e4509e70": "How do AI RMF profiles assist organizations?", "a022894f-2343-4865-9af6-cab405970d55": "What factors does the AI RMF profile for Generative AI consider?", "72fadf55-ed26-49f8-be00-4018d6c36398": "What should the GAI system architecture be able to do when security anomalies are detected?", "e671afeb-b932-40ef-8be0-7f8af8041b45": "How should systems handle queries that may lead to inappropriate or illegal usage?", "b0b28eae-3088-44a4-99b2-77ea8ce290df": "What should be regularly evaluated in GAI systems to ensure safety measures are not circumvented?", "a02a3a94-0b96-42f7-aefd-a551553f3b9f": "What are the suggested actions to prevent GAI systems from generating illegal content?", "c45ecdb5-3da8-406e-b7c4-82ef7fe3f361": "Which risks are associated with the action GV-1.4-001?", "29432f9c-052f-4102-91f6-0dcc9032d1c5": "What does the action GV-1.4-002 aim to address in terms of GAI usage?", "08f595ff-3eef-49de-b9d2-09e68ca49db6": "How can documenting GAI incidents help mitigate harmful outcomes?", "1fefc911-3db7-438b-b10d-c3a499ea93c6": "Why is greater awareness and standardization of GAI incident reporting important?", "2f0b4393-cb14-475d-adeb-bfe5d72464d2": "What role do AI Actors play in tracing the impacts of GAI incidents?", "397249b2-bcf6-4724-af42-f8eaeb157c0d": "What techniques are suggested to mitigate risks related to unexplainable GAI systems?", "9b7ed1b2-c15b-4a86-9bb2-98d899e5c996": "How should pre-trained models be documented when adapted for specific generative tasks?", "4044eeb7-4ab4-4b16-a727-6d85c2c089f8": "What are the GAI risks associated with the action MG-3.2-002?", "b93671b1-60bd-436d-a0fb-760cf4c2eb49": "How does the type of risk influence the implementation of suggested actions?", "0644716c-b39c-4d34-8601-54da518c8006": "What role do the characteristics of GAI systems play in the implementation of suggested actions?", "b3e553d7-9d8e-48a9-94a6-08ff3b889200": "At which stages of the GAI lifecycle are the suggested actions implemented?", "10398acf-8038-4bf5-9852-53492e75e353": "What techniques are suggested for managing statistical biases related to GAI content provenance?", "97976e6a-81e9-4ab6-9bde-5f655b68e61c": "How should content provenance data be documented to ensure privacy and security?", "e683bf9f-e427-4dcf-b615-cfcb359acad1": "What are the GAI risks associated with the action ID MS-2.2-002?", "b09f8d35-af7b-4121-8359-e39837c6b990": "What is the relationship between bias and undesired homogenization in GAI systems?", "1f8006f9-6c50-4f27-82f0-50cefa60cd87": "How can overly homogenized outputs affect decision-making?", "75081493-7323-4eb4-955c-696a0c315102": "What is model collapse and how does it relate to synthetic data?", "7536dcb5-9221-4f6d-add5-30d8cbb66ec6": "What is the purpose of using feedback from internal and external AI actors, users, individuals, and communities?", "9dd8f08c-f36d-4b18-bd47-5dbc694ca1a7": "How can real-time auditing tools aid in the tracking and validation of AI-generated data?", "c883b0ee-43cb-4821-b99e-2a91cb8f3f22": "What mechanisms are suggested for soliciting and capturing user input about AI-generated content?", "26811096-b1d6-4641-81d1-034d7db32e76": "What are some suggested actions for applying organizational risk tolerances to third-party GAI resources?", "893b8b88-ae37-4a31-8ce3-6f6565998108": "What are the GAI risks associated with Action ID MG-3.1-001?", "c9275318-297c-476f-96c8-445d59f3157c": "What processes are involved in applying organizational risk tolerances and controls to third-party GAI resources?", "ee29f8a9-ad2a-4edd-996f-1f294554d162": "What are feedback exercises like AI red-teaming?", "55fe1915-0e0b-47a5-945e-5c6641c357bf": "What is VBRN Information and Capability?", "6d30a943-a4e4-4101-9437-2061bb11a5bf": "What does Integration and Component refer to?", "8160b91f-f423-44f4-a19e-2db9c1f6b5af": "What is the purpose of conducting after-action assessments for GAI system incidents?", "d4863fe2-68ea-4f06-9903-58583dac3f8f": "What are the suggested actions for managing GAI system errors and incidents?", "f5bc019d-7454-4507-8b30-de438eb72d7d": "Which GAI risks are associated with establishing policies to record and track reported errors and near-misses?", "20bc002d-387e-4e95-8d0f-a27cdcc6911e": "What options should be provided to human subjects regarding their participation in GAI applications?", "f784f10f-9c7a-4c0c-a9fb-c97fbbdc5426": "What techniques can be used to minimize the risks associated with linking AI-generated content back to individual human subjects?", "36266059-1d87-410c-b484-4bd4d4c8de0b": "What are the key areas of focus mentioned in the context related to data privacy and human-AI configuration?", "55ee7dca-69ec-4b26-b3ee-c3dcf67bdf30": "What is the purpose of Winogender Schemas in evaluating natural language processing systems?", "4f038019-eb4a-445b-a4f8-93999f8a2cab": "What should be assessed to mitigate concerns of model collapse according to MS-2.11-005?", "95b84e82-55e1-4268-9e5e-a9679b7f518c": "What does MEASURE 2.12 focus on in relation to AI model training and management activities?", "84160501-6685-401b-97d3-604a7fc8753e": "What are some functions of an organization that are impacted by the use of third-party GAI tools?", "e027aa23-bbc6-49bf-8fae-86bfe823de35": "Why might an organization seek to use third-party GAI models or systems?", "5002681e-6026-4c08-b1fc-ef1b02d0ac25": "What implications does the use of third-party GAI tools have for an organization's legal and compliance functions?", "a3319a10-954b-410d-a0bf-ec7c3fabb58a": "What are the biases of GPT detectors against non-native English writers according to Liang et al. (2023)?", "41d3a864-4e9b-4425-8adb-8a4632fbe65f": "What is the focus of the study by Luccioni et al. (2023) on AI deployment?", "947fc303-c11d-4d54-886a-5720a07b7dc3": "What operational risks of AI in large-scale biological attacks are discussed by Mouton et al. (2024)?", "8f98b309-6c29-484a-be59-a948f27a2a4b": "What are the potential consequences of confabulated content in healthcare?", "bb7e140b-a3f0-4929-85fb-b0fb8d129717": "Why might users believe false content generated by confabulations?", "20c2625c-e49c-402f-8e99-646ec21f708d": "Why is it important to monitor confabulated content when integrating GAI into applications involving consequential decision making?", "0cb6928e-1b60-4ca9-8ad1-fcc3a22e8200": "What is the main focus of the paper by Shelby, R. et al. (2023) on arXiv?", "5dc1af7d-2aa9-4e68-93ae-f3165c150917": "How does the paper by Shumailov, I. et al. (2023) describe the impact of training on generated data?", "e8769cd4-2957-4ccf-9f2b-4c039f2a5bb6": "What question does the paper by Soice, E. et al. (2023) on arXiv address regarding large language models and biotechnology?", "d0230a4c-d103-41ff-99d1-b75f2b18dab8": "What is the focus of Appendix B in the AI Risk Management Framework by the National Institute of Standards and Technology?", "471ccfba-71b2-4875-b0b1-b0bb8f30d9ac": "Where can one find the AI RMF Playbook by the National Institute of Standards and Technology?", "c66673cf-b109-48ae-bf4f-e65376b35213": "What type of information is provided in 'The Language of Trustworthy AI: An In-Depth Glossary of Terms' by the National Institute of Standards and Technology?", "b8fb88c4-4c4c-4a36-8198-e29f23202524": "Where can additional information about NIST AI publications be found?", "0a2924f5-8e68-468e-a9ee-264a5ecc332a": "Does the identification of commercial entities in the document imply endorsement by the National Institute of Standards and Technology?", "6a70507f-8155-4dab-a993-9391321d8906": "Is the mention of commercial, non-profit, or academic partners intended to imply endorsement by any U.S. Government agency?", "f184655e-5a8c-49b7-9539-fc99b52c6e13": "What are the suggested actions for GV-2.1-001?", "7352251f-d3ac-428a-bd27-32877aa31706": "What GAI risks are associated with GV-2.1-002?", "0bbfbccb-90ab-4609-88de-a687e1a509c8": "What is the purpose of establishing organizational roles, policies, and procedures for communicating GAI incidents?", "e644106f-d45b-4462-9fda-dc5e159624c1": "What are the potential harms that AI incidents can contribute to?", "64421f48-889f-4122-a1d3-f45945b8d6a1": "How can AI incidents occur in the aggregate?", "707e2c0f-da1d-4cb6-b9ba-412a743314c4": "What is the definition of an AI incident according to the provided context?", "16cc5900-4221-4f0e-88bd-e3ce45da51a2": "What are AI Actors responsible for in the context of monitoring reported issues?", "19775121-2825-4aab-8872-f992d1a81496": "What tasks are included under AI Actor Tasks?", "ad5d3ddb-eadb-4f6b-a7d8-536f054b1bce": "What does MANAGE 4.2 emphasize in terms of AI system updates?", "b3c8537e-caf5-4aeb-b6d3-aab279225b34": "What are chemical and biological design tools (BDTs) specialized in?", "e9373b14-6546-431b-a161-466cceb8181f": "Why is it important to assess the potential harmful uses of chemical and biological design tools?", "ba3bd23b-55ed-4ebc-9f57-1533f2e11c99": "How can ongoing assessments of AI tools' risks be enhanced?", "d08d06c0-ea77-4808-a0a8-ed840ddf5b99": "How can structured public feedback inform design and implementation decisions?", "3ddea656-8d4b-492a-b556-46d0fb344b37": "What purposes can the results and insights from public feedback serve?", "201db89a-a463-48b6-a44c-65c393c314c0": "What best practices should organizations follow when implementing feedback activities?", "0d25e7f6-83ea-4452-8d62-a5b88c06bff9": "What is the purpose of using organizational risk tolerance in evaluating pre-trained models?", "50d44813-bc47-4fc5-9a66-c8fb8f1ff86f": "What should be done with pre-trained models that perform outside of defined limits?", "eb88e490-a886-4e72-bd84-4163cd3733dd": "What are some examples of CBRN Information or Capabilities mentioned in the context?", "d55e68d9-a85b-471e-b646-2abb93a1ffa1": "What is the main focus of Zhang, Y. et al. (2023) in their study on human favoritism and AI aversion?", "aa0a0891-dee8-4b63-9f2e-328a64ef393f": "Where can the article 'Human favoritism, not AI aversion' by Zhang, Y. et al. (2023) be found?", "ebd413d7-13b3-4418-b60e-032961f70888": "What topic is addressed in the paper 'Siren's Song in the AI Ocean' by Zhang, Y. et al. (2023)?", "a164c820-3fa0-4350-bb7b-bd7fbfa4a063": "What is the main focus of the article by Schaul, K. et al. (2024) in the Washington Post?", "f9675711-6bf6-40a5-8cc0-8402a85caacf": "What do Scheurer, J. et al. (2023) claim about large language models in their technical report?", "a7d4a9d1-201e-4375-8956-66753a74965b": "What is the topic of Shelby, R. et al. (2023) paper on arXiv?", "5f73fb5b-6433-4910-8ae5-888fa344a7e0": "What are the potential impacts of GAI systems on different classes of individuals, groups, or environmental ecosystems?", "33ceefd5-e49d-463d-b5c5-c6d9eb46b2d2": "How should sources of bias in GAI training and TEVV data be reviewed and documented?", "b23eee79-f0f2-4b0b-8f2e-be53a0b176f5": "What types of harmful content are mentioned in the context?"}, "relevant_contexts": {"ef34dfc6-9cb4-4800-93cc-8eb1550bc741": "69d5e0bf-aaed-44ec-814d-c13559699310", "f86e7bbd-d547-49d5-a51d-3742e4509e70": "69d5e0bf-aaed-44ec-814d-c13559699310", "a022894f-2343-4865-9af6-cab405970d55": "69d5e0bf-aaed-44ec-814d-c13559699310", "72fadf55-ed26-49f8-be00-4018d6c36398": "e37a9c2b-b064-4c18-b5a4-6c9752287a96", "e671afeb-b932-40ef-8be0-7f8af8041b45": "e37a9c2b-b064-4c18-b5a4-6c9752287a96", "b0b28eae-3088-44a4-99b2-77ea8ce290df": "e37a9c2b-b064-4c18-b5a4-6c9752287a96", "a02a3a94-0b96-42f7-aefd-a551553f3b9f": "2d315caa-ed75-4e93-a121-895cca5f0dff", "c45ecdb5-3da8-406e-b7c4-82ef7fe3f361": "2d315caa-ed75-4e93-a121-895cca5f0dff", "29432f9c-052f-4102-91f6-0dcc9032d1c5": "2d315caa-ed75-4e93-a121-895cca5f0dff", "08f595ff-3eef-49de-b9d2-09e68ca49db6": "fd9adb2e-e4e2-42ec-bdc6-c7f3e5edfcab", "1fefc911-3db7-438b-b10d-c3a499ea93c6": "fd9adb2e-e4e2-42ec-bdc6-c7f3e5edfcab", "2f0b4393-cb14-475d-adeb-bfe5d72464d2": "fd9adb2e-e4e2-42ec-bdc6-c7f3e5edfcab", "397249b2-bcf6-4724-af42-f8eaeb157c0d": "2ac65c95-2e61-4457-bce1-e4f5c1e6b25b", "9b7ed1b2-c15b-4a86-9bb2-98d899e5c996": "2ac65c95-2e61-4457-bce1-e4f5c1e6b25b", "4044eeb7-4ab4-4b16-a727-6d85c2c089f8": "2ac65c95-2e61-4457-bce1-e4f5c1e6b25b", "b93671b1-60bd-436d-a0fb-760cf4c2eb49": "0311f7a0-73ef-436f-854c-31a4d92cadf9", "0644716c-b39c-4d34-8601-54da518c8006": "0311f7a0-73ef-436f-854c-31a4d92cadf9", "b3e553d7-9d8e-48a9-94a6-08ff3b889200": "0311f7a0-73ef-436f-854c-31a4d92cadf9", "10398acf-8038-4bf5-9852-53492e75e353": "0111b957-fc36-4fa7-ae96-4ea86d748af8", "97976e6a-81e9-4ab6-9bde-5f655b68e61c": "0111b957-fc36-4fa7-ae96-4ea86d748af8", "e683bf9f-e427-4dcf-b615-cfcb359acad1": "0111b957-fc36-4fa7-ae96-4ea86d748af8", "b09f8d35-af7b-4121-8359-e39837c6b990": "800f2992-d7dd-45ba-8f8d-2e9e5efa0e4b", "1f8006f9-6c50-4f27-82f0-50cefa60cd87": "800f2992-d7dd-45ba-8f8d-2e9e5efa0e4b", "75081493-7323-4eb4-955c-696a0c315102": "800f2992-d7dd-45ba-8f8d-2e9e5efa0e4b", "7536dcb5-9221-4f6d-add5-30d8cbb66ec6": "eafdc73c-ed21-4383-86c5-3f218b157809", "9dd8f08c-f36d-4b18-bd47-5dbc694ca1a7": "eafdc73c-ed21-4383-86c5-3f218b157809", "c883b0ee-43cb-4821-b99e-2a91cb8f3f22": "eafdc73c-ed21-4383-86c5-3f218b157809", "26811096-b1d6-4641-81d1-034d7db32e76": "7b9724be-f84c-4616-b54f-a79d5a6c15eb", "893b8b88-ae37-4a31-8ce3-6f6565998108": "7b9724be-f84c-4616-b54f-a79d5a6c15eb", "c9275318-297c-476f-96c8-445d59f3157c": "7b9724be-f84c-4616-b54f-a79d5a6c15eb", "ee29f8a9-ad2a-4edd-996f-1f294554d162": "93288f5d-3188-48d3-b27d-582cda410d53", "55fe1915-0e0b-47a5-945e-5c6641c357bf": "93288f5d-3188-48d3-b27d-582cda410d53", "6d30a943-a4e4-4101-9437-2061bb11a5bf": "93288f5d-3188-48d3-b27d-582cda410d53", "8160b91f-f423-44f4-a19e-2db9c1f6b5af": "d8ce1e04-f513-4006-a256-b2f3af7fbc7a", "d4863fe2-68ea-4f06-9903-58583dac3f8f": "d8ce1e04-f513-4006-a256-b2f3af7fbc7a", "f5bc019d-7454-4507-8b30-de438eb72d7d": "d8ce1e04-f513-4006-a256-b2f3af7fbc7a", "20bc002d-387e-4e95-8d0f-a27cdcc6911e": "40970847-f4b7-4cd5-ad25-fd4000cf7cb4", "f784f10f-9c7a-4c0c-a9fb-c97fbbdc5426": "40970847-f4b7-4cd5-ad25-fd4000cf7cb4", "36266059-1d87-410c-b484-4bd4d4c8de0b": "40970847-f4b7-4cd5-ad25-fd4000cf7cb4", "55ee7dca-69ec-4b26-b3ee-c3dcf67bdf30": "565063e8-578e-4e03-9bca-a80b11f2400e", "4f038019-eb4a-445b-a4f8-93999f8a2cab": "565063e8-578e-4e03-9bca-a80b11f2400e", "95b84e82-55e1-4268-9e5e-a9679b7f518c": "565063e8-578e-4e03-9bca-a80b11f2400e", "84160501-6685-401b-97d3-604a7fc8753e": "1f167ca3-8e2d-4a2d-a95d-4efac0b13be4", "e027aa23-bbc6-49bf-8fae-86bfe823de35": "1f167ca3-8e2d-4a2d-a95d-4efac0b13be4", "5002681e-6026-4c08-b1fc-ef1b02d0ac25": "1f167ca3-8e2d-4a2d-a95d-4efac0b13be4", "a3319a10-954b-410d-a0bf-ec7c3fabb58a": "e3ac2abb-69ca-480b-ac63-05f71c728bbd", "41d3a864-4e9b-4425-8adb-8a4632fbe65f": "e3ac2abb-69ca-480b-ac63-05f71c728bbd", "947fc303-c11d-4d54-886a-5720a07b7dc3": "e3ac2abb-69ca-480b-ac63-05f71c728bbd", "8f98b309-6c29-484a-be59-a948f27a2a4b": "468e5866-d571-480f-af16-55a27a9ae341", "bb7e140b-a3f0-4929-85fb-b0fb8d129717": "468e5866-d571-480f-af16-55a27a9ae341", "20c2625c-e49c-402f-8e99-646ec21f708d": "468e5866-d571-480f-af16-55a27a9ae341", "0cb6928e-1b60-4ca9-8ad1-fcc3a22e8200": "d7b96520-e1e2-4f63-811f-94a34c3f6c35", "5dc1af7d-2aa9-4e68-93ae-f3165c150917": "d7b96520-e1e2-4f63-811f-94a34c3f6c35", "e8769cd4-2957-4ccf-9f2b-4c039f2a5bb6": "d7b96520-e1e2-4f63-811f-94a34c3f6c35", "d0230a4c-d103-41ff-99d1-b75f2b18dab8": "caa23407-5500-4328-882a-6a0756b21d67", "471ccfba-71b2-4875-b0b1-b0bb8f30d9ac": "caa23407-5500-4328-882a-6a0756b21d67", "c66673cf-b109-48ae-bf4f-e65376b35213": "caa23407-5500-4328-882a-6a0756b21d67", "b8fb88c4-4c4c-4a36-8198-e29f23202524": "6dca4c3e-af3a-4d80-8a04-13b94c3b7f51", "0a2924f5-8e68-468e-a9ee-264a5ecc332a": "6dca4c3e-af3a-4d80-8a04-13b94c3b7f51", "6a70507f-8155-4dab-a993-9391321d8906": "6dca4c3e-af3a-4d80-8a04-13b94c3b7f51", "f184655e-5a8c-49b7-9539-fc99b52c6e13": "7d7c0a29-395e-4fa5-925a-0a122e0c537a", "7352251f-d3ac-428a-bd27-32877aa31706": "7d7c0a29-395e-4fa5-925a-0a122e0c537a", "0bbfbccb-90ab-4609-88de-a687e1a509c8": "7d7c0a29-395e-4fa5-925a-0a122e0c537a", "e644106f-d45b-4462-9fda-dc5e159624c1": "83f47e09-bece-4665-9081-998fe1a52c34", "64421f48-889f-4122-a1d3-f45945b8d6a1": "83f47e09-bece-4665-9081-998fe1a52c34", "707e2c0f-da1d-4cb6-b9ba-412a743314c4": "83f47e09-bece-4665-9081-998fe1a52c34", "16cc5900-4221-4f0e-88bd-e3ce45da51a2": "6eebdfcd-b4ee-4e9e-a859-199f592862bd", "19775121-2825-4aab-8872-f992d1a81496": "6eebdfcd-b4ee-4e9e-a859-199f592862bd", "ad5d3ddb-eadb-4f6b-a7d8-536f054b1bce": "6eebdfcd-b4ee-4e9e-a859-199f592862bd", "b3c8537e-caf5-4aeb-b6d3-aab279225b34": "7b6d197e-23ea-4ffe-95f8-db2ad2583a5a", "e9373b14-6546-431b-a161-466cceb8181f": "7b6d197e-23ea-4ffe-95f8-db2ad2583a5a", "ba3bd23b-55ed-4ebc-9f57-1533f2e11c99": "7b6d197e-23ea-4ffe-95f8-db2ad2583a5a", "d08d06c0-ea77-4808-a0a8-ed840ddf5b99": "0dfdfdb4-b7a3-42a0-90aa-8a8c3307c351", "3ddea656-8d4b-492a-b556-46d0fb344b37": "0dfdfdb4-b7a3-42a0-90aa-8a8c3307c351", "201db89a-a463-48b6-a44c-65c393c314c0": "0dfdfdb4-b7a3-42a0-90aa-8a8c3307c351", "0d25e7f6-83ea-4452-8d62-a5b88c06bff9": "11ef1fbd-41d9-4dd4-bddb-149794145465", "50d44813-bc47-4fc5-9a66-c8fb8f1ff86f": "11ef1fbd-41d9-4dd4-bddb-149794145465", "eb88e490-a886-4e72-bd84-4163cd3733dd": "11ef1fbd-41d9-4dd4-bddb-149794145465", "d55e68d9-a85b-471e-b646-2abb93a1ffa1": "365c3cb3-3193-4f3d-a820-c452f259c53c", "aa0a0891-dee8-4b63-9f2e-328a64ef393f": "365c3cb3-3193-4f3d-a820-c452f259c53c", "ebd413d7-13b3-4418-b60e-032961f70888": "365c3cb3-3193-4f3d-a820-c452f259c53c", "a164c820-3fa0-4350-bb7b-bd7fbfa4a063": "8fc67923-019c-477a-8116-a77d5253064f", "f9675711-6bf6-40a5-8cc0-8402a85caacf": "8fc67923-019c-477a-8116-a77d5253064f", "a7d4a9d1-201e-4375-8956-66753a74965b": "8fc67923-019c-477a-8116-a77d5253064f", "5f73fb5b-6433-4910-8ae5-888fa344a7e0": "46119b13-9804-40b7-9e65-1978d902140a", "33ceefd5-e49d-463d-b5c5-c6d9eb46b2d2": "46119b13-9804-40b7-9e65-1978d902140a", "b23eee79-f0f2-4b0b-8f2e-be53a0b176f5": "46119b13-9804-40b7-9e65-1978d902140a"}, "corpus": {"69d5e0bf-aaed-44ec-814d-c13559699310": "A profile is an implementation of the AI RMF functions, categories, and subcategories for a specific setting, application, or technology - in this case, Generative AI (GAI) - based on the requirements, risk tolerance, and resources of the Framework user. AI RMF profiles assist organizations in deciding how to best manage Al risks in a manner that is well-aligned with their goals, considers legal/regulatory requirements and best practices, and reflects risk management priorities. Consistent with other AI RMF profiles, this profile offers insights into how risk can be managed across various stages of the Al lifecycle and for GAI as a technology.", "e37a9c2b-b064-4c18-b5a4-6c9752287a96": "Integration; Dangerous, Violent, or \\\\\nHateful Content \\\\\n\\end{tabular} \\\\\n\\hline\nMS-2.6-005 & \\begin{tabular}{l}\nVerify that GAI system architecture can monitor outputs and performance, and \\\\\nhandle, recover from, and repair errors when security anomalies, threats and \\\\\nimpacts are detected. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nConfabulation; Information \\\\\nIntegrity; Information Security \\\\\n\\end{tabular} \\\\\n\\hline\nMS-2.6-006 & \\begin{tabular}{l}\nVerify that systems properly handle queries that may give rise to inappropriate, \\\\\nmalicious, or illegal usage, including facilitating manipulation, extortion, targeted \\\\\nimpersonation, cyber-attacks, and weapons creation. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nCBRN Information or Capabilities; \\\\\nInformation Security \\\\\n\\end{tabular} \\\\\n\\hline\nMS-2.6-007 & \\begin{tabular}{l}\nRegularly evaluate GAI system vulnerabilities to possible circumvention of safety \\\\\nmeasures. \\\\\n\\end{tabular} & \\begin{tabular}{l}", "800f2992-d7dd-45ba-8f8d-2e9e5efa0e4b": "Bias is mutually reinforcing with the problem of undesired homogenization, in which GAI systems produce skewed distributions of outputs that are overly uniform (for example, repetitive aesthetic styles\\\\\nand reduced content diversity). Overly homogenized outputs can themselves be incorrect, or they may lead to unreliable decision-making or amplify harmful biases. These phenomena can flow from foundation models to downstream models and systems, with the foundation models acting as \"bottlenecks,\" or single points of failure.\n\nOverly homogenized content can contribute to \"model collapse.\" Model collapse can occur when model training over-relies on synthetic data, resulting in data points disappearing from the distribution of the new model's outputs. In addition to threatening the robustness of the model overall, model collapse could lead to homogenized outputs, including by amplifying any homogenization from the model used to generate the synthetic training data.", "e3ac2abb-69ca-480b-ac63-05f71c728bbd": "Liang, W. et al. (2023) GPT detectors are biased against non-native English writers. arXiv. \\href{https://arxiv.org/abs/2304.02819}{https://arxiv.org/abs/2304.02819}\n\nLuccioni, A. et al. (2023) Power Hungry Processing: Watts Driving the Cost of AI Deployment? arXiv. \\href{https://arxiv.org/pdf/2311.16863}{https://arxiv.org/pdf/2311.16863}\n\nMouton, C. et al. (2024) The Operational Risks of AI in Large-Scale Biological Attacks. RAND. \\href{https://www.rand.org/pubs/research}{https://www.rand.org/pubs/research} reports/RRA2977-2.html.\n\nNicoletti, L. et al. (2023) Humans Are Biased. Generative Ai Is Even Worse. Bloomberg. \\href{https://www.bloomberg.com/graphics/2023-generative-ai-bias/}{https://www.bloomberg.com/graphics/2023-generative-ai-bias/}.\n\nNational Institute of Standards and Technology (2024) Adversarial Machine Learning: A Taxonomy and Terminology of Attacks and Mitigations \\href{https://csrc.nist.gov/pubs/ai/100/2/e2023/final}{https://csrc.nist.gov/pubs/ai/100/2/e2023/final}", "46119b13-9804-40b7-9e65-1978d902140a": "sampling a fraction of traffic and manually annotating denigrating content). \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHarmful Bias and Homogenization; \\\\\nDangerous, Violent, or Hateful \\\\\nContent \\\\\n\\end{tabular} \\\\\n\\hline\nMS-2.11-003 & \\begin{tabular}{l}\nIdentify the classes of individuals, groups, or environmental ecosystems which \\\\\nmight be impacted by GAI systems through direct engagement with potentially \\\\\nimpacted communities. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nEnvironmental; Harmful Bias and \\\\\nHomogenization \\\\\n\\end{tabular} \\\\\n\\hline\nMS-2.11-004 & \\begin{tabular}{l}\nReview, document, and measure sources of bias in GAI training and TEVV data: \\\\\nDifferences in distributions of outcomes across and within groups, including \\\\\nintersecting groups; Completeness, representativeness, and balance of data \\\\\nsources; demographic group and subgroup coverage in GAI system training \\\\\ndata; Forms of latent systemic bias in images, text, audio, embeddings, or other \\\\", "565063e8-578e-4e03-9bca-a80b11f2400e": "${ }^{15}$ Winogender Schemas is a sample set of paired sentences which differ only by gender of the pronouns used, which can be used to evaluate gender bias in natural language processing coreference resolution systems.\n\n\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nMS-2.11-005 & \\begin{tabular}{l}\nAssess the proportion of synthetic to non-synthetic training data and verify \\\\\ntraining data is not overly homogenous or GAI-produced to mitigate concerns of \\\\\nmodel collapse. \\\\\n\\end{tabular} & Harmful Bias and Homogenization \\\\\n\\hline\n\\begin{tabular}{l}\nAl Actor Tasks: Al Deployment, AI Impact Assessment, Affected Individuals and Communities, Domain Experts, End-Users, \\\\\nOperation and Monitoring, TEVV \\\\\n\\end{tabular} &  &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}\n\nMEASURE 2.12: Environmental impact and sustainability of AI model training and management activities - as identified in the MAP function - are assessed and documented.", "2d315caa-ed75-4e93-a121-895cca5f0dff": "GOVERN 1.4: The risk management process and its outcomes are established through transparent policies, procedures, and other controls based on organizational risk priorities.\n\n\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nGV-1.4-001 & \\begin{tabular}{l}\nEstablish policies and mechanisms to prevent GAI systems from generating \\\\\nCSAM, NCII or content that violates the law. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nObscene, Degrading, and/or \\\\\nAbusive Content; Harmful Bias \\\\\nand Homogenization; \\\\\nDangerous, Violent, or Hateful \\\\\nContent \\\\\n\\end{tabular} \\\\\n\\hline\nGV-1.4-002 & \\begin{tabular}{l}\nEstablish transparent acceptable use policies for GAI that address illegal use or \\\\\napplications of GAI. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nCBRN Information or \\\\\nCapabilities; Obscene, \\\\\nDegrading, and/or Abusive \\\\\nContent; Data Privacy; Civil \\\\\nRights violations \\\\\n\\end{tabular} \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "d7b96520-e1e2-4f63-811f-94a34c3f6c35": "Shelby, R. et al. (2023) Sociotechnical Harms of Algorithmic Systems: Scoping a Taxonomy for Harm Reduction. arXiv. \\href{https://arxiv.org/pdf/2210.05791}{https://arxiv.org/pdf/2210.05791}\n\nShevlane, T. et al. (2023) Model evaluation for extreme risks. arXiv. \\href{https://arxiv.org/pdf/2305.15324}{https://arxiv.org/pdf/2305.15324}\\\\\nShumailov, I. et al. (2023) The curse of recursion: training on generated data makes models forget. arXiv. \\href{https://arxiv.org/pdf/2305.17493v2}{https://arxiv.org/pdf/2305.17493v2}\n\nSmith, A. et al. (2023) Hallucination or Confabulation? Neuroanatomy as metaphor in Large Language Models. PLOS Digital Health.\\\\\n\\href{https://journals.plos.org/digitalhealth/article?id=10.1371/journal.pdig}{https://journals.plos.org/digitalhealth/article?id=10.1371/journal.pdig}. 0000388\\\\\nSoice, E. et al. (2023) Can large language models democratize access to dual-use biotechnology? arXiv. \\href{https://arxiv.org/abs/2306.03809}{https://arxiv.org/abs/2306.03809}", "40970847-f4b7-4cd5-ad25-fd4000cf7cb4": "\\end{tabular} & \\begin{tabular}{l}\nData Privacy; Human AI \\\\\nConfiguration; Information \\\\\nIntegrity; Information Security; \\\\\nDangerous, Violent, or Hateful \\\\\nContent \\\\\n\\end{tabular} \\\\\n\\hline\nMS-2.2-003 & \\begin{tabular}{l}\nProvide human subjects with options to withdraw participation or revoke their \\\\\nconsent for present or future use of their data in GAI applications. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nData Privacy; Human-AI \\\\\nConfiguration; Information \\\\\nIntegrity \\\\\n\\end{tabular} \\\\\n\\hline\nMS-2.2-004 & \\begin{tabular}{l}\nUse techniques such as anonymization, differential privacy or other privacy- \\\\\nenhancing technologies to minimize the risks associated with linking Al-generated \\\\\ncontent back to individual human subjects. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nData Privacy; Human-AI \\\\\nConfiguration \\\\\n\\end{tabular} \\\\\n\\hline\nAI Actor Tasks: Al Development, Human Factors, TEVV &  &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "0111b957-fc36-4fa7-ae96-4ea86d748af8": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMS-2.2-001 & \\begin{tabular}{l}\nAssess and manage statistical biases related to GAI content provenance through \\\\\ntechniques such as re-sampling, re-weighting, or adversarial training. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nInformation Integrity; Information \\\\\nSecurity; Harmful Bias and \\\\\nHomogenization \\\\\n\\end{tabular} \\\\\n\\hline\nMS-2.2-002 & \\begin{tabular}{l}\nDocument how content provenance data is tracked and how that data interacts \\\\\nwith privacy and security. Consider: Anonymizing data to protect the privacy of \\\\\nhuman subjects; Leveraging privacy output filters; Removing any personally \\\\\nidentifiable information (PII) to prevent potential harm or misuse. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nData Privacy; Human AI \\\\\nConfiguration; Information \\\\\nIntegrity; Information Security; \\\\\nDangerous, Violent, or Hateful \\\\\nContent \\\\\n\\end{tabular} \\\\\n\\hline", "83f47e09-bece-4665-9081-998fe1a52c34": "\\section*{A.1.8. Incident Disclosure}\n\\section*{Overview}\nAl incidents can be defined as an \"event, circumstance, or series of events where the development, use, or malfunction of one or more Al systems directly or indirectly contributes to one of the following harms: injury or harm to the health of a person or groups of people (including psychological harms and harms to mental health); disruption of the management and operation of critical infrastructure; violations of human rights or a breach of obligations under applicable law intended to protect fundamental, labor, and intellectual property rights; or harm to property, communities, or the environment.\" Al incidents can occur in the aggregate (i.e., for systemic discrimination) or acutely (i.e., for one individual).\n\\section*{State of AI Incident Tracking and Disclosure}", "11ef1fbd-41d9-4dd4-bddb-149794145465": "MG-3.2-009 & \\begin{tabular}{l}\nUse organizational risk tolerance to evaluate acceptable risks and performance \\\\\nmetrics and decommission or retrain pre-trained models that perform outside of \\\\\ndefined limits. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nCBRN Information or Capabilities; \\\\\nConfabulation \\\\\n\\end{tabular} \\\\\n\\hline\nAI Actor Tasks: Al Deployment, Operation and Monitoring, Third-party entities &  &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "0311f7a0-73ef-436f-854c-31a4d92cadf9": "Implementation of the suggested actions will vary depending on the type of risk, characteristics of GAI systems, stage of the GAI lifecycle, and relevant AI actors involved.", "7d7c0a29-395e-4fa5-925a-0a122e0c537a": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nGV-2.1-001 & \\begin{tabular}{l}\nEstablish organizational roles, policies, and procedures for communicating GAI \\\\\nincidents and performance to AI Actors and downstream stakeholders (including \\\\\nthose potentially impacted), via community or official resources (e.g., Al incident \\\\\ndatabase, AVID, $\\underline{C V E}, \\underline{N V D}$, or OECD AI incident monitor). \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-AI Configuration; Value \\\\\nChain and Component Integration \\\\\n\\end{tabular} \\\\\n\\hline\nGV-2.1-002 & \\begin{tabular}{l}\nEstablish procedures to engage teams for GAI system incident response with \\\\\ndiverse composition and responsibilities based on the particular incident type. \\\\\n\\end{tabular} & Harmful Bias and Homogenization \\\\\n\\hline\nGV-2.1-003 & \\begin{tabular}{l}\nEstablish processes to verify the AI Actors conducting GAI incident response tasks \\\\", "eafdc73c-ed21-4383-86c5-3f218b157809": "\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nMG-2.2-006 & \\begin{tabular}{l}\nUse feedback from internal and external Al Actors, users, individuals, and \\\\\ncommunities, to assess impact of Al-generated content. \\\\\n\\end{tabular} & Human-AI Configuration \\\\\n\\hline\nMG-2.2-007 & \\begin{tabular}{l}\nUse real-time auditing tools where they can be demonstrated to aid in the \\\\\ntracking and validation of the lineage and authenticity of Al-generated data. \\\\\n\\end{tabular} & Information Integrity \\\\\n\\hline\nMG-2.2-008 & \\begin{tabular}{l}\nUse structured feedback mechanisms to solicit and capture user input about AI- \\\\\ngenerated content to detect subtle shifts in quality or alignment with \\\\\ncommunity and societal values. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nHuman-Al Configuration; Harmful \\\\\nBias and Homogenization \\\\\n\\end{tabular} \\\\\n\\hline\nMG-2.2-009 & \\begin{tabular}{l}\nConsider opportunities to responsibly use synthetic data and other privacy \\\\", "fd9adb2e-e4e2-42ec-bdc6-c7f3e5edfcab": "Documenting, reporting, and sharing information about GAI incidents can help mitigate and prevent harmful outcomes by assisting relevant AI Actors in tracing impacts to their source. Greater awareness and standardization of GAI incident reporting could promote this transparency and improve GAI risk management across the AI ecosystem.\n\\section*{Documentation and Involvement of AI Actors}", "365c3cb3-3193-4f3d-a820-c452f259c53c": "Zhang, Y. et al. (2023) Human favoritism, not Al aversion: People's perceptions (and bias) toward generative Al , human experts, and human-GAI collaboration in persuasive content generation. Judgment and Decision Making. \\href{https://www.cambridge.org/core/journals/judgment-and-decision-}{https://www.cambridge.org/core/journals/judgment-and-decision-}\\\\\nmaking/article/human-favoritism-not-ai-aversion-peoples-perceptions-and-bias-toward-generative-aihuman-experts-and-humangai-collaboration-in-persuasive-content-\\\\\ngeneration/419C4BD9CE82673EAF1D8F6C350C4FA8\\\\\nZhang, Y. et al. (2023) Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models. arXiv. \\href{https://arxiv.org/pdf/2309.01219}{https://arxiv.org/pdf/2309.01219}\\\\", "1f167ca3-8e2d-4a2d-a95d-4efac0b13be4": "\\section*{A.1.3. Third-Party Considerations}\nOrganizations may seek to acquire, embed, incorporate, or use open-source or proprietary third-party GAI models, systems, or generated data for various applications across an enterprise. Use of these GAI tools and inputs has implications for all functions of the organization - including but not limited to acquisition, human resources, legal, compliance, and IT services - regardless of whether they are carried out by employees or third parties. Many of the actions cited above are relevant and options for addressing third-party considerations.", "7b6d197e-23ea-4ffe-95f8-db2ad2583a5a": "Furthermore, chemical and biological design tools (BDTs) - highly specialized Al systems trained on scientific data that aid in chemical and biological design - may augment design capabilities in chemistry and biology beyond what text-based LLMs are able to provide. As these models become more efficacious, including for beneficial uses, it will be important to assess their potential to be used for harm, such as the ideation and design of novel harmful chemical or biological agents.\n\nWhile some of these described capabilities lie beyond the reach of existing GAI tools, ongoing assessments of this risk would be enhanced by monitoring both the ability of AI tools to facilitate CBRN weapons planning and GAI systems' connection or access to relevant data and tools.", "caa23407-5500-4328-882a-6a0756b21d67": "National Institute of Standards and Technology (2023) AI Risk Management Framework, Appendix B: How Al Risks Differ from Traditional Software Risks.\\\\\n\\href{https://airc.nist.gov/AI}{https://airc.nist.gov/AI} RMF Knowledge Base/AI RMF/Appendices/Appendix B\\\\\nNational Institute of Standards and Technology (2023) AI RMF Playbook.\\\\\n\\href{https://airc.nist.gov/AI}{https://airc.nist.gov/AI} RMF Knowledge Base/Playbook\\\\\nNational Institue of Standards and Technology (2023) Framing Risk\\\\\n\\href{https://airc.nist.gov/AI}{https://airc.nist.gov/AI} RMF Knowledge Base/AI RMF/Foundational Information/1-sec-risk\\\\\nNational Institute of Standards and Technology (2023) The Language of Trustworthy AI: An In-Depth Glossary of Terms \\href{https://airc.nist.gov/AI}{https://airc.nist.gov/AI} RMF Knowledge Base/Glossary", "7b9724be-f84c-4616-b54f-a79d5a6c15eb": "\\begin{center}\n\\begin{tabular}{|c|c|c|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMG-3.1-001 & \\begin{tabular}{l}\nApply organizational risk tolerances and controls (e.g., acquisition and \\\\\nprocurement processes; assessing personnel credentials and qualifications, \\\\\nperforming background checks; filtering GAI input and outputs, grounding, fine \\\\\ntuning, retrieval-augmented generation) to third-party GAI resources: Apply \\\\\norganizational risk tolerance to the utilization of third-party datasets and other \\\\\nGAI resources; Apply organizational risk tolerances to fine-tuned third-party \\\\\nmodels; Apply organizational risk tolerance to existing third-party models \\\\\nadapted to a new domain; Reassess risk measurements after fine-tuning third- \\\\\nparty GAI models. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nValue Chain and Component \\\\\nIntegration; Intellectual Property \\\\\n\\end{tabular} \\\\\n\\hline\nMG-3.1-002 & \\begin{tabular}{l}", "93288f5d-3188-48d3-b27d-582cda410d53": "feedback exercises such as AI red-teaming or independent external evaluations. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nVBRN Information and Capability; \\\\\nIntegration and Component \\\\\n\\end{tabular} \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "2ac65c95-2e61-4457-bce1-e4f5c1e6b25b": "\\begin{center}\n\\begin{tabular}{|c|c|c|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMG-3.2-001 & \\begin{tabular}{l}\nApply explainable AI (XAI) techniques (e.g., analysis of embeddings, model \\\\\ncompression/distillation, gradient-based attributions, occlusion/term reduction, \\\\\ncounterfactual prompts, word clouds) as part of ongoing continuous \\\\\nimprovement processes to mitigate risks related to unexplainable GAI systems. \\\\\n\\end{tabular} & Harmful Bias and Homogenization \\\\\n\\hline\nMG-3.2-002 & \\begin{tabular}{l}\nDocument how pre-trained models have been adapted (e.g., fine-tuned, or \\\\\nretrieval-augmented generation) for the specific generative task, including any \\\\\ndata augmentations, parameter adjustments, or other modifications. Access to \\\\\nun-tuned (baseline) models supports debugging the relative influence of the pre- \\\\\ntrained weights compared to the fine-tuned model weights or other system \\\\\nupdates. \\\\\n\\end{tabular} & Information Integrity; Data Privacy \\\\", "6dca4c3e-af3a-4d80-8a04-13b94c3b7f51": "\\subsubsection*{\\section{Additional Information}\n}\n Additional information about this publication and other NIST AI publications are available at \\href{https://airc.nist.gov/Home}{https://airc.nist.gov/Home}. Disclaimer: Certain commercial entities, equipment, or materials may be identified in this document in order to adequately describe an experimental procedure or concept. Such identification is not intended to imply recommendation or endorsement by the National Institute of Standards and Technology, nor is it intended to imply that the entities, materials, or equipment are necessarily the best available for the purpose. Any mention of commercial, non-profit, academic partners, or their products, or references is for information only; it is not intended to imply endorsement or recommendation by any U.S. Government agency.\n\\end{abstract}", "d8ce1e04-f513-4006-a256-b2f3af7fbc7a": "MANAGE 4.3: Incidents and errors are communicated to relevant AI Actors, including affected communities. Processes for tracking, responding to, and recovering from incidents and errors are followed and documented.\n\n\\begin{center}\n\\begin{tabular}{|l|l|l|}\n\\hline\nAction ID & Suggested Action & GAI Risks \\\\\n\\hline\nMG-4.3-001 & \\begin{tabular}{l}\nConduct after-action assessments for GAI system incidents to verify incident \\\\\nresponse and recovery processes are followed and effective, including to follow \\\\\nprocedures for communicating incidents to relevant AI Actors and where \\\\\napplicable, relevant legal and regulatory bodies. \\\\\n\\end{tabular} & Information Security \\\\\n\\hline\nMG-4.3-002 & \\begin{tabular}{l}\nEstablish and maintain policies and procedures to record and track GAI system \\\\\nreported errors, near-misses, and negative impacts. \\\\\n\\end{tabular} & \\begin{tabular}{l}\nConfabulation; Information \\\\\nIntegrity \\\\\n\\end{tabular} \\\\\n\\hline\n\\end{tabular}\n\\end{center}", "468e5866-d571-480f-af16-55a27a9ae341": "Risks from confabulations may arise when users believe false content - often due to the confident nature of the response - leading users to act upon or promote the false information. This poses a challenge for many real-world applications, such as in healthcare, where a confabulated summary of patient information reports could cause doctors to make incorrect diagnoses and/or recommend the wrong treatments. Risks of confabulated content may be especially important to monitor when integrating GAI into applications involving consequential decision making.", "6eebdfcd-b4ee-4e9e-a859-199f592862bd": "MG-4.1-007\\\\\nVerify that AI Actors responsible for monitoring reported issues can effectively evaluate GAI system performance including the application of content provenance data tracking techniques, and promptly escalate issues for response.\\\\\nHuman-Al Configuration; Information Integrity\n\nAl Actor Tasks: AI Deployment, Affected Individuals and Communities, Domain Experts, End-Users, Human Factors, Operation and Monitoring\n\nMANAGE 4.2: Measurable activities for continual improvements are integrated into Al system updates and include regular engagement with interested parties, including relevant AI Actors.", "8fc67923-019c-477a-8116-a77d5253064f": "Schaul, K. et al. (2024) Inside the secret list of websites that make AI like ChatGPT sound smart.\\\\\nWashington Post. \\href{https://www.washingtonpost.com/technology/interactive/2023/ai-chatbot-learning/}{https://www.washingtonpost.com/technology/interactive/2023/ai-chatbot-learning/}\\\\\nScheurer, J. et al. (2023) Technical report: Large language models can strategically deceive their users when put under pressure. arXiv. \\href{https://arxiv.org/abs/2311.07590}{https://arxiv.org/abs/2311.07590}\n\nShelby, R. et al. (2023) Sociotechnical Harms of Algorithmic Systems: Scoping a Taxonomy for Harm Reduction. arXiv. \\href{https://arxiv.org/pdf/2210.05791}{https://arxiv.org/pdf/2210.05791}", "0dfdfdb4-b7a3-42a0-90aa-8a8c3307c351": "\\end{itemize}\nInformation gathered from structured public feedback can inform design, implementation, deployment approval, maintenance, or decommissioning decisions. Results and insights gleaned from these exercises can serve multiple purposes, including improving data quality and preprocessing, bolstering governance decision making, and enhancing system documentation and debugging practices. When implementing feedback activities, organizations should follow human subjects research requirements and best practices such as informed consent and subject compensation.\n\\section*{Participatory Engagement Methods}"}}