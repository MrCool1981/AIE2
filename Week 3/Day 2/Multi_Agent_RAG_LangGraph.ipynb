{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxpWDFG11o3G"
      },
      "source": [
        "# Multi-Agent Workflows + RAG - LangGraph\n",
        "\n",
        "Today we'll be looking at an example of a Multi-Agent workflow that's powered by LangGraph, LCEL, and more!\n",
        "\n",
        "We're going to be, more specifically, looking at a \"heirarchical agent teams\" from the [AutoGen: Enabling Next-Gen LLM\n",
        "Applications via Multi-Agent Conversation](https://arxiv.org/pdf/2308.08155) paper.\n",
        "\n",
        "This will be the final \"graph\" of our system:\n",
        "\n",
        "![image](https://i.imgur.com/Bhc7RVE.png)\n",
        "\n",
        "It's important to keep in mind that the actual implementation will be constructed of 3 separate graphs, the final one having 2 graphs as nodes! LangGraph is a heckuva tool!\n",
        "\n",
        "> NOTE: We'll be following along with the official LangGraph implementation very closely, which you can find [here](https://github.com/langchain-ai/langgraph/blob/main/examples/multi_agent/hierarchical_agent_teams.ipynb), with some minor modifications and extensions to showcase just how straightforward it is to modify LangGraph implementations to suit your own needs!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx3oaVoX5cA2"
      },
      "source": [
        "## Dependencies\n",
        "\n",
        "We'll start, as we normally do, by grabbing our dependencies.\n",
        "\n",
        "We'll be using LangChain and LangGraph to power our application, so let's start by grabbing those!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cs6HUTgecbzW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU langgraph langchain langchain_openai langchain_experimental"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMzWFUc25oqT"
      },
      "source": [
        "We're going to be showing a simple RAG chain as part of our LangGraph - and so we'll need specific dependencies for that as well!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qEUBCOdukjwc"
      },
      "outputs": [],
      "source": [
        "!pip install -qU --disable-pip-version-check qdrant-client pymupdf tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zpv2MWqu5vS9"
      },
      "source": [
        "Since we'll be relying on OpenAI's suite of models to power our agents today, we'll want to provide our OpenAI API Key.\n",
        "\n",
        "We're also going to be using the Tavily search tool - so we'll want to provide that API key as well!\n",
        "\n",
        "Instruction for how to obtain the Tavily API key can be found:\n",
        "\n",
        "1. [Tavily API Key](https://app.tavily.com/sign-in)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h30OjkLfeR2Y",
        "outputId": "9b1275c1-bf33-4984-ab6f-e27080ef494e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# import getpass\n",
        "# keys saved in environment variables\n",
        "# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
        "# os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"TAVILY_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_LD7rwT6PbO"
      },
      "source": [
        "## Simple LCEL RAG\n",
        "\n",
        "Now that we have our dependencies set-up - let's create a simple RAG chain that works over a single PDF.\n",
        "\n",
        "> NOTE: While this particular example is very straight forward - you can \"plug in\" any complexity of chain you desire as a node in a LangGraph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY7T5kxJ6jGn"
      },
      "source": [
        "## Retrieval\n",
        "\n",
        "The 'R' in 'RAG' - this is, at this point, fairly straightforward!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGuPxSCk7Ztz"
      },
      "source": [
        "#### Data Collection and Processing\n",
        "\n",
        "A classic first step, at this point, let's grab our desired document!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LfuoEYRCln3H"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyMuPDFLoader\n",
        "\n",
        "docs = PyMuPDFLoader(\"https://arxiv.org/pdf/2404.19553\").load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_t_F1zG6vXa"
      },
      "source": [
        "Now we can chunk it down to size!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5R7A_z8CgL79"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "def tiktoken_len(text):\n",
        "    tokens = tiktoken.encoding_for_model(\"gpt-4o-mini\").encode(\n",
        "        text,\n",
        "    )\n",
        "    return len(tokens)\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 300,\n",
        "    chunk_overlap = 0,\n",
        "    length_function = tiktoken_len,\n",
        ")\n",
        "\n",
        "split_chunks = text_splitter.split_documents(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGE-VuMc7AKv"
      },
      "source": [
        "Now we've successfully split our single PDF into..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgYBHsdWmLvW",
        "outputId": "16d5e6f1-46ff-428f-870b-2df570065171"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(split_chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxaKmmyh7DHD"
      },
      "source": [
        "documents!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGWs7KTd7QPS"
      },
      "source": [
        "#### Embedding Model and Vector Store\n",
        "\n",
        "Now that we have our chunked document - lets create a vector store, which will first require us to create an embedding model to get the vector representations of our text!\n",
        "\n",
        "We'll use OpenAI's [`text-embedding-3-small`](https://platform.openai.com/docs/guides/embeddings/embedding-models) model - as it's cheap, and performant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xLIWMMZCmfrj"
      },
      "outputs": [],
      "source": [
        "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
        "\n",
        "embedding_model = AzureOpenAIEmbeddings(azure_deployment=\"text-embedding-3-large\") # using large instead"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTEi7Ww573sc"
      },
      "source": [
        "Now we can create our QDrant backed vector store!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Xct51f8omVAU"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "\n",
        "qdrant_vectorstore = Qdrant.from_documents(\n",
        "    split_chunks,\n",
        "    embedding_model,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"extending_context_window_llama_3\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzGq6o4s79Ar"
      },
      "source": [
        "Let's make sure we can access it as a retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OTnQZbWymi4K"
      },
      "outputs": [],
      "source": [
        "qdrant_retriever = qdrant_vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU8qSrMS7_D7"
      },
      "source": [
        "### Augmented\n",
        "\n",
        "Now that we have our retrieval process set-up, we need to set up our \"augmentation\" process - AKA a prompt template."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lezTN0zCmk46"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_PROMPT = \"\"\"\n",
        "CONTEXT:\n",
        "{context}\n",
        "\n",
        "QUERY:\n",
        "{question}\n",
        "\n",
        "You are a helpful assistant. Use the available context to answer the question. If you can't answer the question, say you don't know.\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9fa63nM7IKK"
      },
      "source": [
        "### Generation\n",
        "\n",
        "Last, but certainly not least, let's put the 'G' in 'RAG' by adding our generator - in this case, we can rely on OpenAI's [`gpt-4o-mini`](https://platform.openai.com/docs/models/gpt-4o-mini) model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "AwEi29-Jo3a8"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import AzureChatOpenAI\n",
        "\n",
        "openai_chat_model = AzureChatOpenAI(azure_deployment=\"gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO-ZC0T98XJJ"
      },
      "source": [
        "### RAG - Retrieval Augmented Generation\n",
        "\n",
        "All that's left to do is combine our R, A, and G into a single chain - and we're off!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nlOJrPm_oT3S"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | qdrant_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | rag_prompt | openai_chat_model | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiWrbXpu8ggz"
      },
      "source": [
        "Let's test this out and make sure it works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "gJhFlW32pBPe",
        "outputId": "9847e13d-7435-4224-d3e5-ac04f8a6f868"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In the context of 'long context' as mentioned in the document, 'context' refers to the amount of text or information that a large language model (LLM) can process at one time. Specifically, it involves the length of the input data, which can include coherent texts such as books or long papers. The document discusses extending the context length of the Llama-3 model from 8K tokens to 80K tokens, allowing it to handle larger amounts of information for tasks like question-answering and data aggregation.\""
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_chain.invoke({\"question\" : \"What does the 'context' in 'long context' refer to?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gReMizYk8qd-"
      },
      "source": [
        "### RAG Limitation\n",
        "\n",
        "Notice how we're hard-coding our data, while this is simply meant to be an illustrative example - you could easily extend this to work with any provied paper or document in order to have a more dynamic system.\n",
        "\n",
        "For now, we'll stick with this single hard-coded example in order to keep complexity down in an already very long notebook!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxkbuir-H5rE"
      },
      "source": [
        "##### 🏗️ Activity #1 (Bonus Marks)\n",
        "\n",
        "Allow the system to dynamically fetch Arxiv papers instead of hard coding them.\n",
        "\n",
        "> HINT: Tuesday's assignment will be very useful here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U6a_pqQ9uWf"
      },
      "source": [
        "## Helper Functions for Agent Graphs\n",
        "\n",
        "We'll be using a number of agents, nodes, and supervisors in the rest of the notebook - and so it will help to have a collection of useful helper functions that we can leverage to make our lives easier going forward.\n",
        "\n",
        "Let's start with the most simple one!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDUnpEEl-L_F"
      },
      "source": [
        "#### Import Wall\n",
        "\n",
        "Here's a wall of imports we'll be needing going forward!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "TbzoL3Q3-SG1"
      },
      "outputs": [],
      "source": [
        "from typing import Any, Callable, List, Optional, TypedDict, Union\n",
        "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
        "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
        "from langchain_core.runnables import Runnable\n",
        "from langchain_core.tools import BaseTool\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "\n",
        "from langgraph.graph import END, StateGraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb6Z3EEz-Asi"
      },
      "source": [
        "### Agent Node Helper\n",
        "\n",
        "Since we're going to be wrapping each of our agents into a node - it will help to have an easy way to create the node!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "5IF7KWfS-JKd"
      },
      "outputs": [],
      "source": [
        "def agent_node(state, agent, name):\n",
        "    result = agent.invoke(state)\n",
        "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwND2teK-WHm"
      },
      "source": [
        "### Agent Creation Helper Function\n",
        "\n",
        "Since we know we'll need to create agents to populate our agent nodes, let's use a helper function for that as well!\n",
        "\n",
        "Notice a few things:\n",
        "\n",
        "1. We have a standard suffix to append to our system messages for each agent to handle the tool calling and boilerplate prompting.\n",
        "2. Each agent has its our scratchpad.\n",
        "3. We're relying on OpenAI's function-calling API for tool selection\n",
        "4. Each agent is its own executor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NxLyHJt5-eUx"
      },
      "outputs": [],
      "source": [
        "def create_agent(\n",
        "    llm: AzureChatOpenAI,\n",
        "    tools: list,\n",
        "    system_prompt: str,\n",
        ") -> str:\n",
        "    \"\"\"Create a function-calling agent and add it to the graph.\"\"\"\n",
        "    system_prompt += (\"\\nWork autonomously according to your specialty, using the tools available to you.\"\n",
        "    \" Do not ask for clarification.\"\n",
        "    \" Your other team members (and other teams) will collaborate with you with their own specialties.\"\n",
        "    \" You are chosen for a reason! You are one of the following team members: {team_members}.\")\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                \"system\",\n",
        "                system_prompt,\n",
        "            ),\n",
        "            MessagesPlaceholder(variable_name=\"messages\"),\n",
        "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "        ]\n",
        "    )\n",
        "    agent = create_openai_functions_agent(llm, tools, prompt)\n",
        "    executor = AgentExecutor(agent=agent, tools=tools)\n",
        "    return executor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6kmlR9d-1K5"
      },
      "source": [
        "### Supervisor Helper Function\n",
        "\n",
        "Finally, we need a \"supervisor\" that decides and routes tasks to specific agents.\n",
        "\n",
        "Since each \"team\" will have a collection of potential agents - this \"supervisor\" will act as an \"intelligent\" router to make sure that the right agent is selected for the right task.\n",
        "\n",
        "Notice that, at the end of the day, this \"supervisor\" is simply directing who acts next - or if the state is considered \"done\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "S2MXA83mrYE2"
      },
      "outputs": [],
      "source": [
        "def create_team_supervisor(llm: AzureChatOpenAI, system_prompt, members) -> str:\n",
        "    \"\"\"An LLM-based router.\"\"\"\n",
        "    options = [\"FINISH\"] + members\n",
        "    function_def = {\n",
        "        \"name\": \"route\",\n",
        "        \"description\": \"Select the next role.\",\n",
        "        \"parameters\": {\n",
        "            \"title\": \"routeSchema\",\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"next\": {\n",
        "                    \"title\": \"Next\",\n",
        "                    \"anyOf\": [\n",
        "                        {\"enum\": options},\n",
        "                    ],\n",
        "                },\n",
        "            },\n",
        "            \"required\": [\"next\"],\n",
        "        },\n",
        "    }\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", system_prompt),\n",
        "            MessagesPlaceholder(variable_name=\"messages\"),\n",
        "            (\n",
        "                \"system\",\n",
        "                \"Given the conversation above, who should act next?\"\n",
        "                \" Or should we FINISH? Select one of: {options}\",\n",
        "            ),\n",
        "        ]\n",
        "    ).partial(options=str(options), team_members=\", \".join(members))\n",
        "    return (\n",
        "        prompt\n",
        "        | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
        "        | JsonOutputFunctionsParser()\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jd0zfyq48jKb"
      },
      "source": [
        "## Research Team - A LangGraph for Researching A Specific Topic\n",
        "\n",
        "Now that we have our RAG chain set-up and some awesome helper functions, we want to create a LangGraph related to researching a specific topic.\n",
        "\n",
        "We're going to start by equipping our Research Team with a few tools:\n",
        "\n",
        "1. Tavily Search - aka \"Google\", for the most up to date information possible.\n",
        "2. Our RAG chain - specific and high quality information about our topic.\n",
        "\n",
        "Let's create those tools now!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNsVTZrH_alw"
      },
      "source": [
        "### Tool Creation\n",
        "\n",
        "As you can see below, some tools already come pre-packaged ready to use!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ce7FKTZDgAWG"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIR7cbTL9agM"
      },
      "source": [
        "Creating a custom tool, however, is very straightforward.\n",
        "\n",
        "> NOTE: You *must* include a docstring, as that is what the LLM will consider when deciding when to use this tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "sSwO2L_UqFhm"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated, List, Tuple, Union\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def retrieve_information(\n",
        "    query: Annotated[str, \"query to ask the retrieve information tool\"]\n",
        "    ):\n",
        "  \"\"\"Use Retrieval Augmented Generation to retrieve information about the 'Extending Llama-3’s Context Ten-Fold Overnight' paper.\"\"\"\n",
        "  return rag_chain.invoke({\"question\" : query})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxsMnqjpBTCj"
      },
      "source": [
        "> NOTE: We could just as easily use the LCEL chain directly, since nodes can be LCEL objects - but creating a tool helps explain the tool creation process at the same time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDHCajO4_gB2"
      },
      "source": [
        "### Research Team State\n",
        "\n",
        "Since we're using LangGraph - we're going to need state!\n",
        "\n",
        "Let's look at how we've created our state below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "mXminK9d_1fa"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "import operator\n",
        "\n",
        "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
        "from langchain_openai.chat_models import AzureChatOpenAI, ChatOpenAI\n",
        "\n",
        "class ResearchTeamState(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], operator.add]\n",
        "    team_members: List[str]\n",
        "    next: str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvPM5msq_18C"
      },
      "source": [
        "Notice how we've used `messages`, `team_members`, and `next`.\n",
        "\n",
        "These states will help us understand:\n",
        "\n",
        "1. What we've done so far (`messages`)\n",
        "2. Which team members we have access to (`team_members`)\n",
        "3. Which team member is up next! (`next`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mu7B_6qHAFjK"
      },
      "source": [
        "### Research Team LLM\n",
        "\n",
        "We'll be using `gpt-4-turbo` today. This LLM is going to be doing a lot of reasoning - and so using a \"powerful\" LLM is very important here!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "dTNqrip8AcKR"
      },
      "outputs": [],
      "source": [
        "# llm = AzureChatOpenAI(azure_deployment=\"gpt-4-turbo\")\n",
        "llm = ChatOpenAI(model=\"gpt-4-turbo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfb_VCNKIy9w"
      },
      "source": [
        "##### ❓ Question #1:\n",
        "\n",
        "Why is a \"powerful\" LLM important for this use-case?\n",
        "\n",
        "What tasks must our Agent perform that make it such that the LLM's reasoning capability is a potential limiter?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ✔️ Answer #1:\n",
        "\n",
        "If I understand correctly, research team LLM will be used in three nodes: Research Team router, Tavily Search agent and RAG agent.\n",
        "- Research Team router is an important task for deciding whether to use Internet search or RAG. This requires decent amount of reasoning capability, however, with just 2 choices I think `gpt-4-o-mini` could be enough.\n",
        "- Tavily Search and RAG agents both require high reasoning capabilities as it is required to reason over chunks of information, choose and pick relevant ones, and analyse/summarise them to produce a response to a user query."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR_1LuMKAekf"
      },
      "source": [
        "### Research Team Agents & Nodes\n",
        "\n",
        "Now we can use our helper functions to create our agent nodes, with their related tools.\n",
        "\n",
        "Let's start with our search agent node."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzx6wuPoAlPq"
      },
      "source": [
        "#### Research Team: Search Agent\n",
        "\n",
        "We're going to give our agent access to the Tavily tool, power it with our GPT-4 Turbo model, and then create its node - and name it `Search`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "FIlLPxj7Atpj"
      },
      "outputs": [],
      "source": [
        "search_agent = create_agent(\n",
        "    llm,\n",
        "    [tavily_tool],\n",
        "    \"You are a research assistant who can search for up-to-date info using the tavily search engine.\",\n",
        ")\n",
        "search_node = functools.partial(agent_node, agent=search_agent, name=\"Search\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emLtesudA9Dd"
      },
      "source": [
        "#### Research Team: RAG Agent Node\n",
        "\n",
        "Now we can wrap our LCEL RAG pipeline in an agent node as well, using the LCEL RAG pipeline as the tool, as created above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "z-nnAG9XA_p7"
      },
      "outputs": [],
      "source": [
        "research_agent = create_agent(\n",
        "    llm,\n",
        "    [retrieve_information],\n",
        "    \"You are a research assistant who can provide specific information on the provided paper: 'Extending Llama-3’s Context Ten-Fold Overnight'. You must only respond with information about the paper related to the request.\",\n",
        ")\n",
        "research_node = functools.partial(agent_node, agent=research_agent, name=\"PaperInformationRetriever\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dA5z6T1CBeSc"
      },
      "source": [
        "### Research Team Supervisor Agent\n",
        "\n",
        "Notice that we're not yet creating our supervisor *node*, simply the agent here.\n",
        "\n",
        "Also notice how we need to provide a few extra pieces of information - including which tools we're using.\n",
        "\n",
        "> NOTE: It's important to use the *exact* tool name, as that is how the LLM will reference the tool. Also, it's important that your tool name is all a single alphanumeric string!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "J0g8CQMBrtFs"
      },
      "outputs": [],
      "source": [
        "supervisor_agent = create_team_supervisor(\n",
        "    llm,\n",
        "    (\"You are a supervisor tasked with managing a conversation between the\"\n",
        "    \" following workers:  Search, PaperInformationRetriever. Given the following user request,\"\n",
        "    \" determine the subject to be researched and respond with the worker to act next. Each worker will perform a\"\n",
        "    \" task and respond with their results and status. \"\n",
        "    \" You should never ask your team to do anything beyond research. They are not required to write content or posts.\"\n",
        "    \" You should only pass tasks to workers that are specifically research focused.\"\n",
        "    \" When finished, respond with FINISH.\"),\n",
        "    [\"Search\", \"PaperInformationRetriever\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qohn0DcgB_U1"
      },
      "source": [
        "### Research Team Graph Creation\n",
        "\n",
        "Now that we have our research team agent nodes created, and our supervisor agent - let's finally construct our graph!\n",
        "\n",
        "We'll start by creating our base graph from our state, and then adding the nodes/agent we've created as nodes on our LangGraph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "p0s2GAgJCN8G"
      },
      "outputs": [],
      "source": [
        "research_graph = StateGraph(ResearchTeamState)\n",
        "\n",
        "research_graph.add_node(\"Search\", search_node)\n",
        "research_graph.add_node(\"PaperInformationRetriever\", research_node)\n",
        "research_graph.add_node(\"supervisor\", supervisor_agent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33qixRGNCaAX"
      },
      "source": [
        "Now we can define our edges - include our conditional edge from our supervisor to our agent nodes.\n",
        "\n",
        "Notice how we're always routing our agent nodes back to our supervisor!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "yYSJIhijsGyg"
      },
      "outputs": [],
      "source": [
        "research_graph.add_edge(\"Search\", \"supervisor\")\n",
        "research_graph.add_edge(\"PaperInformationRetriever\", \"supervisor\")\n",
        "research_graph.add_conditional_edges(\n",
        "    \"supervisor\",\n",
        "    lambda x: x[\"next\"],\n",
        "    {\"Search\": \"Search\", \"PaperInformationRetriever\": \"PaperInformationRetriever\", \"FINISH\": END},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgGcuZzkCj1-"
      },
      "source": [
        "Now we can set our supervisor node as the entry point, and compile our graph!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "1l-1I2Z3CnPX"
      },
      "outputs": [],
      "source": [
        "research_graph.set_entry_point(\"supervisor\")\n",
        "chain = research_graph.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDwQpYTSEY13"
      },
      "source": [
        "#### Display Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "pzRE5ldzFlLQ"
      },
      "outputs": [],
      "source": [
        "!pip install -qU python_mermaid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "l8n6SXhpEa2b",
        "outputId": "7bdb0c10-9bfe-4b5b-a812-0b01ba66dda9"
      },
      "outputs": [
        {
          "data": {
            "image/jpeg": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(chain.get_graph(xray=True).draw_mermaid_png()))\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfRvA2QfCqFL"
      },
      "source": [
        "The next part is key - since we need to \"wrap\" our LangGraph in order for it to be compatible in the following steps - let's create an LCEL chain out of it!\n",
        "\n",
        "This allows us to \"broadcast\" messages down to our Research Team LangGraph!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "1G7hmEINCx3i"
      },
      "outputs": [],
      "source": [
        "def enter_chain(message: str):\n",
        "    results = {\n",
        "        \"messages\": [HumanMessage(content=message)],\n",
        "    }\n",
        "    return results\n",
        "\n",
        "research_chain = enter_chain | chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGdoCdXWC7Pi"
      },
      "source": [
        "Now, finally, we can take it for a spin!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIDpFIg2sRUl",
        "outputId": "8cf7eb77-d6bb-4646-b45d-35c04cbd3cbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'supervisor': {'next': 'Search'}}\n",
            "---\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "\"Input to ChatPromptTemplate is missing variables {'team_members'}.  Expected: ['agent_scratchpad', 'messages', 'team_members'] Received: ['messages', 'next', 'intermediate_steps', 'agent_scratchpad']\\nNote: if you intended {team_members} to be part of the string and not a variable, please escape it with double curly braces like: '{{team_members}}'.\"",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[88], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresearch_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat are the main takeaways from the paper `Extending Llama-3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms Context Ten-Fold Overnight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m? Please use Search and PaperInformationRetriever!\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecursion_limit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m__end__\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3396\u001b[0m, in \u001b[0;36mRunnableSequence.stream\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream\u001b[39m(\n\u001b[0;32m   3391\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3392\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   3393\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3394\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   3395\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 3396\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3383\u001b[0m, in \u001b[0;36mRunnableSequence.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[0;32m   3378\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3379\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[0;32m   3380\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3381\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   3382\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 3383\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[0;32m   3384\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   3385\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform,\n\u001b[0;32m   3386\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m   3387\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3388\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2186\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[1;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   2184\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2185\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 2186\u001b[0m         chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   2187\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[0;32m   2188\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3346\u001b[0m, in \u001b[0;36mRunnableSequence._transform\u001b[1;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[0;32m   3343\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3344\u001b[0m         final_pipeline \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39mtransform(final_pipeline, config)\n\u001b[1;32m-> 3346\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m final_pipeline\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1420\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   1417\u001b[0m             final \u001b[38;5;241m=\u001b[39m ichunk\n\u001b[0;32m   1419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[1;32m-> 1420\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(final, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1222\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1211\u001b[0m \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   1217\u001b[0m     input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels,\n\u001b[0;32m   1218\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   1219\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   1220\u001b[0m     manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[0;32m   1221\u001b[0m ):\n\u001b[1;32m-> 1222\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[0;32m   1228\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langgraph\\pregel\\runner.py:94\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_futures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpanic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langgraph\\pregel\\runner.py:210\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[1;34m(futs, timeout_exc_cls, panic)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m panic:\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langgraph\\pregel\\executor.py:61\u001b[0m, in \u001b[0;36mBackgroundExecutor.done\u001b[1;34m(self, task)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdone\u001b[39m(\u001b[38;5;28mself\u001b[39m, task: concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mFuture) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 61\u001b[0m         \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m GraphInterrupt:\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;66;03m# This exception is an interruption signal, not an error\u001b[39;00m\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;66;03m# so we don't want to re-raise it on exit\u001b[39;00m\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mpop(task)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langgraph\\pregel\\retry.py:26\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy)\u001b[0m\n\u001b[0;32m     24\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langgraph\\utils\\runnable.py:343\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    341\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 343\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langgraph\\utils\\runnable.py:131\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 131\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "Cell \u001b[1;32mIn[15], line 2\u001b[0m, in \u001b[0;36magent_node\u001b[1;34m(state, agent, name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magent_node\u001b[39m(state, agent, name):\n\u001b[1;32m----> 2\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [HumanMessage(content\u001b[38;5;241m=\u001b[39mresult[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m], name\u001b[38;5;241m=\u001b[39mname)]}\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain\\chains\\base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain\\chains\\base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    167\u001b[0m     )\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain\\agents\\agent.py:1629\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m   1627\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m   1628\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m-> 1629\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1635\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1636\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m   1637\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[0;32m   1638\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[0;32m   1639\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain\\agents\\agent.py:1335\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1328\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1332\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1333\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m   1334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1335\u001b[0m         \u001b[43m[\u001b[49m\n\u001b[0;32m   1336\u001b[0m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[0;32m   1337\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1338\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1339\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1340\u001b[0m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1341\u001b[0m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1342\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1343\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1345\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain\\agents\\agent.py:1363\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1360\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[0;32m   1362\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m-> 1363\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_action_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1367\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1368\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1369\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain\\agents\\agent.py:464\u001b[0m, in \u001b[0;36mRunnableAgent.plan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    456\u001b[0m final_output: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_runnable:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;66;03m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;66;03m# streaming\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;66;03m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;66;03m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[1;32m--> 464\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunnable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfinal_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3396\u001b[0m, in \u001b[0;36mRunnableSequence.stream\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream\u001b[39m(\n\u001b[0;32m   3391\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3392\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   3393\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3394\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   3395\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 3396\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3383\u001b[0m, in \u001b[0;36mRunnableSequence.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[0;32m   3378\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3379\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[0;32m   3380\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3381\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   3382\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 3383\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[0;32m   3384\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   3385\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform,\n\u001b[0;32m   3386\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m   3387\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3388\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2186\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[1;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   2184\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2185\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 2186\u001b[0m         chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   2187\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[0;32m   2188\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3346\u001b[0m, in \u001b[0;36mRunnableSequence._transform\u001b[1;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[0;32m   3343\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3344\u001b[0m         final_pipeline \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39mtransform(final_pipeline, config)\n\u001b[1;32m-> 3346\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m final_pipeline\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1402\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   1399\u001b[0m final: Input\n\u001b[0;32m   1400\u001b[0m got_first_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1402\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# The default implementation of transform is to buffer input and\u001b[39;49;00m\n\u001b[0;32m   1404\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# then call stream.\u001b[39;49;00m\n\u001b[0;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# It'll attempt to gather all input into a single chunk using\u001b[39;49;00m\n\u001b[0;32m   1406\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# the `+` operator.\u001b[39;49;00m\n\u001b[0;32m   1407\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If the input is not addable, then we'll assume that we can\u001b[39;49;00m\n\u001b[0;32m   1408\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# only operate on the last chunk,\u001b[39;49;00m\n\u001b[0;32m   1409\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# and we'll iterate until we get to the last chunk.\u001b[39;49;00m\n\u001b[0;32m   1410\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgot_first_val\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5520\u001b[0m, in \u001b[0;36mRunnableBindingBase.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[0;32m   5515\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5516\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[0;32m   5517\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5518\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   5519\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 5520\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[0;32m   5521\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5522\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5523\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5524\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1402\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   1399\u001b[0m final: Input\n\u001b[0;32m   1400\u001b[0m got_first_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1402\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# The default implementation of transform is to buffer input and\u001b[39;49;00m\n\u001b[0;32m   1404\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# then call stream.\u001b[39;49;00m\n\u001b[0;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# It'll attempt to gather all input into a single chunk using\u001b[39;49;00m\n\u001b[0;32m   1406\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# the `+` operator.\u001b[39;49;00m\n\u001b[0;32m   1407\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If the input is not addable, then we'll assume that we can\u001b[39;49;00m\n\u001b[0;32m   1408\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# only operate on the last chunk,\u001b[39;49;00m\n\u001b[0;32m   1409\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# and we'll iterate until we get to the last chunk.\u001b[39;49;00m\n\u001b[0;32m   1410\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgot_first_val\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1420\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   1417\u001b[0m             final \u001b[38;5;241m=\u001b[39m ichunk\n\u001b[0;32m   1419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[1;32m-> 1420\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(final, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\runnables\\base.py:986\u001b[0m, in \u001b[0;36mRunnable.stream\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream\u001b[39m(\n\u001b[0;32m    969\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    970\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m    971\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    972\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m    973\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m    974\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;124;03m    Default implementation of stream, which calls invoke.\u001b[39;00m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;124;03m    Subclasses should override this method if they support streaming output.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;124;03m        The output of the Runnable.\u001b[39;00m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 986\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\prompts\\base.py:193\u001b[0m, in \u001b[0;36mBasePromptTemplate.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags:\n\u001b[0;32m    192\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags\n\u001b[1;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_prompt_with_error_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserialized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serialized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1916\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[0;32m   1912\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   1913\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[0;32m   1914\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1915\u001b[0m         Output,\n\u001b[1;32m-> 1916\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1917\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1918\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1919\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1920\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1921\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1922\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1923\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1924\u001b[0m     )\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1926\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\runnables\\config.py:398\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    397\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\prompts\\base.py:167\u001b[0m, in \u001b[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001b[1;34m(self, inner_input)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_format_prompt_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, inner_input: Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[1;32m--> 167\u001b[0m     _inner_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_prompt(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_inner_input)\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\prompts\\base.py:163\u001b[0m, in \u001b[0;36mBasePromptTemplate._validate_input\u001b[1;34m(self, inner_input)\u001b[0m\n\u001b[0;32m    157\u001b[0m     example_key \u001b[38;5;241m=\u001b[39m missing\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m    158\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNote: if you intended \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m to be part of the string\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and not a variable, please escape it with double curly braces like: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    162\u001b[0m     )\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(msg)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inner_input\n",
            "\u001b[1;31mKeyError\u001b[0m: \"Input to ChatPromptTemplate is missing variables {'team_members'}.  Expected: ['agent_scratchpad', 'messages', 'team_members'] Received: ['messages', 'next', 'intermediate_steps', 'agent_scratchpad']\\nNote: if you intended {team_members} to be part of the string and not a variable, please escape it with double curly braces like: '{{team_members}}'.\""
          ]
        }
      ],
      "source": [
        "for s in research_chain.stream(\n",
        "    \"What are the main takeaways from the paper `Extending Llama-3's Context Ten-Fold Overnight'? Please use Search and PaperInformationRetriever!\", \n",
        "    {\"recursion_limit\": 100}\n",
        "):\n",
        "    if \"__end__\" not in s:\n",
        "        print(s)\n",
        "        print(\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Comments\n",
        "\n",
        "I could not fix the error, cannot understand where it originates from.\n",
        "I tried:\n",
        "- creating a new virtual python environment as I thought it could be a problem with conflicting packages\n",
        "- tried different models in Azure OpenAI\n",
        "- tried running with the suggested model for OpenAI API\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHAgsbwIIhwj"
      },
      "source": [
        "##### 🏗️ Activity #2:\n",
        "\n",
        "Using whatever drawing application you wish - please label the flow above on a diagram of your graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ✔️ Answer Activity 2:\n",
        "\n",
        "I do not understand the task. Label with what? The diagram seems to be self-explanatory.\n",
        "\n",
        "If you mean label with the messages that we supposed to be generated in the cell above, then the code does not work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH70eHGlJbq4"
      },
      "source": [
        "##### ❓ Question #2:\n",
        "\n",
        "How could you make sure your Agent uses specific tools that you wish it to use? Are there any ways to concretely set a flow through tools?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ✔️ Answer Question 2:\n",
        "\n",
        "We could:\n",
        "- Create a very comprehensive system message for an agent specifying how to choose tools correctly\n",
        "- Fine-tune a model to choose correct tools\n",
        "- Lower tempreature or/and set a seed for OpenAI models\n",
        "- Use another model within a node or extra node that checks a choice of tools\n",
        "- To set a flow through tools we could use conditional edges and hard code logic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejsHCZZ2EmwM"
      },
      "source": [
        "## Document Writing Team - A LangGraph for Writing, Editing, and Planning a LinkedIn post.\n",
        "\n",
        "Let's run it all back, this time specifically creating tools, agent nodes, and a graph for planning, writing, and editing a LinkedIn post!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4awQtZ-oFUN-"
      },
      "source": [
        "### Tool Creation\n",
        "\n",
        "Let's create some tools that will help us understand, open, work with, and edit documents to our liking!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "ptXilgparOkq"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from tempfile import TemporaryDirectory\n",
        "from typing import Dict, Optional\n",
        "from typing_extensions import TypedDict\n",
        "import uuid\n",
        "import os\n",
        "\n",
        "os.makedirs('/content/data', exist_ok=True)\n",
        "\n",
        "def create_random_subdirectory():\n",
        "    random_id = str(uuid.uuid4())[:8]  # Use first 8 characters of a UUID\n",
        "    subdirectory_path = os.path.join('/content/data', random_id)\n",
        "    os.makedirs(subdirectory_path, exist_ok=True)\n",
        "    return subdirectory_path\n",
        "\n",
        "WORKING_DIRECTORY = Path(create_random_subdirectory())\n",
        "\n",
        "@tool\n",
        "def create_outline(\n",
        "    points: Annotated[List[str], \"List of main points or sections.\"],\n",
        "    file_name: Annotated[str, \"File path to save the outline.\"],\n",
        ") -> Annotated[str, \"Path of the saved outline file.\"]:\n",
        "    \"\"\"Create and save an outline.\"\"\"\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
        "        for i, point in enumerate(points):\n",
        "            file.write(f\"{i + 1}. {point}\\n\")\n",
        "    return f\"Outline saved to {file_name}\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def read_document(\n",
        "    file_name: Annotated[str, \"File path to save the document.\"],\n",
        "    start: Annotated[Optional[int], \"The start line. Default is 0\"] = None,\n",
        "    end: Annotated[Optional[int], \"The end line. Default is None\"] = None,\n",
        ") -> str:\n",
        "    \"\"\"Read the specified document.\"\"\"\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
        "        lines = file.readlines()\n",
        "    if start is not None:\n",
        "        start = 0\n",
        "    return \"\\n\".join(lines[start:end])\n",
        "\n",
        "\n",
        "@tool\n",
        "def write_document(\n",
        "    content: Annotated[str, \"Text content to be written into the document.\"],\n",
        "    file_name: Annotated[str, \"File path to save the document.\"],\n",
        ") -> Annotated[str, \"Path of the saved document file.\"]:\n",
        "    \"\"\"Create and save a text document.\"\"\"\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
        "        file.write(content)\n",
        "    return f\"Document saved to {file_name}\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def edit_document(\n",
        "    file_name: Annotated[str, \"Path of the document to be edited.\"],\n",
        "    inserts: Annotated[\n",
        "        Dict[int, str],\n",
        "        \"Dictionary where key is the line number (1-indexed) and value is the text to be inserted at that line.\",\n",
        "    ] = {},\n",
        ") -> Annotated[str, \"Path of the edited document file.\"]:\n",
        "    \"\"\"Edit a document by inserting text at specific line numbers.\"\"\"\n",
        "\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    sorted_inserts = sorted(inserts.items())\n",
        "\n",
        "    for line_number, text in sorted_inserts:\n",
        "        if 1 <= line_number <= len(lines) + 1:\n",
        "            lines.insert(line_number - 1, text + \"\\n\")\n",
        "        else:\n",
        "            return f\"Error: Line number {line_number} is out of range.\"\n",
        "\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
        "        file.writelines(lines)\n",
        "\n",
        "    return f\"Document edited and saved to {file_name}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8yH1IAYK7nL"
      },
      "source": [
        "##### 🏗️ Activity #3:\n",
        "\n",
        "Describe, briefly, what each of these tools is doing in your own words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ✔️ Answer Activity 3:\n",
        "\n",
        "1. **Tool: `create_outline`:**\n",
        "    - This function creates an outline from a list of points and saves it to a specified file within the working directory.\n",
        "\n",
        "2. **Tool: `read_document`:**\n",
        "     - This function reads a document from the working directory, optionally from a specified range of lines, and returns the content as a string.\n",
        "\n",
        "3. **Tool: `write_document`:**\n",
        "    - This function writes given text content to a specified file within the working directory and returns the path of the saved document.\n",
        "\n",
        "4. **Tool: `edit_document`:**\n",
        "    - This function edits a document by inserting specified text at given line numbers. It reads the document, applies the inserts, and then saves the edited document back to the working directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__Jw_XBIFwwa"
      },
      "source": [
        "### Document Writing State\n",
        "\n",
        "Just like with our Research Team state - we want to keep track of a few things, however this time - we also want to keep track of which files we've created - so let's add that here!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "DoU2YwJRu7wD"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "from pathlib import Path\n",
        "\n",
        "class DocWritingState(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], operator.add]\n",
        "    team_members: str\n",
        "    next: str\n",
        "    current_files: str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p1kQShmGHCh"
      },
      "source": [
        "### Document Writing Prelude Function\n",
        "\n",
        "Since we have a working directory - we want to be clear about what our current working directory looks like - this helper function will allow us to do that cleanly!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "G79mUggQGLVq"
      },
      "outputs": [],
      "source": [
        "def prelude(state):\n",
        "    written_files = []\n",
        "    if not WORKING_DIRECTORY.exists():\n",
        "        WORKING_DIRECTORY.mkdir()\n",
        "    try:\n",
        "        written_files = [\n",
        "            f.relative_to(WORKING_DIRECTORY) for f in WORKING_DIRECTORY.rglob(\"*\")\n",
        "        ]\n",
        "    except:\n",
        "        pass\n",
        "    if not written_files:\n",
        "        return {**state, \"current_files\": \"No files written.\"}\n",
        "    return {\n",
        "        **state,\n",
        "        \"current_files\": \"\\nBelow are files your team has written to the directory:\\n\"\n",
        "        + \"\\n\".join([f\" - {f}\" for f in written_files]),\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbSre9agT9Gb"
      },
      "source": [
        "### Document Writing Node Creation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "v7oso327T_wa"
      },
      "outputs": [],
      "source": [
        "doc_writer_agent = create_agent(\n",
        "    llm,\n",
        "    [write_document, edit_document, read_document],\n",
        "    (\"You are an expert writing technical LinkedIn posts.\\n\"\n",
        "    \"Below are files currently in your directory:\\n{current_files}\"),\n",
        ")\n",
        "context_aware_doc_writer_agent = prelude | doc_writer_agent\n",
        "doc_writing_node = functools.partial(\n",
        "    agent_node, agent=context_aware_doc_writer_agent, name=\"DocWriter\"\n",
        ")\n",
        "\n",
        "note_taking_agent = create_agent(\n",
        "    llm,\n",
        "    [create_outline, read_document],\n",
        "    (\"You are an expert senior researcher tasked with writing a LinkedIn post outline and\"\n",
        "    \" taking notes to craft a LinkedIn post.\\n{current_files}\"),\n",
        ")\n",
        "context_aware_note_taking_agent = prelude | note_taking_agent\n",
        "note_taking_node = functools.partial(\n",
        "    agent_node, agent=context_aware_note_taking_agent, name=\"NoteTaker\"\n",
        ")\n",
        "\n",
        "copy_editor_agent = create_agent(\n",
        "    llm,\n",
        "    [write_document, edit_document, read_document],\n",
        "    (\"You are an expert copy editor who focuses on fixing grammar, spelling, and tone issues\\n\"\n",
        "    \"Below are files currently in your directory:\\n{current_files}\"),\n",
        ")\n",
        "context_aware_copy_editor_agent = prelude | copy_editor_agent\n",
        "copy_editing_node = functools.partial(\n",
        "    agent_node, agent=context_aware_copy_editor_agent, name=\"CopyEditor\"\n",
        ")\n",
        "\n",
        "dopeness_editor_agent = create_agent(\n",
        "    llm,\n",
        "    [write_document, edit_document, read_document],\n",
        "    (\"You are an expert in dopeness, litness, coolness, etc - you edit the document to make sure it's dope.\"\n",
        "    \"Below are files currently in your directory:\\n{current_files}\"),\n",
        ")\n",
        "context_aware_dopeness_editor_agent = prelude | dopeness_editor_agent\n",
        "dopeness_node = functools.partial(\n",
        "    agent_node, agent=context_aware_dopeness_editor_agent, name=\"DopenessEditor\"\n",
        ")\n",
        "\n",
        "doc_writing_supervisor = create_team_supervisor(\n",
        "    llm,\n",
        "    (\"You are a supervisor tasked with managing a conversation between the\"\n",
        "    \" following workers: {team_members}. You should always verify the technical\"\n",
        "    \" contents after any edits are made. \"\n",
        "    \"Given the following user request,\"\n",
        "    \" respond with the worker to act next. Each worker will perform a\"\n",
        "    \" task and respond with their results and status. When each team is finished,\"\n",
        "    \" you must respond with FINISH.\"),\n",
        "    [\"DocWriter\", \"NoteTaker\", \"DopenessEditor\", \"CopyEditor\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUiNMpJBGXN0"
      },
      "source": [
        "### Document Writing Team LangGraph Construction\n",
        "\n",
        "This part is almost exactly the same (with a few extra nodes) as our Research Team LangGraph construction - so we'll leave it as one block!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "Q6n8A1ytxVTv"
      },
      "outputs": [],
      "source": [
        "authoring_graph = StateGraph(DocWritingState)\n",
        "authoring_graph.add_node(\"DocWriter\", doc_writing_node)\n",
        "authoring_graph.add_node(\"NoteTaker\", note_taking_node)\n",
        "authoring_graph.add_node(\"CopyEditor\", copy_editing_node)\n",
        "authoring_graph.add_node(\"DopenessEditor\", dopeness_node)\n",
        "authoring_graph.add_node(\"supervisor\", doc_writing_supervisor)\n",
        "\n",
        "authoring_graph.add_edge(\"DocWriter\", \"supervisor\")\n",
        "authoring_graph.add_edge(\"NoteTaker\", \"supervisor\")\n",
        "authoring_graph.add_edge(\"CopyEditor\", \"supervisor\")\n",
        "authoring_graph.add_edge(\"DopenessEditor\", \"supervisor\")\n",
        "\n",
        "authoring_graph.add_conditional_edges(\n",
        "    \"supervisor\",\n",
        "    lambda x: x[\"next\"],\n",
        "    {\n",
        "        \"DocWriter\": \"DocWriter\",\n",
        "        \"NoteTaker\": \"NoteTaker\",\n",
        "        \"CopyEditor\" : \"CopyEditor\",\n",
        "        \"DopenessEditor\" : \"DopenessEditor\",\n",
        "        \"FINISH\": END,\n",
        "    },\n",
        ")\n",
        "\n",
        "authoring_graph.set_entry_point(\"supervisor\")\n",
        "chain = authoring_graph.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx-EKGkHKUBO"
      },
      "source": [
        "#### Display Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "AZdOb3GZKSM7",
        "outputId": "74490792-5ba5-43fd-e28d-28c4740c52a8"
      },
      "outputs": [
        {
          "data": {
            "image/jpeg": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(chain.get_graph(xray=True).draw_mermaid_png()))\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yB_rOw1hGpwd"
      },
      "source": [
        "Just as before - we'll need to create an \"interface\" between the level above, and our graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "G-RbbCKoG_nt"
      },
      "outputs": [],
      "source": [
        "def enter_chain(message: str, members: List[str]):\n",
        "    results = {\n",
        "        \"messages\": [HumanMessage(content=message)],\n",
        "        \"team_members\": \", \".join(members),\n",
        "    }\n",
        "    return results\n",
        "\n",
        "authoring_chain = (\n",
        "    functools.partial(enter_chain, members=authoring_graph.nodes)\n",
        "    | authoring_graph.compile()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgyhpTrRNgQd"
      },
      "source": [
        "Now we can test this out!\n",
        "\n",
        "> NOTE: It is possible you may see an error here - rerun the cell to clear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWUxv4XDx3kg",
        "outputId": "1d626a44-3ad2-44dc-fe12-7850777d062f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'supervisor': {'next': 'DocWriter'}}\n",
            "---\n",
            "{'DocWriter': {'messages': [HumanMessage(content='The outline for a LinkedIn post on Linear Regression has been successfully created and saved to disk with the filename \"LinkedIn_Post_Outline_Linear_Regression.txt\". This outline covers an introduction to Linear Regression, its key components, applications, advantages, challenges, and a conclusion to wrap up the post.', additional_kwargs={}, response_metadata={}, name='DocWriter')]}}\n",
            "---\n",
            "{'supervisor': {'next': 'FINISH'}}\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "for s in authoring_chain.stream(\n",
        "    \"Write an outline for for a short LinkedIn post on Linear Regression and write it to disk.\",\n",
        "    {\"recursion_limit\": 100},\n",
        "):\n",
        "    if \"__end__\" not in s:\n",
        "        print(s)\n",
        "        print(\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpW2R9SUHGUq"
      },
      "source": [
        "## Meta-Supervisor\n",
        "\n",
        "Finally, now that we have our two LangGraph agents (some of which are already multi-agent), we can build a supervisor that sits above all of them!\n",
        "\n",
        "The final process, surprisingly, is quite straight forward!\n",
        "\n",
        "Let's jump in!\n",
        "\n",
        "First off - we'll need to create our supervisor agent node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "wkpxeUf9ygKp"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
        "from langchain_openai.chat_models import AzureChatOpenAI\n",
        "\n",
        "\n",
        "llm = AzureChatOpenAI(azure_deployment=\"gpt-4\") # using GPT-4o model from Azure OpenAI\n",
        "\n",
        "supervisor_node = create_team_supervisor(\n",
        "    llm,\n",
        "    \"You are a supervisor tasked with managing a conversation between the\"\n",
        "    \" following teams: {team_members}. Given the following user request,\"\n",
        "    \" respond with the worker to act next. Each worker will perform a\"\n",
        "    \" task and respond with their results and status. When all workers are finished,\"\n",
        "    \" you must respond with FINISH.\",\n",
        "    [\"Research team\", \"LinkedIn team\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUvOh_xWIKig"
      },
      "source": [
        "We'll also create our new state - as well as some methods to help us navigate the new state and the subgraphs.\n",
        "\n",
        "> NOTE: We only pass the most recent message from the parent graph to the subgraph, and we only extract the most recent message from the subgraph to include in the state of the parent graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "O7HJ8MF0yh_i"
      },
      "outputs": [],
      "source": [
        "class State(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], operator.add]\n",
        "    next: str\n",
        "\n",
        "def get_last_message(state: State) -> str:\n",
        "    return state[\"messages\"][-1].content\n",
        "\n",
        "def join_graph(response: dict):\n",
        "    return {\"messages\": [response[\"messages\"][-1]]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5RHao1sIanG"
      },
      "source": [
        "Next, we'll create our base graph.\n",
        "\n",
        "Notice how each node we're adding is *AN ENTIRE LANGGRAPH AGENT* (wrapped into an LCEL chain with our helper functions above)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "PfCWABCMIaFy"
      },
      "outputs": [],
      "source": [
        "super_graph = StateGraph(State)\n",
        "\n",
        "super_graph.add_node(\"Research team\", get_last_message | research_chain | join_graph)\n",
        "super_graph.add_node(\n",
        "    \"LinkedIn team\", get_last_message | authoring_chain | join_graph\n",
        ")\n",
        "super_graph.add_node(\"supervisor\", supervisor_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpwpUXMtI62E"
      },
      "source": [
        "Next, we'll create our edges!\n",
        "\n",
        "This process is completely idenctical to what we've seen before - just addressing the LangGraph subgraph nodes instead of individual nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "tLtjRuUYI-fx"
      },
      "outputs": [],
      "source": [
        "super_graph.add_edge(\"Research team\", \"supervisor\")\n",
        "super_graph.add_edge(\"LinkedIn team\", \"supervisor\")\n",
        "super_graph.add_conditional_edges(\n",
        "    \"supervisor\",\n",
        "    lambda x: x[\"next\"],\n",
        "    {\n",
        "        \"LinkedIn team\": \"LinkedIn team\",\n",
        "        \"Research team\": \"Research team\",\n",
        "        \"FINISH\": END,\n",
        "    },\n",
        ")\n",
        "super_graph.set_entry_point(\"supervisor\")\n",
        "super_graph = super_graph.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1KMfFqgJKw8"
      },
      "source": [
        "That's it!\n",
        "\n",
        "Now we can finally use our full agent!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M6wUDR-yk8s",
        "outputId": "c21fbc33-1031-400b-aaa2-ec799a23a682"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'supervisor': {'next': 'Research team'}}\n",
            "---\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "\"Input to ChatPromptTemplate is missing variables {'team_members'}.  Expected: ['agent_scratchpad', 'messages', 'team_members'] Received: ['messages', 'next', 'intermediate_steps', 'agent_scratchpad']\\nNote: if you intended {team_members} to be part of the string and not a variable, please escape it with double curly braces like: '{{team_members}}'.\"",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[79], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msuper_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWrite a LinkedIn post on the paper \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mExtending Llama-3’s Context Ten-Fold Overnight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m. First consult the research team. Then make sure you consult the LinkedIn team, and check for copy editing and dopeness, and write the file to disk.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecursion_limit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m__end__\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1222\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1211\u001b[0m \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   1217\u001b[0m     input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels,\n\u001b[0;32m   1218\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   1219\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   1220\u001b[0m     manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[0;32m   1221\u001b[0m ):\n\u001b[1;32m-> 1222\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[0;32m   1228\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langgraph\\pregel\\runner.py:94\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_futures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpanic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langgraph\\pregel\\runner.py:210\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[1;34m(futs, timeout_exc_cls, panic)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m panic:\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langgraph\\pregel\\executor.py:61\u001b[0m, in \u001b[0;36mBackgroundExecutor.done\u001b[1;34m(self, task)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdone\u001b[39m(\u001b[38;5;28mself\u001b[39m, task: concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mFuture) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 61\u001b[0m         \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m GraphInterrupt:\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;66;03m# This exception is an interruption signal, not an error\u001b[39;00m\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;66;03m# so we don't want to re-raise it on exit\u001b[39;00m\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mpop(task)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langgraph\\pregel\\retry.py:26\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy)\u001b[0m\n\u001b[0;32m     24\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langgraph\\utils\\runnable.py:345\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    344\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 345\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1468\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1467\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1468\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1469\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1470\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1471\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1472\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1473\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1474\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1476\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1477\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1478\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1222\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1211\u001b[0m \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   1217\u001b[0m     input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels,\n\u001b[0;32m   1218\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   1219\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   1220\u001b[0m     manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[0;32m   1221\u001b[0m ):\n\u001b[1;32m-> 1222\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[0;32m   1228\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langgraph\\pregel\\runner.py:94\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_futures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpanic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langgraph\\pregel\\runner.py:210\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[1;34m(futs, timeout_exc_cls, panic)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m panic:\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langgraph\\pregel\\executor.py:61\u001b[0m, in \u001b[0;36mBackgroundExecutor.done\u001b[1;34m(self, task)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdone\u001b[39m(\u001b[38;5;28mself\u001b[39m, task: concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mFuture) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 61\u001b[0m         \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m GraphInterrupt:\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;66;03m# This exception is an interruption signal, not an error\u001b[39;00m\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;66;03m# so we don't want to re-raise it on exit\u001b[39;00m\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mpop(task)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langgraph\\pregel\\retry.py:26\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy)\u001b[0m\n\u001b[0;32m     24\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langgraph\\utils\\runnable.py:343\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    341\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 343\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langgraph\\utils\\runnable.py:131\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 131\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "Cell \u001b[1;32mIn[15], line 2\u001b[0m, in \u001b[0;36magent_node\u001b[1;34m(state, agent, name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magent_node\u001b[39m(state, agent, name):\n\u001b[1;32m----> 2\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [HumanMessage(content\u001b[38;5;241m=\u001b[39mresult[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m], name\u001b[38;5;241m=\u001b[39mname)]}\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain\\chains\\base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain\\chains\\base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    167\u001b[0m     )\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain\\agents\\agent.py:1629\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m   1627\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m   1628\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m-> 1629\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1635\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1636\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m   1637\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[0;32m   1638\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[0;32m   1639\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain\\agents\\agent.py:1335\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1328\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1332\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1333\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m   1334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1335\u001b[0m         \u001b[43m[\u001b[49m\n\u001b[0;32m   1336\u001b[0m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[0;32m   1337\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1338\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1339\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1340\u001b[0m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1341\u001b[0m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1342\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1343\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1345\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain\\agents\\agent.py:1363\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1360\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[0;32m   1362\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m-> 1363\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_action_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1367\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1368\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1369\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain\\agents\\agent.py:464\u001b[0m, in \u001b[0;36mRunnableAgent.plan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    456\u001b[0m final_output: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_runnable:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;66;03m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;66;03m# streaming\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;66;03m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;66;03m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[1;32m--> 464\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunnable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfinal_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3396\u001b[0m, in \u001b[0;36mRunnableSequence.stream\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream\u001b[39m(\n\u001b[0;32m   3391\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3392\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   3393\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3394\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   3395\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 3396\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3383\u001b[0m, in \u001b[0;36mRunnableSequence.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[0;32m   3378\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3379\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[0;32m   3380\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3381\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   3382\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 3383\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[0;32m   3384\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   3385\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform,\n\u001b[0;32m   3386\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m   3387\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3388\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2186\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[1;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   2184\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2185\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 2186\u001b[0m         chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   2187\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[0;32m   2188\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3346\u001b[0m, in \u001b[0;36mRunnableSequence._transform\u001b[1;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[0;32m   3343\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3344\u001b[0m         final_pipeline \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39mtransform(final_pipeline, config)\n\u001b[1;32m-> 3346\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m final_pipeline\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1402\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   1399\u001b[0m final: Input\n\u001b[0;32m   1400\u001b[0m got_first_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1402\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# The default implementation of transform is to buffer input and\u001b[39;49;00m\n\u001b[0;32m   1404\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# then call stream.\u001b[39;49;00m\n\u001b[0;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# It'll attempt to gather all input into a single chunk using\u001b[39;49;00m\n\u001b[0;32m   1406\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# the `+` operator.\u001b[39;49;00m\n\u001b[0;32m   1407\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If the input is not addable, then we'll assume that we can\u001b[39;49;00m\n\u001b[0;32m   1408\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# only operate on the last chunk,\u001b[39;49;00m\n\u001b[0;32m   1409\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# and we'll iterate until we get to the last chunk.\u001b[39;49;00m\n\u001b[0;32m   1410\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgot_first_val\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5520\u001b[0m, in \u001b[0;36mRunnableBindingBase.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[0;32m   5515\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5516\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[0;32m   5517\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5518\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   5519\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 5520\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[0;32m   5521\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5522\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5523\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5524\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1402\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   1399\u001b[0m final: Input\n\u001b[0;32m   1400\u001b[0m got_first_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1402\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# The default implementation of transform is to buffer input and\u001b[39;49;00m\n\u001b[0;32m   1404\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# then call stream.\u001b[39;49;00m\n\u001b[0;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# It'll attempt to gather all input into a single chunk using\u001b[39;49;00m\n\u001b[0;32m   1406\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# the `+` operator.\u001b[39;49;00m\n\u001b[0;32m   1407\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If the input is not addable, then we'll assume that we can\u001b[39;49;00m\n\u001b[0;32m   1408\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# only operate on the last chunk,\u001b[39;49;00m\n\u001b[0;32m   1409\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# and we'll iterate until we get to the last chunk.\u001b[39;49;00m\n\u001b[0;32m   1410\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgot_first_val\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1420\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   1417\u001b[0m             final \u001b[38;5;241m=\u001b[39m ichunk\n\u001b[0;32m   1419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[1;32m-> 1420\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(final, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\runnables\\base.py:986\u001b[0m, in \u001b[0;36mRunnable.stream\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream\u001b[39m(\n\u001b[0;32m    969\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    970\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m    971\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    972\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m    973\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m    974\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;124;03m    Default implementation of stream, which calls invoke.\u001b[39;00m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;124;03m    Subclasses should override this method if they support streaming output.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;124;03m        The output of the Runnable.\u001b[39;00m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 986\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\prompts\\base.py:193\u001b[0m, in \u001b[0;36mBasePromptTemplate.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags:\n\u001b[0;32m    192\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags\n\u001b[1;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_prompt_with_error_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserialized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serialized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1916\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[0;32m   1912\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   1913\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[0;32m   1914\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1915\u001b[0m         Output,\n\u001b[1;32m-> 1916\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1917\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1918\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1919\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1920\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1921\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1922\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1923\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1924\u001b[0m     )\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1926\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\runnables\\config.py:398\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    397\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\prompts\\base.py:167\u001b[0m, in \u001b[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001b[1;34m(self, inner_input)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_format_prompt_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, inner_input: Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[1;32m--> 167\u001b[0m     _inner_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_prompt(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_inner_input)\n",
            "File \u001b[1;32mc:\\Users\\novikova\\OneDrive - Fonterra Co-operative Group Limited\\Documents\\Learning\\The AI Engineering Bootcamp\\Day 2\\AIE2\\.w3d2\\Lib\\site-packages\\langchain_core\\prompts\\base.py:163\u001b[0m, in \u001b[0;36mBasePromptTemplate._validate_input\u001b[1;34m(self, inner_input)\u001b[0m\n\u001b[0;32m    157\u001b[0m     example_key \u001b[38;5;241m=\u001b[39m missing\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m    158\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNote: if you intended \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m to be part of the string\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and not a variable, please escape it with double curly braces like: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    162\u001b[0m     )\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(msg)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inner_input\n",
            "\u001b[1;31mKeyError\u001b[0m: \"Input to ChatPromptTemplate is missing variables {'team_members'}.  Expected: ['agent_scratchpad', 'messages', 'team_members'] Received: ['messages', 'next', 'intermediate_steps', 'agent_scratchpad']\\nNote: if you intended {team_members} to be part of the string and not a variable, please escape it with double curly braces like: '{{team_members}}'.\""
          ]
        }
      ],
      "source": [
        "for s in super_graph.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            HumanMessage(\n",
        "                content=\"Write a LinkedIn post on the paper 'Extending Llama-3’s Context Ten-Fold Overnight'. First consult the research team. Then make sure you consult the LinkedIn team, and check for copy editing and dopeness, and write the file to disk.\"\n",
        "            )\n",
        "        ],\n",
        "    },\n",
        "    {\"recursion_limit\": 30},\n",
        "):\n",
        "    if \"__end__\" not in s:\n",
        "        print(s)\n",
        "        print(\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuZAvSlJJpPP"
      },
      "source": [
        "## SAMPLE POST!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOEMCrXTJaxW"
      },
      "source": [
        "```\n",
        "A game-changing breakthrough in AI just touched down! The Llama-3-8B-Instruct model just went from cool to ultra-cool, extending its context length from 8K to a mind-blowing 80K. And guess what? It kept all its original capabilities for shorter contexts.\n",
        "\n",
        "Talk about speed? This upgrade was pulled off in only 8 hours using an 8xA800 (80G) GPU machine. Big ups to the 3.5K synthetic training samples generated by GPT-4 that made this possible. This shows how large language models are pushing boundaries and taking giant leaps in the game.\n",
        "\n",
        "Here's the dopest part: the squad is going all out, releasing all related resources including data, model, and training code, for everyone. This is how we move the needle, with open collaboration.\n",
        "\n",
        "For more deets on this cutting-edge breakthrough and further upgrades, hit up our dedicated teams. We've got the info, you bring the curiosity.\n",
        "\n",
        "#AI #MachineLearning #OpenSource #Innovation #Collaboration #Advancement\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "IDUnpEEl-L_F"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
