{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-IqJAMkwnCF"
      },
      "source": [
        "# Advanced Retrieval with LangChain\n",
        "\n",
        "In the following notebook, we'll explore various methods of advanced retrieval using LangChain!\n",
        "\n",
        "We'll touch on:\n",
        "\n",
        "- Naive Retrieval\n",
        "- Best-Matching 25 (BM25)\n",
        "- Multi-Query Retrieval\n",
        "- Parent-Document Retrieval\n",
        "- Contextual Compression (a.k.a. Rerank)\n",
        "- Ensemble Retrieval\n",
        "- Semantic chunking\n",
        "\n",
        "We'll also discuss how these methods impact performance on our set of documents with a simple RAG chain.\n",
        "\n",
        "There will be two breakout rooms:\n",
        "\n",
        "-  Breakout Room Part #1\n",
        "  - Task 1: Getting Dependencies!\n",
        "  - Task 2: Data Collection and Preparation\n",
        "  - Task 3: Setting Up QDrant!\n",
        "  - Task 4-10: Retrieval Strategies\n",
        "-  Breakout Room Part #2\n",
        "  - Activity: Evaluate with Ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rKP3hgHivpe"
      },
      "source": [
        "#  Breakout Room Part #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xes8oT-xHN7"
      },
      "source": [
        "## Task 1: Getting Dependencies!\n",
        "\n",
        "We're going to need a few specific LangChain community packages, like OpenAI (for our [LLM](https://platform.openai.com/docs/models) and [Embedding Model](https://platform.openai.com/docs/guides/embeddings)) and Cohere (for our [Reranker](https://cohere.com/rerank))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkgFAXWVW3wm",
        "outputId": "636db35c-f05a-4038-ec7a-02360bef2dae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (0.3.1)\n",
            "Requirement already satisfied: langchain-openai in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (0.2.1)\n",
            "Requirement already satisfied: langchain-cohere in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (0.3.0)\n",
            "Requirement already satisfied: rank_bm25 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (0.2.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain) (3.10.6)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain) (0.1.128)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.40.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain-openai) (1.50.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: cohere<6.0,>=5.5.6 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain-cohere) (5.10.0)\n",
            "Requirement already satisfied: langchain-experimental>=0.3.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain-cohere) (0.3.2)\n",
            "Requirement already satisfied: pandas>=1.4.3 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain-cohere) (2.2.3)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain-cohere) (0.9.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.12.1)\n",
            "Requirement already satisfied: boto3<2.0.0,>=1.34.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (1.35.28)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (1.9.7)\n",
            "Requirement already satisfied: httpx>=0.21.2 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.27.2)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.4.0)\n",
            "Requirement already satisfied: parameterized<0.10.0,>=0.9.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.9.0)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.23.4)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.20.0)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.32.0.20240914)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (4.12.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (24.1)\n",
            "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain-experimental>=0.3.0->langchain-cohere) (0.3.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.6.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.5.0)\n",
            "Requirement already satisfied: sniffio in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.66.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from pandas>=1.4.3->langchain-cohere) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from pandas>=1.4.3->langchain-cohere) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from pandas>=1.4.3->langchain-cohere) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n",
            "Requirement already satisfied: botocore<1.36.0,>=1.35.28 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain-cohere) (1.35.28)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain-cohere) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain-cohere) (0.10.2)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from httpcore==1.*->httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain) (3.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (2.5.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.4.3->langchain-cohere) (1.16.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (0.25.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.40.0->langchain-openai) (0.4.6)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (0.9.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (2024.9.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (1.0.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain langchain-openai langchain-cohere rank_bm25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKqYM4Eoxcov"
      },
      "source": [
        "We're also going to be leveraging [Qdrant's](https://qdrant.tech/documentation/frameworks/langchain/) (pronounced \"Quadrant\") VectorDB in \"memory\" mode (so we can leverage it locally in our colab environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "s6xav5CxYnML"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting qdrant-client\n",
            "  Using cached qdrant_client-1.11.3-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting grpcio>=1.41.0 (from qdrant-client)\n",
            "  Using cached grpcio-1.66.1-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
            "Collecting grpcio-tools>=1.41.0 (from qdrant-client)\n",
            "  Using cached grpcio_tools-1.66.1-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: httpx>=0.20.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.27.2)\n",
            "Requirement already satisfied: numpy>=1.26 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from qdrant-client) (1.26.4)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client)\n",
            "  Using cached portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.10.8 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from qdrant-client) (2.9.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from qdrant-client) (2.2.3)\n",
            "Collecting protobuf<6.0dev,>=5.26.1 (from grpcio-tools>=1.41.0->qdrant-client)\n",
            "  Using cached protobuf-5.28.2-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
            "Collecting setuptools (from grpcio-tools>=1.41.0->qdrant-client)\n",
            "  Using cached setuptools-75.1.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: anyio in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (4.6.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.5)\n",
            "Requirement already satisfied: idna in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.10)\n",
            "Requirement already satisfied: sniffio in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.14.0)\n",
            "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant-client)\n",
            "  Using cached h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pywin32>=226 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from portalocker<3.0.0,>=2.7.0->qdrant-client) (306)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from pydantic>=1.10.8->qdrant-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from pydantic>=1.10.8->qdrant-client) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from pydantic>=1.10.8->qdrant-client) (4.12.2)\n",
            "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client)\n",
            "  Using cached hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client)\n",
            "  Using cached hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Using cached qdrant_client-1.11.3-py3-none-any.whl (258 kB)\n",
            "Using cached grpcio-1.66.1-cp312-cp312-win_amd64.whl (4.3 MB)\n",
            "Using cached grpcio_tools-1.66.1-cp312-cp312-win_amd64.whl (1.1 MB)\n",
            "Using cached portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Using cached h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "Using cached protobuf-5.28.2-cp310-abi3-win_amd64.whl (431 kB)\n",
            "Using cached setuptools-75.1.0-py3-none-any.whl (1.2 MB)\n",
            "Using cached hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Using cached hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: setuptools, protobuf, portalocker, hyperframe, hpack, grpcio, h2, grpcio-tools, qdrant-client\n",
            "Successfully installed grpcio-1.66.1 grpcio-tools-1.66.1 h2-4.1.0 hpack-4.0.0 hyperframe-6.0.1 portalocker-2.10.1 protobuf-5.28.2 qdrant-client-1.11.3 setuptools-75.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U qdrant-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7OHJXzfyJyA"
      },
      "source": [
        "We'll also provide our OpenAI key, as well as our Cohere API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LttlDQUYgSI",
        "outputId": "9dca95ab-4d02-4adf-ec3f-cb831326dc54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API Key:路路路路路路路路路路\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iUahNiJyQbv",
        "outputId": "78bf06ef-2ee8-46c3-f73d-27958b4dd79b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cohere API Key:路路路路路路路路路路\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0pDRFEWSXvh"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw304iAFyRtl"
      },
      "source": [
        "## Task 2: Data Collection and Preparation\n",
        "\n",
        "We'll be using some reviews from the 4 movies in the John Wick franchise today to explore the different retrieval strategies.\n",
        "\n",
        "These were obtained from IMDB, and are available in the [AIM Data Repository](https://github.com/AI-Maker-Space/DataRepository)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXKHcZmKzDwT"
      },
      "source": [
        "### Data Collection\n",
        "\n",
        "We can simply `wget` these from GitHub.\n",
        "\n",
        "You could use any review data you wanted in this step - just be careful to make sure your metadata is aligned with your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbbSIGtzX3dS",
        "outputId": "0ce6514e-2479-4001-af24-824f987ce599"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SYSTEM_WGETRC = c:/progra~1/wget/etc/wgetrc\n",
            "syswgetrc = C:\\Program Files (x86)\\GnuWin32/etc/wgetrc\n",
            "--2024-09-27 11:39:12--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv\n",
            "Resolving raw.githubusercontent.com... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com|185.199.110.133|:443... connected.\n",
            "OpenSSL: error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown protocol\n",
            "Unable to establish SSL connection.\n",
            "SYSTEM_WGETRC = c:/progra~1/wget/etc/wgetrc\n",
            "syswgetrc = C:\\Program Files (x86)\\GnuWin32/etc/wgetrc\n",
            "--2024-09-27 11:39:13--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv\n",
            "Resolving raw.githubusercontent.com... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com|185.199.110.133|:443... connected.\n",
            "OpenSSL: error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown protocol\n",
            "Unable to establish SSL connection.\n",
            "SYSTEM_WGETRC = c:/progra~1/wget/etc/wgetrc\n",
            "syswgetrc = C:\\Program Files (x86)\\GnuWin32/etc/wgetrc\n",
            "--2024-09-27 11:39:13--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv\n",
            "Resolving raw.githubusercontent.com... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com|185.199.110.133|:443... connected.\n",
            "OpenSSL: error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown protocol\n",
            "Unable to establish SSL connection.\n",
            "SYSTEM_WGETRC = c:/progra~1/wget/etc/wgetrc\n",
            "syswgetrc = C:\\Program Files (x86)\\GnuWin32/etc/wgetrc\n",
            "--2024-09-27 11:39:13--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv\n",
            "Resolving raw.githubusercontent.com... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com|185.199.110.133|:443... connected.\n",
            "OpenSSL: error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown protocol\n",
            "Unable to establish SSL connection.\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv -O john_wick_1.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv -O john_wick_2.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv -O john_wick_3.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv -O john_wick_4.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92NC2QZzCsi"
      },
      "source": [
        "### Data Preparation\n",
        "\n",
        "We want to make sure all our documents have the relevant metadata for the various retrieval strategies we're going to be applying today.\n",
        "\n",
        "- Self-Query: Wants as much metadata as we can provide\n",
        "- Time-weighted: Wants temporal data\n",
        "\n",
        "> NOTE: While we're creating a temporal relationship based on when these movies came out for illustrative purposes, it needs to be clear that the \"time-weighting\" in the Time-weighted Retriever is based on when the document was *accessed* last - not when it was created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GshBjVRJZ6p8"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "documents = []\n",
        "\n",
        "for i in range(1, 5):\n",
        "  loader = CSVLoader(\n",
        "      file_path=f\"john_wick_{i}.csv\",\n",
        "      metadata_columns=[\"Review_Date\", \"Review_Title\", \"Review_Url\", \"Author\", \"Rating\"],\n",
        "      encoding=\"UTF-8\"\n",
        "  )\n",
        "\n",
        "  movie_docs = loader.load()\n",
        "  for doc in movie_docs:\n",
        "\n",
        "    # Add the \"Movie Title\" (John Wick 1, 2, ...)\n",
        "    doc.metadata[\"Movie_Title\"] = f\"John Wick {i}\"\n",
        "\n",
        "    # convert \"Rating\" to an `int`, if no rating is provided - assume 0 rating\n",
        "    doc.metadata[\"Rating\"] = int(doc.metadata[\"Rating\"]) if doc.metadata[\"Rating\"] else 0\n",
        "\n",
        "    # newer movies have a more recent \"last_accessed_at\"\n",
        "    doc.metadata[\"last_accessed_at\"] = datetime.now() - timedelta(days=4-i)\n",
        "\n",
        "  documents.extend(movie_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gQphb6y0C0S"
      },
      "source": [
        "Let's look at an example document to see if everything worked as expected!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkUkCf7DaMiq",
        "outputId": "e90bd5da-1d87-423b-838a-cb6efc16b199"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'john_wick_1.csv', 'row': 0, 'Review_Date': '6 May 2015', 'Review_Title': ' Kinetic, concise, and stylish; John Wick kicks ass.\\n', 'Review_Url': '/review/rw3233896/?ref_=tt_urv', 'Author': 'lnvicta', 'Rating': 8, 'Movie_Title': 'John Wick 1', 'last_accessed_at': datetime.datetime(2024, 9, 24, 11, 47, 5, 638957)}, page_content=\": 0\\nReview: The best way I can describe John Wick is to picture Taken but instead of Liam Neeson it's Keanu Reeves and instead of his daughter it's his dog. That's essentially the plot of the movie. John Wick (Reeves) is out to seek revenge on the people who took something he loved from him. It's a beautifully simple premise for an action movie - when action movies get convoluted, they get bad i.e. A Good Day to Die Hard. John Wick gives the viewers what they want: Awesome action, stylish stunts, kinetic chaos, and a relatable hero to tie it all together. John Wick succeeds in its simplicity.\")"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWaQpdHl0Gzc"
      },
      "source": [
        "## Task 3: Setting up QDrant!\n",
        "\n",
        "Now that we have our documents, let's create a QDrant VectorStore with the collection name \"JohnWick\".\n",
        "\n",
        "We'll leverage OpenAI's [`text-embedding-3-small`](https://openai.com/blog/new-embedding-models-and-api-updates) because it's a very powerful (and low-cost) embedding model.\n",
        "\n",
        "> NOTE: We'll be creating additional vectorstores where necessary, but this pattern is still extremely useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NT8ihRJbYmMT"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "\n",
        "embeddings = AzureOpenAIEmbeddings(azure_deployment=\"text-embedding-3-small\")\n",
        "\n",
        "vectorstore = Qdrant.from_documents(\n",
        "    documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"JohnWick\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.65336683]])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np  \n",
        "\n",
        "cosine_similarity(np.array(embeddings.embed_query(\"mass-energy equivalence formula\")).reshape(1, -1),\n",
        "                  np.array(embeddings.embed_query(\"$$E = mc^2$$\")).reshape(1, -1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x2SS4Rh0hiN"
      },
      "source": [
        "## Task 4: Naive RAG Chain\n",
        "\n",
        "Since we're focusing on the \"R\" in RAG today - we'll create our Retriever first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEH7X5Ai08FH"
      },
      "source": [
        "### R - Retrieval\n",
        "\n",
        "This naive retriever will simply look at each review as a document, and use cosine-similarity to fetch the 10 most relevant documents.\n",
        "\n",
        "> NOTE: We're choosing `10` as our `k` here to provide enough documents for our reranking process later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "GFDPrNBtb72o"
      },
      "outputs": [],
      "source": [
        "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbBhyQjz06dx"
      },
      "source": [
        "### A - Augmented\n",
        "\n",
        "We're going to go with a standard prompt for our simple RAG chain today! Nothing fancy here, we want this to mostly be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "7uSz-Dbqcoki"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_TEMPLATE = \"\"\"\\\n",
        "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
        "\n",
        "If you do not know the answer, or are unsure, say you don't know.\n",
        "\n",
        "Query:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlRzpb231GGJ"
      },
      "source": [
        "### G - Generation\n",
        "\n",
        "We're going to leverage `gpt-3.5-turbo` as our LLM today, as - again - we want this to largely be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "c-1t9H60dJLg"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import AzureChatOpenAI\n",
        "\n",
        "chat_model = AzureChatOpenAI(azure_deployment=\"gpt-35-turbo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg3QRGzA1M2x"
      },
      "source": [
        "### LCEL RAG Chain\n",
        "\n",
        "We're going to use LCEL to construct our chain.\n",
        "\n",
        "> NOTE: This chain will be exactly the same across the various examples with the exception of our Retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "0bvstS7mdOW3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "naive_retrieval_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izKujhNb1ZG8"
      },
      "source": [
        "Let's see how this simple chain does on a few different prompts.\n",
        "\n",
        "> NOTE: You might think that we've cherry picked prompts that showcase the individual skill of each of the retrieval strategies - you'd be correct!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LI-5ueEddku9",
        "outputId": "7f3cec18-5f4e-41bb-cf71-51ba0be5388e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Overall, the reviews suggest that people generally liked John Wick. Many reviewers praised the film's action sequences, Keanu Reeves' performance as the titular character, and the film's stylish visuals. However, there were a few negative reviews as well. One reviewer did not understand the hype surrounding the film and found it to be a generic action thriller. Another reviewer felt that the magic of the first film was lost in the third installment.\""
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "43zdcdUydtXh",
        "outputId": "db874e67-f568-4ed1-b863-b7c17b387052"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Yes, one review has a rating of 10. Here is the URL to that review: '/review/rw4854296/?ref_=tt_urv'.\""
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lpG6rlvvvKFq",
        "outputId": "a1b330b0-628e-41be-d829-9c1d55e781f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the original John Wick movie, an ex-hitman seeks revenge against the gangsters who killed his dog and took everything from him. He becomes the target of an army of bounty-hunting killers, and he unleashes a maelstrom of destruction against those who attempt to chase him. In the second movie, John Wick is forced back into the assassin world when he is called on to pay off an old debt. In the third movie, John Wick deals with the consequences of his actions in the previous film and continues to explore the world of assassination.'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsbfQmbr1leg"
      },
      "source": [
        "Overall, this is not bad! Let's see if we can make it better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft1vt8HPR16w"
      },
      "source": [
        "## Task 5: Best-Matching 25 (BM25) Retriever\n",
        "\n",
        "Taking a step back in time - [BM25](https://www.nowpublishers.com/article/Details/INR-019) is based on [Bag-Of-Words](https://en.wikipedia.org/wiki/Bag-of-words_model) which is a sparse representation of text.\n",
        "\n",
        "In essence, it's a way to compare how similar two pieces of text are based on the words they both contain.\n",
        "\n",
        "This retriever is very straightforward to set-up! Let's see it happen down below!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "qdF4wuj5R-cG"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIjJlBQ8drKH"
      },
      "source": [
        "We'll construct the same chain - only changing the retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "WR15EQG7SLuw"
      },
      "outputs": [],
      "source": [
        "naive_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gi-yXCDdvJk"
      },
      "source": [
        "Let's look at the responses!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oY9qzmm3SOrF",
        "outputId": "4d4f450f-5978-460f-f242-b32407868353"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'It is difficult to determine whether people generally liked John Wick based on the given context as there are differing opinions expressed in the reviews provided.'"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "igfinyneSQkh",
        "outputId": "9752d4a9-dd16-45b1-f63f-a76e93a05eb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, one review has a rating of 10. However, there are no URLs provided for the reviews in the given context.'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "w0H7pV_USSMQ",
        "outputId": "bdead654-3109-4143-9a30-e1d6ca8dc534"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'John Wick is a movie series known for its beautifully choreographed action scenes, emotional setup, and unique characters.'"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvg5xHaUdxCl"
      },
      "source": [
        "It's not clear that this is better or worse - but the `I don't know` isn't great!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-dcbFn2vpZF"
      },
      "source": [
        "## Task 6: Contextual Compression (Using Reranking)\n",
        "\n",
        "Contextual Compression is a fairly straightforward idea: We want to \"compress\" our retrieved context into just the most useful bits.\n",
        "\n",
        "There are a few ways we can achieve this - but we're going to look at a specific example called reranking.\n",
        "\n",
        "The basic idea here is this:\n",
        "\n",
        "- We retrieve lots of documents that are very likely related to our query vector\n",
        "- We \"compress\" those documents into a smaller set of *more* related documents using a reranking algorithm.\n",
        "\n",
        "We'll be leveraging Cohere's Rerank model for our reranker today!\n",
        "\n",
        "All we need to do is the following:\n",
        "\n",
        "- Create a basic retriever\n",
        "- Create a compressor (reranker, in this case)\n",
        "\n",
        "That's it!\n",
        "\n",
        "Let's see it in the code below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "psHvO2K1v_ZQ"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "compressor = CohereRerank(model=\"rerank-english-v3.0\")\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=naive_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TA9RB2x-j7P"
      },
      "source": [
        "Let's create our chain again, and see how this does!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "1BXqmxvHwX6T"
      },
      "outputs": [],
      "source": [
        "contextual_compression_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V3iGpokswcBb",
        "outputId": "f15d2aa1-5e8b-417d-f623-eb835d072e59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the given context, it appears that people generally liked John Wick. The first two reviews gave it high ratings and praised its action sequences, characters, and overall entertainment value. However, the third review suggests that the magic may have been lost in the third installment.'"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7u_k0i4OweUd",
        "outputId": "be5fccc8-2352-4189-c524-bbeaa28cf799"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Yes, one review has a rating of 10. Here is the URL to that review: '/review/rw4854296/?ref_=tt_urv'.\""
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "zn1EqaGqweXN",
        "outputId": "42bc5972-4164-46eb-f49d-4272f39bb89b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In John Wick 2, John Wick is asked by Santino D'Antonio to kill his sister Gianna D'Antonio in Rome so that Santino can sit on the High Table of the criminal organizations. After completing the task, Santino puts a seven-million dollar contract on John Wick, attracting professional killers from everywhere. John Wick promises to kill Santino, who is no longer protected by his marker. \\n\\nIn John Wick 1, an ex-hit-man seeks revenge after an arrogant Russian mob prince and hoodlums steal his car and kill his dog. He finds himself dragged into an impossible task as every killer in the business dreams of cornering the legendary Wick who now has an enormous price on his head. The legendary hitman will be forced to unearth his meticulously concealed identity and to carry out a relentless vendetta.\""
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEbT0g2S-mZ4"
      },
      "source": [
        "We'll need to rely on something like Ragas to help us get a better sense of how this is performing overall - but it \"feels\" better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqbghrBEQNn5"
      },
      "source": [
        "## Task 7: Multi-Query Retriever\n",
        "\n",
        "Typically in RAG we have a single query - the one provided by the user.\n",
        "\n",
        "What if we had....more than one query!\n",
        "\n",
        "In essence, a Multi-Query Retriever works by:\n",
        "\n",
        "1. Taking the original user query and creating `n` number of new user queries using an LLM.\n",
        "2. Retrieving documents for each query.\n",
        "3. Using all unique retrieved documents as context\n",
        "\n",
        "So, how is it to set-up? Not bad! Let's see it down below!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "pfM26ReXQjzU"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=naive_retriever, llm=chat_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "1vRc129jQ5WW"
      },
      "outputs": [],
      "source": [
        "multi_query_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CGgNuOb3Q3M9",
        "outputId": "c5273ecf-da35-40b8-fbdb-0f8beab425f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"People generally liked John Wick, with many reviewers praising its slick action sequences and Keanu Reeves' performance as the titular character. However, there were a few reviewers who were less impressed and found the film to be generic or lacking in plot. It is important to note that opinions on the film were not unanimous.\""
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aAlSthxrRDBC",
        "outputId": "230ff807-23ae-4d25-8d11-cfdbed0b77cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Yes, there is a review with a rating of 10 for John Wick 3. The URL for that review is '/review/rw4854296/?ref_=tt_urv'.\""
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "Uv1mpCK8REs4",
        "outputId": "00fbc22a-ed9b-4613-9695-0b179e3f8369"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In John Wick, an ex-hit-man comes out of retirement to seek revenge against the gangsters that killed his dog and took everything from him. He unleashes a carefully orchestrated maelstrom of destruction against those attempting to chase him, as he is the target of hit men. In John Wick 2, he is forced back into the assassin world when an Italian baddie calls in a favor and Wick has no choice but to accept. In John Wick 3, the film deals with the fallout of John's actions at the end of the previous film and sends him on an even bigger odyssey of violence.\""
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDEawBf_d_3G"
      },
      "source": [
        "## Task 8: Parent Document Retriever\n",
        "\n",
        "A \"small-to-big\" strategy - the Parent Document Retriever works based on a simple strategy:\n",
        "\n",
        "1. Each un-split \"document\" will be designated as a \"parent document\" (You could use larger chunks of document as well, but our data format allows us to consider the overall document as the parent chunk)\n",
        "2. Store those \"parent documents\" in a memory store (not a VectorStore)\n",
        "3. We will chunk each of those documents into smaller documents, and associate them with their respective parents, and store those in a VectorStore. We'll call those \"child chunks\".\n",
        "4. When we query our Retriever, we will do a similarity search comparing our query vector to the \"child chunks\".\n",
        "5. Instead of returning the \"child chunks\", we'll return their associated \"parent chunks\".\n",
        "\n",
        "Okay, maybe that was a few steps - but the basic idea is this:\n",
        "\n",
        "- Search for small documents\n",
        "- Return big documents\n",
        "\n",
        "The intuition is that we're likely to find the most relevant information by limiting the amount of semantic information that is encoded in each embedding vector - but we're likely to miss relevant surrounding context if we only use that information.\n",
        "\n",
        "Let's start by creating our \"parent documents\" and defining a `RecursiveCharacterTextSplitter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "qJ53JJuMd_ZH"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "parent_docs = documents\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOpXfVUH3gL3"
      },
      "source": [
        "We'll need to set up a new QDrant vectorstore - and we'll use another useful pattern to do so!\n",
        "\n",
        "> NOTE: We are manually defining our embedding dimension, you'll need to change this if you're using a different embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzFc-_9HlGQ-",
        "outputId": "223662dd-c36f-42f7-d1b0-b086e571484e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\novikova\\AppData\\Local\\Temp\\ipykernel_55868\\3287387143.py:8: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-qdrant package and should be used instead. To use it run `pip install -U :class:`~langchain-qdrant` and import as `from :class:`~langchain_qdrant import Qdrant``.\n",
            "  parent_document_vectorstore = Qdrant(\n"
          ]
        }
      ],
      "source": [
        "client = QdrantClient(location=\":memory:\")\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=\"full_documents\",\n",
        "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
        ")\n",
        "\n",
        "parent_document_vectorstore = Qdrant(\n",
        "    collection_name=\"full_documents\", embeddings=embeddings, client=client\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf_g95FA3s6w"
      },
      "source": [
        "Now we can create our `InMemoryStore` that will hold our \"parent documents\" - and build our retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "BpWVjPf4fLUp"
      },
      "outputs": [],
      "source": [
        "store = InMemoryStore()\n",
        "\n",
        "parent_document_retriever = ParentDocumentRetriever(\n",
        "    vectorstore = parent_document_vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoYmSWfE32Zo"
      },
      "source": [
        "By default, this is empty as we haven't added any documents - let's add some now!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "iQ2ZzfKigMZc"
      },
      "outputs": [],
      "source": [
        "parent_document_retriever.add_documents(parent_docs, ids=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI7Tip1335rE"
      },
      "source": [
        "We'll create the same chain we did before - but substitute our new `parent_document_retriever`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "Qq_adt2KlSqp"
      },
      "outputs": [],
      "source": [
        "parent_document_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNolUVQb4Apt"
      },
      "source": [
        "Let's give it a whirl!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "TXB5i89Zly5W",
        "outputId": "94c240be-7c5b-4c58-9eee-56d93285a054"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'It is unclear from the provided context whether people generally liked John Wick. There are mixed opinions expressed in the reviews.'"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V5F1T-wNl3cg",
        "outputId": "9b81e72e-5db7-4b8a-b25b-400ea0df5335"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. The URL to that review is /review/rw4854296/?ref_=tt_urv.'"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ZqARszGzvGcG",
        "outputId": "8867f83c-db13-4db4-d57f-9bd51d32cd8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In John Wick 1, an ex-hitman seeks revenge when gangsters kill his dog and steal his car. In John Wick 2, John is called on to pay off an old debt by helping Ian McShane take over the Assassin's Guild by flying around to Italy, Canada, and Manhattan and killing what seems like hundreds of assassins.\""
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B41cj42s4DPM"
      },
      "source": [
        "Overall, the performance *seems* largely the same. We can leverage a tool like [Ragas]() to more effectively answer the question about the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUrIBKl_TwS9"
      },
      "source": [
        "## Task 9: Ensemble Retriever\n",
        "\n",
        "In brief, an Ensemble Retriever simply takes 2, or more, retrievers and combines their retrieved documents based on a rank-fusion algorithm.\n",
        "\n",
        "In this case - we're using the [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) algorithm.\n",
        "\n",
        "Setting it up is as easy as providing a list of our desired retrievers - and the weights for each retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "8j7jpZsKTxic"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, compression_retriever, multi_query_retriever]\n",
        "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=retriever_list, weights=equal_weighting\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpo9Psl5hhJ-"
      },
      "source": [
        "We'll pack *all* of these retrievers together in an ensemble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "KZ__EZwpUKkd"
      },
      "outputs": [],
      "source": [
        "ensemble_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSsvHpRMj24L"
      },
      "source": [
        "Let's look at our results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lMvqL88UQI-",
        "outputId": "d86dd5f7-0a13-4836-c0ce-cc4c431fd889"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"The majority of the reviews suggest that people generally liked John Wick. There are numerous positive reviews that praise the film's action sequences, world-building, and Keanu Reeves' performance. However, there are also a few negative reviews that criticize the film for being too violent or lacking in plot. Overall, it seems that the film has a strong following among action fans.\""
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MNFWLYECURI1",
        "outputId": "b17973b5-66a9-4481-97d5-880b5754b5c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is one review with a rating of 10 for \"John Wick 3\". The URL to that review is \\'/review/rw4854296/?ref_=tt_urv\\'.'"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "A7qbHfWgUR4c",
        "outputId": "f7373144-59ef-4fc7-b75d-ca00e7df881e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In John Wick, an ex-hitman comes out of retirement to track down the gangsters that killed his dog and took everything from him. With the untimely death of his beloved wife still bitter in his mouth, he seeks vengeance. In John Wick 2, John Wick is called on to pay off an old debt by helping Ian McShane take over the Assassin's Guild by flying around to Italy, Canada and Manhattan and killing what seems like hundreds of assassins. In John Wick 3, John Wick deals with the consequences of his actions at the end of the previous film and goes on an even bigger odyssey of violence that continues to explore the world of assassination and deliver beautifully clean action sequences. As for John Wick 4, there are mixed reviews, with some finding it disappointing and others enjoying it.\""
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MopbkNJAXVaN"
      },
      "source": [
        "## Task 10: Semantic Chunking\n",
        "\n",
        "While this is not a retrieval method - it *is* an effective way of increasing retrieval performance on corpora that have clean semantic breaks in them.\n",
        "\n",
        "Essentially, Semantic Chunking is implemented by:\n",
        "\n",
        "1. Embedding all sentences in the corpus.\n",
        "2. Combining or splitting sequences of sentences based on their semantic similarity based on a number of [possible thresholding methods](https://python.langchain.com/docs/how_to/semantic-chunker/):\n",
        "  - `percentile`\n",
        "  - `standard_deviation`\n",
        "  - `interquartile`\n",
        "  - `gradient`\n",
        "3. Each sequence of related sentences is kept as a document!\n",
        "\n",
        "Let's see how to implement this!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dHeB-yGXneL",
        "outputId": "efc59105-518a-4134-9228-d98b8a97e08e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain_experimental in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (0.3.2)\n",
            "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain_experimental) (0.3.1)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain_experimental) (0.3.6)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.10.6)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.1 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.1.128)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.5.2)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain_experimental) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain_experimental) (24.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain_experimental) (2.9.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain_experimental) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.12.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain_experimental) (3.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langchain<0.4.0,>=0.3.1->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.6->langchain_experimental) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.6->langchain_experimental) (2.23.4)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.1.1)\n",
            "Requirement already satisfied: anyio in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (4.6.0)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.5)\n",
            "Requirement already satisfied: sniffio in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.14.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\novikova\\onedrive - fonterra co-operative group limited\\documents\\learning\\the ai engineering bootcamp\\day 2\\aie2\\.w7d2\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain_experimental"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9ciZbFEldv_"
      },
      "source": [
        "We'll use the `percentile` thresholding method for this example which will:\n",
        "\n",
        "Calculate all distances between sentences, and then break apart sequences of setences that exceed a given percentile among all distances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "66EIEWiEYl5y"
      },
      "outputs": [],
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "semantic_chunker = SemanticChunker(\n",
        "    embeddings,\n",
        "    breakpoint_threshold_type=\"percentile\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqoKmz12mhRW"
      },
      "source": [
        "Now we can split our documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "ROcV7o68ZIq7"
      },
      "outputs": [],
      "source": [
        "semantic_documents = semantic_chunker.split_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8-LNC-Xmjex"
      },
      "source": [
        "Let's create a new vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "h3sl9QjyZhIe"
      },
      "outputs": [],
      "source": [
        "semantic_vectorstore = Qdrant.from_documents(\n",
        "    semantic_documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"JohnWickSemantic\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh_r_-LHmmKn"
      },
      "source": [
        "We'll use naive retrieval for this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "odVyDUHwZftc"
      },
      "outputs": [],
      "source": [
        "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkeiv_ojmp6G"
      },
      "source": [
        "Finally we can create our classic chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "xWE_0J0mZveG"
      },
      "outputs": [],
      "source": [
        "semantic_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5pfjLQ3ms9_"
      },
      "source": [
        "And view the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lN2j-e4Z0SD",
        "outputId": "ef483e21-7200-4dfc-b8bf-aed4f23587b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Overall, the reviews suggest that people generally liked John Wick. Many reviewers praised the action sequences, Keanu Reeves' performance, and the style of the film. However, there were a few negative reviews that criticized the lack of plot or character development.\""
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xdqfBH1SZ3f9",
        "outputId": "ed62b2d1-7586-46cc-aaf4-c54192a56155"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Yes, one review has a rating of 10. The URL to that review is '/review/rw4854296/?ref_=tt_urv'.\""
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "rAcAObZnZ4o6",
        "outputId": "3f1cade3-41e4-4e42-ef71-048dd18e5e3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In John Wick, an ex-hitman seeks revenge after gangsters kill his dog and steal his car, and he becomes the target of hitmen. In John Wick 2, John is forced back into the assassination world to pay off an old debt and is tasked with killing the sister of a mobster. In John Wick 3, John is on the run after being declared excommunicado and has to fight his way out of New York City. In John Wick 4, the plot is unclear from the reviews provided.'"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk2n3-pnVWDJ"
      },
      "source": [
        "#  Breakout Room Part #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SkJLYwMVZkj"
      },
      "source": [
        "#### 锔 Activity #1\n",
        "\n",
        "Your task is to evaluate the various Retriever methods against eachother.\n",
        "\n",
        "You are expected to:\n",
        "\n",
        "1. Create a \"golden dataset\"\n",
        " - Use Synthetic Data Generation (powered by Ragas, or otherwise) to create this dataset\n",
        "2. Evaluate each retriever with *retriever specific* Ragas metrics\n",
        " - Semantic Chunking is not considered a retriever method and will not be required for marks, but you may find it useful to do a \"semantic chunking on\" vs. \"semantic chunking off\" comparision between them\n",
        "3. Compile these in a list and write a small paragraph about which is best for this particular data and why.\n",
        "\n",
        "Your analysis should factor in:\n",
        "  - Cost\n",
        "  - Latency\n",
        "  - Performance\n",
        "\n",
        "> NOTE: This is **NOT** required to be completed in class. Please spend time in your breakout rooms creating a plan before moving on to writing code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWAr16a5XMub"
      },
      "source": [
        "##### HINTS:\n",
        "\n",
        "- LangSmith provides detailed information about latency and cost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "documents = []\n",
        "\n",
        "for i in range(1, 5):\n",
        "  loader = CSVLoader(\n",
        "      file_path=f\"john_wick_{i}.csv\",\n",
        "      metadata_columns=[\"Review_Date\", \"Review_Title\", \"Review_Url\", \"Author\", \"Rating\"],\n",
        "      encoding=\"UTF-8\"\n",
        "  )\n",
        "\n",
        "  movie_docs = loader.load()\n",
        "  for doc in movie_docs:\n",
        "\n",
        "    # Add the \"Movie Title\" (John Wick 1, 2, ...)\n",
        "    doc.metadata[\"Movie_Title\"] = f\"John Wick {i}\"\n",
        "\n",
        "    # convert \"Rating\" to an `int`, if no rating is provided - assume 0 rating\n",
        "    doc.metadata[\"Rating\"] = int(doc.metadata[\"Rating\"]) if doc.metadata[\"Rating\"] else 0\n",
        "\n",
        "    # newer movies have a more recent \"last_accessed_at\"\n",
        "    doc.metadata[\"last_accessed_at\"] = datetime.now() - timedelta(days=4-i)\n",
        "\n",
        "  documents.extend(movie_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating a Golden Test Data Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "750a2aaa16794540bf83a36fab668c9c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "embedding nodes:   0%|          | 0/264 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Filename and doc_id are the same for all nodes.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bfd64610dfd740588aa03d6d7610b8d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>evolution_type</th>\n",
              "      <th>metadata</th>\n",
              "      <th>episode_done</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What are the priorities outlined in the White ...</td>\n",
              "      <td>[The White House (2022) Roadmap for Researcher...</td>\n",
              "      <td>The answer to given question is not present in...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'data/nist_ai.tex'}, {'source': 'd...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What type of information can provenance metada...</td>\n",
              "      <td>[Provenance metadata can include information a...</td>\n",
              "      <td>Provenance metadata can include information ab...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'data/nist_ai.tex'}]</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What processes are defined, assessed, and docu...</td>\n",
              "      <td>[MAP 3.4: Processes for operator and practitio...</td>\n",
              "      <td>Processes for operator and practitioner profic...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'data/nist_ai.tex'}]</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the purpose of field testing in the ev...</td>\n",
              "      <td>[\\item Al Red-teaming: A structured testing ex...</td>\n",
              "      <td>The purpose of field testing in the evaluation...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'data/nist_ai.tex'}]</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the purpose of conducting periodic mon...</td>\n",
              "      <td>[\\begin{center}\\n\\begin{tabular}{|c|c|c|}\\n\\hl...</td>\n",
              "      <td>The purpose of conducting periodic monitoring ...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'data/nist_ai.tex'}]</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How should GAI acceptable use policies be upda...</td>\n",
              "      <td>[may rely on embedded GAI technologies; Addres...</td>\n",
              "      <td>GAI acceptable use policies should be updated ...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'data/nist_ai.tex'}]</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What are the environmental impacts associated ...</td>\n",
              "      <td>[\\item Confabulation: The production of confid...</td>\n",
              "      <td>Impacts due to high compute resource utilizati...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'data/nist_ai.tex'}]</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How could model distillation or compression he...</td>\n",
              "      <td>[Trustworthy Al Characteristics: Accountable a...</td>\n",
              "      <td>Methods for creating smaller versions of train...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'data/nist_ai.tex'}]</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What actions are suggested to address Human-AI...</td>\n",
              "      <td>[MAP 3.4: Processes for operator and practitio...</td>\n",
              "      <td>The suggested actions to address Human-AI Conf...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'data/nist_ai.tex'}]</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How can structured public feedback be used to ...</td>\n",
              "      <td>[Measurement gaps can arise from mismatches be...</td>\n",
              "      <td>Structured public feedback can be used to eval...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'data/nist_ai.tex'}, {'source': 'd...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>How to ID GAI risks and eval AI biases when cu...</td>\n",
              "      <td>[MEASURE 2.13: Effectiveness of the employed T...</td>\n",
              "      <td>Establish processes for identifying emergent G...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'data/nist_ai.tex'}, {'source': 'd...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>How do third-party components in GAI systems a...</td>\n",
              "      <td>[CSAM. Even when trained on \"clean\" data, incr...</td>\n",
              "      <td>Third-party components in GAI systems can affe...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'data/nist_ai.tex'}, {'source': 'd...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>How do vendor reviews and policy tweaks monito...</td>\n",
              "      <td>[may rely on embedded GAI technologies; Addres...</td>\n",
              "      <td>Vendor reviews and policy tweaks monitor third...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'data/nist_ai.tex'}, {'source': 'd...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What should GAI incident response plans includ...</td>\n",
              "      <td>[MANAGE 2.3: Procedures are followed to respon...</td>\n",
              "      <td>GAI incident response plans should include nec...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'data/nist_ai.tex'}, {'source': 'd...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>How can systems secure responses, prevent misu...</td>\n",
              "      <td>[Hateful Content \\\\\\n\\end{tabular} \\\\\\n\\hline\\...</td>\n",
              "      <td>Systems can secure responses, prevent misuse, ...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'data/nist_ai.tex'}, {'source': 'd...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>How do collab with experts and explainable AI ...</td>\n",
              "      <td>[\\begin{center}\\n\\begin{tabular}{|c|c|c|}\\n\\hl...</td>\n",
              "      <td>Collaborating with external researchers, indus...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'data/nist_ai.tex'}, {'source': 'd...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>How do public feedback methods like field test...</td>\n",
              "      <td>[Measurement gaps can arise from mismatches be...</td>\n",
              "      <td>Public feedback methods like field testing bri...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'data/nist_ai.tex'}, {'source': 'd...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>How do GAI systems' cyber vulnerabilities and ...</td>\n",
              "      <td>[There may also be concerns about emotional en...</td>\n",
              "      <td>GAI systems can ease the unintentional product...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'data/nist_ai.tex'}, {'source': 'd...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Who manages AI risks for CBRN and violent cont...</td>\n",
              "      <td>[\\begin{center}\\n\\begin{tabular}{|l|l|l|}\\n\\hl...</td>\n",
              "      <td>The answer to given question is not present in...</td>\n",
              "      <td>reasoning</td>\n",
              "      <td>[{'source': 'data/nist_ai.tex'}]</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Why does model reuse in GAI complicate transpa...</td>\n",
              "      <td>[CSAM. Even when trained on \"clean\" data, incr...</td>\n",
              "      <td>Model reuse in GAI complicates transparency be...</td>\n",
              "      <td>reasoning</td>\n",
              "      <td>[{'source': 'data/nist_ai.tex'}]</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question  \\\n",
              "0   What are the priorities outlined in the White ...   \n",
              "1   What type of information can provenance metada...   \n",
              "2   What processes are defined, assessed, and docu...   \n",
              "3   What is the purpose of field testing in the ev...   \n",
              "4   What is the purpose of conducting periodic mon...   \n",
              "5   How should GAI acceptable use policies be upda...   \n",
              "6   What are the environmental impacts associated ...   \n",
              "7   How could model distillation or compression he...   \n",
              "8   What actions are suggested to address Human-AI...   \n",
              "9   How can structured public feedback be used to ...   \n",
              "10  How to ID GAI risks and eval AI biases when cu...   \n",
              "11  How do third-party components in GAI systems a...   \n",
              "12  How do vendor reviews and policy tweaks monito...   \n",
              "13  What should GAI incident response plans includ...   \n",
              "14  How can systems secure responses, prevent misu...   \n",
              "15  How do collab with experts and explainable AI ...   \n",
              "16  How do public feedback methods like field test...   \n",
              "17  How do GAI systems' cyber vulnerabilities and ...   \n",
              "18  Who manages AI risks for CBRN and violent cont...   \n",
              "19  Why does model reuse in GAI complicate transpa...   \n",
              "\n",
              "                                             contexts  \\\n",
              "0   [The White House (2022) Roadmap for Researcher...   \n",
              "1   [Provenance metadata can include information a...   \n",
              "2   [MAP 3.4: Processes for operator and practitio...   \n",
              "3   [\\item Al Red-teaming: A structured testing ex...   \n",
              "4   [\\begin{center}\\n\\begin{tabular}{|c|c|c|}\\n\\hl...   \n",
              "5   [may rely on embedded GAI technologies; Addres...   \n",
              "6   [\\item Confabulation: The production of confid...   \n",
              "7   [Trustworthy Al Characteristics: Accountable a...   \n",
              "8   [MAP 3.4: Processes for operator and practitio...   \n",
              "9   [Measurement gaps can arise from mismatches be...   \n",
              "10  [MEASURE 2.13: Effectiveness of the employed T...   \n",
              "11  [CSAM. Even when trained on \"clean\" data, incr...   \n",
              "12  [may rely on embedded GAI technologies; Addres...   \n",
              "13  [MANAGE 2.3: Procedures are followed to respon...   \n",
              "14  [Hateful Content \\\\\\n\\end{tabular} \\\\\\n\\hline\\...   \n",
              "15  [\\begin{center}\\n\\begin{tabular}{|c|c|c|}\\n\\hl...   \n",
              "16  [Measurement gaps can arise from mismatches be...   \n",
              "17  [There may also be concerns about emotional en...   \n",
              "18  [\\begin{center}\\n\\begin{tabular}{|l|l|l|}\\n\\hl...   \n",
              "19  [CSAM. Even when trained on \"clean\" data, incr...   \n",
              "\n",
              "                                         ground_truth evolution_type  \\\n",
              "0   The answer to given question is not present in...         simple   \n",
              "1   Provenance metadata can include information ab...         simple   \n",
              "2   Processes for operator and practitioner profic...         simple   \n",
              "3   The purpose of field testing in the evaluation...         simple   \n",
              "4   The purpose of conducting periodic monitoring ...         simple   \n",
              "5   GAI acceptable use policies should be updated ...         simple   \n",
              "6   Impacts due to high compute resource utilizati...         simple   \n",
              "7   Methods for creating smaller versions of train...         simple   \n",
              "8   The suggested actions to address Human-AI Conf...         simple   \n",
              "9   Structured public feedback can be used to eval...         simple   \n",
              "10  Establish processes for identifying emergent G...  multi_context   \n",
              "11  Third-party components in GAI systems can affe...  multi_context   \n",
              "12  Vendor reviews and policy tweaks monitor third...  multi_context   \n",
              "13  GAI incident response plans should include nec...  multi_context   \n",
              "14  Systems can secure responses, prevent misuse, ...  multi_context   \n",
              "15  Collaborating with external researchers, indus...  multi_context   \n",
              "16  Public feedback methods like field testing bri...  multi_context   \n",
              "17  GAI systems can ease the unintentional product...  multi_context   \n",
              "18  The answer to given question is not present in...      reasoning   \n",
              "19  Model reuse in GAI complicates transparency be...      reasoning   \n",
              "\n",
              "                                             metadata  episode_done  \n",
              "0   [{'source': 'data/nist_ai.tex'}, {'source': 'd...          True  \n",
              "1                    [{'source': 'data/nist_ai.tex'}]          True  \n",
              "2                    [{'source': 'data/nist_ai.tex'}]          True  \n",
              "3                    [{'source': 'data/nist_ai.tex'}]          True  \n",
              "4                    [{'source': 'data/nist_ai.tex'}]          True  \n",
              "5                    [{'source': 'data/nist_ai.tex'}]          True  \n",
              "6                    [{'source': 'data/nist_ai.tex'}]          True  \n",
              "7                    [{'source': 'data/nist_ai.tex'}]          True  \n",
              "8                    [{'source': 'data/nist_ai.tex'}]          True  \n",
              "9   [{'source': 'data/nist_ai.tex'}, {'source': 'd...          True  \n",
              "10  [{'source': 'data/nist_ai.tex'}, {'source': 'd...          True  \n",
              "11  [{'source': 'data/nist_ai.tex'}, {'source': 'd...          True  \n",
              "12  [{'source': 'data/nist_ai.tex'}, {'source': 'd...          True  \n",
              "13  [{'source': 'data/nist_ai.tex'}, {'source': 'd...          True  \n",
              "14  [{'source': 'data/nist_ai.tex'}, {'source': 'd...          True  \n",
              "15  [{'source': 'data/nist_ai.tex'}, {'source': 'd...          True  \n",
              "16  [{'source': 'data/nist_ai.tex'}, {'source': 'd...          True  \n",
              "17  [{'source': 'data/nist_ai.tex'}, {'source': 'd...          True  \n",
              "18                   [{'source': 'data/nist_ai.tex'}]          True  \n",
              "19                   [{'source': 'data/nist_ai.tex'}]          True  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from ragas.testset.generator import TestsetGenerator\n",
        "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
        "from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "generator_llm = AzureChatOpenAI(azure_deployment=\"gpt-4\", temperature=0)\n",
        "critic_llm = AzureChatOpenAI(azure_deployment=\"gpt-4\", temperature=0)\n",
        "embeddings = AzureOpenAIEmbeddings(azure_deployment=\"text-embedding-3-large\")\n",
        "\n",
        "generator = TestsetGenerator.from_langchain(\n",
        "    generator_llm,\n",
        "    critic_llm,\n",
        "    embeddings\n",
        ")\n",
        "\n",
        "distributions = {\n",
        "    simple: 0.5,\n",
        "    multi_context: 0.4,\n",
        "    reasoning: 0.1\n",
        "}\n",
        "\n",
        "num_qa_pairs = 20 # You can reduce the number of QA pairs to 5 if you're experiencing rate-limiting issues\n",
        "\n",
        "testset = generator.generate_with_langchain_docs(eval_documents, num_qa_pairs, distributions, raise_exceptions=False)\n",
        "testset.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "tgDICngKXLGK"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Student's t-test is a statistical test used to compare the means of two groups. There are several key assumptions that must be met for the results of the t-test to be valid:\n",
        "\n",
        "1. **Independence**: The observations within each group and between groups should be independent of each other. This means that the data points collected from one subject should not influence the data points collected from another subject.\n",
        "\n",
        "2. **Normality**: The data in each group should be approximately normally distributed. This assumption is particularly important for small sample sizes. For larger sample sizes, the t-test is fairly robust to deviations from normality due to the Central Limit Theorem.\n",
        "\n",
        "3. **Homogeneity of Variances (Homoskedasticity)**: The variances of the two groups should be equal. This assumption can be tested using Levene's test or an F-test. If the variances are not equal, a variation of the t-test known as Welch's t-test can be used.\n",
        "\n",
        "4. **Scale of Measurement**: The dependent variable should be measured at the interval or ratio level, meaning that it should be continuous and have a meaningful zero point.\n",
        "\n",
        "For a two-sample t-test specifically, these assumptions apply to both groups being compared. If any of these assumptions are violated, the results of the t-test may not be reliable, and alternative statistical methods may need to be considered."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Example data for two groups\n",
        "group1 = np.random.normal(loc=0, scale=1, size=30)\n",
        "group2 = np.random.normal(loc=0, scale=1, size=30)\n",
        "\n",
        "# Normality test using Shapiro-Wilk test\n",
        "shapiro_test_group1 = stats.shapiro(group1)\n",
        "shapiro_test_group2 = stats.shapiro(group2)\n",
        "\n",
        "print(\"Shapiro-Wilk Test for Group 1:\")\n",
        "print(f\"Statistic: {shapiro_test_group1.statistic}, p-value: {shapiro_test_group1.pvalue}\")\n",
        "\n",
        "print(\"Shapiro-Wilk Test for Group 2:\")\n",
        "print(f\"Statistic: {shapiro_test_group2.statistic}, p-value: {shapiro_test_group2.pvalue}\")\n",
        "\n",
        "# Homogeneity of variances test using Levene's test\n",
        "levene_test = stats.levene(group1, group2)\n",
        "\n",
        "print(\"\\nLevene's Test for Homogeneity of Variances:\")\n",
        "print(f\"Statistic: {levene_test.statistic}, p-value: {levene_test.pvalue}\")\n",
        "\n",
        "# Interpretation of p-values\n",
        "alpha = 0.05\n",
        "\n",
        "if shapiro_test_group1.pvalue > alpha:\n",
        "    print(\"Group 1: Data is normally distributed (fail to reject H0)\")\n",
        "else:\n",
        "    print(\"Group 1: Data is not normally distributed (reject H0)\")\n",
        "\n",
        "if shapiro_test_group2.pvalue > alpha:\n",
        "    print(\"Group 2: Data is normally distributed (fail to reject H0)\")\n",
        "else:\n",
        "    print(\"Group 2: Data is not normally distributed (reject H0)\")\n",
        "\n",
        "if levene_test.pvalue > alpha:\n",
        "    print(\"Groups have equal variances (fail to reject H0)\")\n",
        "else:\n",
        "    print(\"Groups do not have equal variances (reject H0)\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
